{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMrGcdSuh6amFD3YjIbHnvs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvsim001/projekt/blob/main/tar_meinMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-tvm --pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71VaE3q0q2Z6",
        "outputId": "7b9b2d1c-c1a2-469a-b691-b9ae98cc0d1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: apache-tvm in /usr/local/lib/python3.10/dist-packages (0.14.dev273)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.12.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserial==3.5 tflite==2.1 Pillow==9.0 typing_extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TUSQT_DXqz4B",
        "outputId": "7060ed83-2f32-4915-a687-76f46b50fa51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial==3.5 in /usr/local/lib/python3.10/dist-packages (3.5)\n",
            "Requirement already satisfied: tflite==2.1 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: Pillow==9.0 in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.12.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from tflite==2.1) (24.3.25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "41mjxATIq-eT",
        "outputId": "46197693-9a55-4432-f10e-f8df723b4668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOyL6Gc5q_C7",
        "outputId": "859a88ad-e87d-4c9d-f958-8e127aa286e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tflite\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_16IxXY87vl",
        "outputId": "66b9c2d5-045e-48c4-82f6-0771d0cc29aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tflite in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Collecting tflite\n",
            "  Downloading tflite-2.10.0-py2.py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from tflite) (24.3.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflite) (1.26.4)\n",
            "Downloading tflite-2.10.0-py2.py3-none-any.whl (123 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/123.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tflite\n",
            "  Attempting uninstall: tflite\n",
            "    Found existing installation: tflite 2.1.0\n",
            "    Uninstalling tflite-2.1.0:\n",
            "      Successfully uninstalled tflite-2.1.0\n",
            "Successfully installed tflite-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import json\n",
        "from PIL import Image\n",
        "import tarfile\n",
        "\n",
        "import tvm\n",
        "from tvm import relay\n",
        "from tvm.relay.backend import Executor, Runtime\n",
        "from tvm.contrib.download import download_testdata\n",
        "from tvm.micro import export_model_library_format\n",
        "from tvm.relay.op.contrib import cmsisnn\n",
        "from tvm.micro.testing.utils import create_header_file"
      ],
      "metadata": {
        "id": "xIMNlcfUq4ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Charger les données MNIST\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Les données doivent rester en uint8, donc pas de normalisation\n",
        "# Ajouter une dimension de canal pour que les images soient au format attendu (batch_size, height, width, channels)\n",
        "x_train = np.expand_dims(x_train, axis=-1).astype(np.uint8)\n",
        "x_test = np.expand_dims(x_test, axis=-1).astype(np.uint8)\n",
        "\n",
        "# Vérifier les types de données\n",
        "print(f\"x_train dtype: {x_train.dtype}, y_train dtype: {y_train.dtype}\")\n",
        "print(f\"x_test dtype: {x_test.dtype}, y_test dtype: {y_test.dtype}\")\n",
        "\n",
        "# Sauvegarder les données dans un fichier .npz\n",
        "np.savez('/content/drive/MyDrive/trained_models/mnist_uint8.npz', x_test=x_test[0:100], y_test=y_test[0:100])\n",
        "\n",
        "print(\"Fichier mnist_uint8.npz créé avec succès.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moBdMPbcE6RJ",
        "outputId": "d4aa0424-ff3e-4c08-f5f0-55539efea29e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "x_train dtype: uint8, y_train dtype: uint8\n",
            "x_test dtype: uint8, y_test dtype: uint8\n",
            "Fichier mnist_uint8.npz créé avec succès.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_URL = \"/content/drive/MyDrive/trained_models/mnist_model_quant.tflite\"\n",
        "MODEL_NAME = \"mnist_model_quant.tflite\"\n",
        "MODEL_PATH = MODEL_URL\n",
        "\n",
        "tflite_model_buf = open(MODEL_PATH, \"rb\").read()\n",
        "try:\n",
        "    import tflite\n",
        "\n",
        "    tflite_model = tflite.Model.GetRootAsModel(tflite_model_buf, 0)\n",
        "except AttributeError:\n",
        "    import tflite.Model\n",
        "\n",
        "    tflite_model = tflite.Model.Model.GetRootAsModel(tflite_model_buf, 0)\n",
        "\n",
        "\n",
        "\n",
        "input_shape = (1, 28, 28, 1)\n",
        "INPUT_NAME = \"input_1_uint8\"\n",
        "\n",
        "from tvm import relay ,transform\n",
        "relay_mod, params = tvm.relay.frontend.from_tflite(\n",
        "    tflite_model, shape_dict={INPUT_NAME: input_shape}, dtype_dict={INPUT_NAME: \"uint8\"}\n",
        ")\n",
        "\n",
        "# Print the Relay module to inspect the weights\n",
        "print(relay_mod)\n",
        "\n",
        "# Check the type and shape of the weight tensors\n",
        "for name, param in params.items():\n",
        "    print(f\"Name: {name}, Type: {type(param)}, Shape: {param.shape}\")"
      ],
      "metadata": {
        "id": "Mu4_TNG9rFvG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863bcaf7-fb1e-4488-9f15-cad0b07eec68"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%input_1: Tensor[(1, 28, 28, 1), uint8] /* span=input_1:0:0 */, %v_param_1: Tensor[(3, 3, 1, 12), int8] /* span=sequential/conv2d/Conv2D:0:0 */, %v_param_2: Tensor[(12), int32] /* span=sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_3: Tensor[(3, 3, 12, 32), int8] /* span=sequential/conv2d_1/Conv2D:0:0 */, %v_param_4: Tensor[(32), int32] /* span=sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_5: Tensor[(3, 3, 32, 64), int8] /* span=sequential/conv2d_2/Conv2D:0:0 */, %v_param_6: Tensor[(64), int32] /* span=sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, %v_param_7: Tensor[(10, 64), int8] /* span=sequential/dense/MatMul:0:0 */, %v_param_8: Tensor[(10), int32] /* span=sequential/dense/BiasAdd/ReadVariableOp/resource:0:0 */, output_tensor_names=[\"Identity\"]) {\n",
            "  %0 = qnn.requantize(%input_1, 0.00392157f /* span=tfl.quantize:0:0 */, 0 /* span=tfl.quantize:0:0 */, 0.00392157f /* span=tfl.quantize:0:0 */, -128 /* span=tfl.quantize:0:0 */, out_dtype=\"int8\") /* span=tfl.quantize:0:0 */;\n",
            "  %1 = qnn.conv2d(%0, %v_param_1, -128 /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, 0 /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, 0.00392157f /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, meta[relay.Constant][0] /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, padding=[0, 0, 0, 0], channels=12, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %2 = nn.bias_add(%1, %v_param_2, axis=3) /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %3 = qnn.requantize(%2, meta[relay.Constant][1] /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, 0 /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, 0.00764128f /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, -128 /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */, axis=3, out_dtype=\"int8\") /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %4 = clip(%3, a_min=-128f, a_max=127f) /* span=sequential/conv2d/Relu;sequential/conv2d/BiasAdd;sequential/conv2d/Conv2D;sequential/conv2d/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %5 = nn.max_pool2d(%4, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0], layout=\"NHWC\") /* span=sequential/max_pooling2d/MaxPool:0:0 */;\n",
            "  %6 = qnn.conv2d(%5, %v_param_3, -128 /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, 0 /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, 0.00764128f /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, meta[relay.Constant][2] /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %7 = nn.bias_add(%6, %v_param_4, axis=3) /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %8 = qnn.requantize(%7, meta[relay.Constant][3] /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, 0 /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, 0.0216478f /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, -128 /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */, axis=3, out_dtype=\"int8\") /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %9 = clip(%8, a_min=-128f, a_max=127f) /* span=sequential/conv2d_1/Relu;sequential/conv2d_1/BiasAdd;sequential/conv2d_1/Conv2D;sequential/conv2d_1/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %10 = nn.max_pool2d(%9, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0], layout=\"NHWC\") /* span=sequential/max_pooling2d_1/MaxPool:0:0 */;\n",
            "  %11 = qnn.conv2d(%10, %v_param_5, -128 /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, 0 /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, 0.0216478f /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, meta[relay.Constant][4] /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %12 = nn.bias_add(%11, %v_param_6, axis=3) /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %13 = qnn.requantize(%12, meta[relay.Constant][5] /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, 0 /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, 0.0640948f /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, -128 /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */, axis=3, out_dtype=\"int8\") /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %14 = clip(%13, a_min=-128f, a_max=127f) /* span=sequential/conv2d_2/Relu;sequential/conv2d_2/BiasAdd;sequential/conv2d_2/Conv2D;sequential/conv2d_2/BiasAdd/ReadVariableOp/resource:0:0 */;\n",
            "  %15 = nn.max_pool2d(%14, pool_size=[2, 2], strides=[2, 2], padding=[0, 0, 0, 0], layout=\"NHWC\") /* span=sequential/max_pooling2d_2/MaxPool:0:0 */;\n",
            "  %16 = reshape(%15, newshape=[-1, 64]) /* span=sequential/flatten/Reshape:0:0 */;\n",
            "  %17 = reshape(%16, newshape=[-1, 64]) /* span=Identity1:0:0 */;\n",
            "  %18 = qnn.dense(%17, %v_param_7, -128 /* span=Identity1:0:0 */, 0 /* span=Identity1:0:0 */, 0.0640948f /* span=Identity1:0:0 */, 0.00421588f /* span=Identity1:0:0 */, units=10, out_dtype=\"int32\") /* span=Identity1:0:0 */;\n",
            "  %19 = nn.bias_add(%18, %v_param_8) /* span=Identity1:0:0 */;\n",
            "  %20 = qnn.requantize(%19, 0.000270216f /* span=Identity1:0:0 */, 0 /* span=Identity1:0:0 */, 0.150491f /* span=Identity1:0:0 */, -1 /* span=Identity1:0:0 */, out_dtype=\"int8\") /* span=Identity1:0:0 */;\n",
            "  qnn.requantize(%20, 0.150491f /* span=Identity:0:0 */, -1 /* span=Identity:0:0 */, 0.150491f /* span=Identity:0:0 */, 127 /* span=Identity:0:0 */, out_dtype=\"uint8\") /* span=Identity:0:0 */\n",
            "}\n",
            "\n",
            "\n",
            "Name: _param_1, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 1, 12)\n",
            "Name: _param_2, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (12,)\n",
            "Name: _param_3, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 12, 32)\n",
            "Name: _param_4, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (32,)\n",
            "Name: _param_5, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 32, 64)\n",
            "Name: _param_6, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (64,)\n",
            "Name: _param_7, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (10, 64)\n",
            "Name: _param_8, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (10,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "version = tflite_model.Version()\n",
        "print(\"Model Version: \" + str(version))"
      ],
      "metadata": {
        "id": "Ra8svcffVjG-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14881ef0-f6fd-42ea-824f-10741de35912"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Version: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use TVM native schedules or rely on the CMSIS-NN kernels using TVM Bring-Your-Own-Code (BYOC) capability.\n",
        "USE_CMSIS_NN = True\n",
        "\n",
        "# USMP (Unified Static Memory Planning) performs memory planning of all tensors holistically to achieve best memory utilization\n",
        "DISABLE_USMP = False\n",
        "\n",
        "# Use the C runtime (crt)\n",
        "RUNTIME = Runtime(\"crt\")\n",
        "\n",
        "# We define the target by passing the board name to `tvm.target.target.micro`.\n",
        "# If your board is not included in the supported models, you can define the target such as:\n",
        "#TARGET = tvm.target.Target(\"c -keys=arm_cpu,cpu -mcpu=cortex-m4\")\n",
        "TARGET = tvm.target.target.micro(\"stm32l4r5zi\")\n",
        "\n",
        "# Use the AOT executor rather than graph or vm executors. Use unpacked API and C calling style.\n",
        "EXECUTOR = tvm.relay.backend.Executor(\n",
        "    \"aot\", {\"unpacked-api\": True, \"interface-api\": \"c\", \"workspace-byte-alignment\": 8}\n",
        ")\n",
        "\n",
        "# Now, we set the compilation configurations and compile the model for the target:\n",
        "config = {\"tir.disable_vectorize\": True}\n",
        "#if USE_CMSIS_NN:\n",
        "#    config[\"relay.ext.cmsisnn.options\"] = {\"mcpu\": TARGET.mcpu}\n",
        "#if DISABLE_USMP:\n",
        "#    config[\"tir.usmp.enable\"] = False\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3, config=config):\n",
        "    if USE_CMSIS_NN:\n",
        "        # When we are using CMSIS-NN, TVM searches for patterns in the\n",
        "        # relay graph that it can offload to the CMSIS-NN kernels.\n",
        "        relay_mod = cmsisnn.partition_for_cmsisnn(relay_mod, params, mcpu=TARGET.mcpu)\n",
        "        lowered = tvm.relay.build(\n",
        "        relay_mod, target=TARGET, params=params, runtime=RUNTIME, executor=EXECUTOR\n",
        "    )\n",
        "parameter_size = len(tvm.runtime.save_param_dict(lowered.get_params()))\n",
        "print(f\"Model parameter size: {parameter_size}\")\n",
        "\n",
        "# We need to pick a directory where our file will be saved.\n",
        "# If running on Google Colab, we'll save everything in ``/root/tutorial`` (aka ``~/tutorial``)\n",
        "# but you'll probably want to store it elsewhere if running locally.\n",
        "\n",
        "BUILD_DIR = pathlib.Path(\"/content/drive/MyDrive/Rar_files\")\n",
        "\n",
        "BUILD_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Now, we export the model into a tar file:\n",
        "TAR_PATH = pathlib.Path(BUILD_DIR) / \"model_meinMNIST.tar\"\n",
        "export_model_library_format(lowered, TAR_PATH)"
      ],
      "metadata": {
        "id": "AAMh-jT8rbG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c361fbb-2c64-45a7-f647-839fa7d6db3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameter size: 32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Rar_files/model_meinMNIST.tar')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with tarfile.open(TAR_PATH, mode=\"a\") as tar_file:\n",
        "    SAMPLES_DIR = \"samples\"\n",
        "    SAMPLE_NUMMER2_PATH = \"/content/drive/MyDrive/RANDOM_IMAGE_FOR_TEST/Nummer_2.jpg\"\n",
        "    SAMPLE_NUMMER5_PATH = \"/content/drive/MyDrive/RANDOM_IMAGE_FOR_TEST/Nummer_5.jpg\"\n",
        "\n",
        "    if os.path.exists(SAMPLE_NUMMER2_PATH):\n",
        "        with open(SAMPLE_NUMMER2_PATH, 'rb') as f:\n",
        "            try:\n",
        "                img = Image.open(f).convert('RGB')\n",
        "                create_header_file(\"nummer_2\", np.asarray(img), SAMPLES_DIR, tar_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error opening image: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {SAMPLE_NUMMER2_PATH}\")\n",
        "\n",
        "    # Repeat the same process for SAMPLE_NUMMER5_PATH\n",
        "    if os.path.exists(SAMPLE_NUMMER5_PATH):\n",
        "        with open(SAMPLE_NUMMER5_PATH, 'rb') as f:\n",
        "            try:\n",
        "                img = Image.open(f).convert('RGB')\n",
        "                create_header_file(\"nummer_5\", np.asarray(img), SAMPLES_DIR, tar_file)\n",
        "            except Exception as e:\n",
        "                print(f\"Error opening image: {e}\")\n",
        "    else:\n",
        "        print(f\"File not found: {SAMPLE_NUMMER5_PATH}\")"
      ],
      "metadata": {
        "id": "28wXI2Le63eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDTB_JQLD2xn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}