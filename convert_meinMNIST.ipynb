{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO9RHse3BBn+DH5zb3abznI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvsim001/projekt/blob/main/convert_meinMNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kTRUWIos1ub9",
        "outputId": "9c784e22-565c-40e2-b69e-92c760faf216"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.17.0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserial==3.5 tflite==2.3 Pillow==9.0 typing_extensions\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        },
        "id": "-_KmvJERheWb",
        "outputId": "8f1b45a7-b10c-49dd-dc17-ab940ca4e9b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyserial==3.5\n",
            "  Downloading pyserial-3.5-py2.py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting tflite==2.3\n",
            "  Downloading tflite-2.3.0-py2.py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting Pillow==9.0\n",
            "  Downloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.12.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from tflite==2.3) (24.3.25)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tflite==2.3) (1.26.4)\n",
            "Downloading pyserial-3.5-py2.py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.6/90.6 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tflite-2.3.0-py2.py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Pillow-9.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyserial, tflite, Pillow\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scikit-image 0.23.2 requires pillow>=9.1, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Pillow-9.0.0 pyserial-3.5 tflite-2.3.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "2449320b050c496ebea5bc6814f1fcc0"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import tflite\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "jKxFsHwO49Mm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzkZCVH-3tyP",
        "outputId": "373b1f04-9bd4-416f-868e-2b45690112fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filepath=\"/content/drive/MyDrive/trained_models/meinMNIST.h5\"\n",
        "model= tf.keras.models.load_model(filepath=filepath)\n",
        "\n"
      ],
      "metadata": {
        "id": "5yxmijdn32gA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89550c4a-8854-43c2-85e2-9f6324b12d2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "ylpnH1_IJtiX",
        "outputId": "cde515b6-a02c-44ae-f5d9-2613c58d4e95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_11\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_11\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_2 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m50,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m650\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ flatten_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">50,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">650</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m50,892\u001b[0m (198.80 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,892</span> (198.80 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m50,890\u001b[0m (198.79 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">50,890</span> (198.79 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2\u001b[0m (12.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2</span> (12.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "saved_model_dir =\"/content/drive/MyDrive/trained_models/meinMNIST\"\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME=\"/content/drive/MyDrive/trained_models/meinMNIST.tflite\"\n",
        "\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "x_train = x_train.reshape(60000, 28,28,1)\n",
        "x_test = x_test.reshape(10000, 28,28,1)\n",
        "\n",
        "x_test_2 = x_test\n",
        "\n",
        "\n",
        "print(x_train.dtype)\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "id": "bBPSUHCcE285",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b8a2729-6710-44a6-b92f-f7c0ab05ee0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n",
            "uint8\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.max(x_train))\n",
        "print(np.min(x_train))\n",
        "print(x_train.dtype)\n",
        "print(np.max(x_test))\n",
        "print(np.min(x_test))\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "id": "urY0jE1fuqNH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1445c782-39aa-444f-bbab-9fd8932548d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "255\n",
            "0\n",
            "uint8\n",
            "255\n",
            "0\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.min(x_test))\n",
        "print(np.max(x_test))\n",
        "print(x_test.dtype)"
      ],
      "metadata": {
        "id": "kcZJZwEEtZ3f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77e9e3a1-6653-4e95-ac24-376fe1c37012"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "255\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Scale= ((np.max(x_test)-np.min(x_test))/(127-(-128))).astype(\"float32\") #Quantization  Result= 84,27%\n",
        "#Scale =  (2*(128)/256)                     #Quantization NVIDIA -> scale is equal max -min /2^n bit\n",
        "\n",
        "Zeropoint= -128-np.min(x_test)/Scale\n",
        "print(Scale)\n",
        "print(Zeropoint)"
      ],
      "metadata": {
        "id": "Ta0zAn-X2UwW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864203da-5037-4a1c-d3fa-7be80671f0f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.0\n",
            "-128.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = np.clip(np.round(x_test/Scale +Zeropoint), np.round(0.0/Scale+Zeropoint), np.round(255.0/Scale+Zeropoint))\n",
        "x_train = np.clip(np.round(x_train/Scale +Zeropoint), np.round(0.0/Scale+Zeropoint), np.round(255.0/Scale+Zeropoint))\n",
        "\n",
        "\n",
        "#x_test= np.clip(np.round(x_test/Scale),-128,127).astype(\"float32\")\n",
        "\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(\"x_train shape\", x_train.shape)\n",
        "print(\"y_train shape\", y_train.shape)"
      ],
      "metadata": {
        "id": "Ef9ub_StqA35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa752a91-142b-4854-e4dc-76779c48cb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape (60000, 28, 28, 1)\n",
            "y_train shape (60000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Define the representative dataset generation function\n",
        "# Convertissez le modèle en TFLite avec quantification\n",
        "mnist_sampleset = tf.data.Dataset.from_tensor_slices(x_train).batch(1)\n",
        "\n",
        "def representative_dataset_gen():\n",
        "    for input_value in mnist_sampleset.take(100):\n",
        "        yield [input_value]\n",
        "\n",
        "\n",
        "\n",
        "# Convert the saved model to a TFLite model with full integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.representative_dataset = representative_dataset_gen\n",
        "# This enables quantization\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "# This ensures that if any ops can't be quantized, the converter throws an error\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "# For full integer quantization, though supported types defaults to int8 only\n",
        "converter.target_spec.supported_types = [tf.int8]\n",
        "# These set the input and output tensors to uint8 (added in r2.3)\n",
        "converter.inference_input_type = tf.uint8  # or tf.int8/tf.float32\n",
        "converter.inference_output_type = tf.uint8  # or tf.int8/tf.float32\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "# Save the model.\n",
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "id": "6stnDCaZp5bB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c789056-58e1-47f8-9ed6-892f703c2fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55576"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "mfs-WNtkBYkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_file_size(file_path):\n",
        "    size = os.path.getsize(file_path)\n",
        "    return size"
      ],
      "metadata": {
        "id": "E1V4toQltMb5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_bytes(size, unit=None):\n",
        "    if unit == \"KB\":\n",
        "        return print('File size: ' + str(round(size / 1024, 3)) + ' Kilobytes')\n",
        "    elif unit == \"MB\":\n",
        "        return print('File size: ' + str(round(size / (1024 * 1024), 3)) + ' Megabytes')\n",
        "    else:\n",
        "        return print('File size: ' + str(size) + ' bytes')"
      ],
      "metadata": {
        "id": "NrQeu4yOtHj1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "convert_bytes(get_file_size(saved_model_dir), \"KB\")"
      ],
      "metadata": {
        "id": "Ukq0wraamlyx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0aaf6f35-f654-4013-e73a-a262544f7c20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File size: 4.0 Kilobytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the quantized TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=TF_LITE_MODEL_FILE_NAME)\n",
        "\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "\n",
        "# Adjust the model interpreter to take 10,000 inputs at once instead of just 1\n",
        "interpreter.resize_tensor_input(input_details[0][\"index\"], (10000, 28,28,1))\n",
        "interpreter.resize_tensor_input(output_details[0][\"index\"], (10000, 10))\n",
        "\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "# Cast the test data to int8 before setting the tensor\n",
        "x_test_int8 = (x_test.astype(np.uint8))  # Cast to int8\n",
        "print(np.min(x_test_int8))\n",
        "print(np.max(x_test_int8))\n",
        "print(x_test_int8.dtype)\n",
        "\n",
        "# Set the test input and run\n",
        "interpreter.set_tensor(input_details[0][\"index\"], x_test_2) # Use the int8 version\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the result and check its accuracy\n",
        "output_data = (interpreter.get_tensor(output_details[0][\"index\"]))//255\n",
        "y_test = y_test.astype(np.uint8)\n",
        "\n",
        "predicted_classes = [np.argmax(y, axis=None, out=None) for y in output_data]\n",
        "true_classes = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
        "\n",
        "accuracy = (np.array(predicted_classes) == np.array(true_classes)).mean()\n",
        "print(\"TFLite Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "-j8QIPEPwXTj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "167d9156-9a12-46f9-c0ca-76c1180d3fc5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "255\n",
            "uint8\n",
            "TFLite Accuracy: 0.1452\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "yas2IktlGh-C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[0:10])\n",
        "print(y_test.dtype)"
      ],
      "metadata": {
        "id": "Gay4RdS4spwr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049487e0-3cdc-414a-d6d2-4f2ffc91498a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 0 0 0 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [1 0 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]\n",
            " [0 0 0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 0 0 0 1]]\n",
            "uint8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(output_data[0:10])"
      ],
      "metadata": {
        "id": "KyLs68XU_fkC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ac560c-7c53-410b-95c0-727f2126b19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0 0 0]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(predicted_classes[0:100])\n",
        "print(true_classes[0:100])"
      ],
      "metadata": {
        "id": "_8Ny2mlB_uKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e063ca70-68bd-4ef1-9797-7a02bf82c452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 7, 1, 1, 1, 1, 5, 1, 5, 1, 1, 1, 1, 1, 1, 1, 7, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            "[7, 2, 1, 0, 4, 1, 4, 9, 5, 9, 0, 6, 9, 0, 1, 5, 9, 7, 3, 4, 9, 6, 6, 5, 4, 0, 7, 4, 0, 1, 3, 1, 3, 4, 7, 2, 7, 1, 2, 1, 1, 7, 4, 2, 3, 5, 1, 2, 4, 4, 6, 3, 5, 5, 6, 0, 4, 1, 9, 5, 7, 8, 9, 3, 7, 4, 6, 4, 3, 0, 7, 0, 2, 9, 1, 7, 3, 2, 9, 7, 7, 6, 2, 7, 8, 4, 7, 3, 6, 1, 3, 6, 9, 3, 1, 4, 1, 7, 6, 9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vlqqYWehfJfk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mXg-_nfvhhBQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iHYpI9skQnpj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install apache-tvm --pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQeicYvERNf0",
        "outputId": "44434ba6-99c3-470a-8f78-d1b002ec0148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting apache-tvm\n",
            "  Downloading apache_tvm-0.14.dev273-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (0.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.26.4)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.13.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.12.2)\n",
            "Downloading apache_tvm-0.14.dev273-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (69.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.2/69.2 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: apache-tvm\n",
            "Successfully installed apache-tvm-0.14.dev273\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import json\n",
        "from PIL import Image\n",
        "import tarfile\n",
        "\n",
        "import tvm\n",
        "from tvm import relay\n",
        "from tvm.relay.backend import Executor, Runtime\n",
        "from tvm.contrib.download import download_testdata\n",
        "from tvm.micro import export_model_library_format\n",
        "from tvm.relay.op.contrib import cmsisnn\n",
        "from tvm.micro.testing.utils import create_header_file"
      ],
      "metadata": {
        "id": "ntkWHrCfQnc_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_URL = \"/content/drive/MyDrive/trained_models/meinMNIST.tflite\"\n",
        "MODEL_NAME = \"meinMNIST.tflite\"\n",
        "MODEL_PATH = MODEL_URL\n",
        "\n",
        "tflite_model_buf = open(MODEL_PATH, \"rb\").read()\n",
        "try:\n",
        "    import tflite\n",
        "\n",
        "    tflite_model = tflite.Model.GetRootAsModel(tflite_model_buf, 0)\n",
        "except AttributeError:\n",
        "    import tflite.Model\n",
        "\n",
        "    tflite_model = tflite.Model.Model.GetRootAsModel(tflite_model_buf, 0)\n",
        "\n",
        "\n",
        "\n",
        "# TFLite input tensor name, shape and type\n",
        "input_tensor = \"input\"\n",
        "input_shape = (1, 28, 28, 1)\n",
        "input_dtype = \"uint8\"\n",
        "\n",
        "# Parse TFLite model and convert it to a Relay module\n",
        "from tvm import relay, transform\n",
        "\n",
        "mod, params = relay.frontend.from_tflite(\n",
        "    tflite_model, shape_dict={input_tensor: input_shape}, dtype_dict={input_tensor: input_dtype}\n",
        ")\n",
        "\n",
        "# Print the Relay module to inspect the weights\n",
        "print(relay_mod)\n",
        "\n",
        "# Check the type and shape of the weight tensors\n",
        "for name, param in params.items():\n",
        "    print(f\"Name: {name}, Type: {type(param)}, Shape: {param.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "AiL47v6CQEl_",
        "outputId": "bcf3a340-f778-42f1-f987-cc1467dbd068"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AssertionError",
          "evalue": "Expr is not a constant scalar.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-4ec9a6f29eac>\u001b[0m in \u001b[0;36m<cell line: 25>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtvm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m mod, params = relay.frontend.from_tflite(\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mtflite_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minput_dtype\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tvm/relay/frontend/tflite.py\u001b[0m in \u001b[0;36mfrom_tflite\u001b[0;34m(model, shape_dict, dtype_dict, op_converter)\u001b[0m\n\u001b[1;32m   4201\u001b[0m     \u001b[0mop_converter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop_converter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexp_tab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m     \u001b[0mop_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_unsupported_ops\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4203\u001b[0;31m     \u001b[0mop_converter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_op_to_relay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4205\u001b[0m     \u001b[0;31m# params and outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tvm/relay/frontend/tflite.py\u001b[0m in \u001b[0;36mconvert_op_to_relay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOperator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mop_code_str\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m             \u001b[0;31m# In case the Op can be prefetched, the output can be optimized out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tvm/relay/frontend/tflite.py\u001b[0m in \u001b[0;36mconvert_fully_connected\u001b[0;34m(self, op)\u001b[0m\n\u001b[1;32m   2003\u001b[0m             \u001b[0mweight_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqnn_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"scale\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2004\u001b[0m             \u001b[0mdata_scale_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scalar_from_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m             \u001b[0mweight_scale_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_scalar_from_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight_scale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m             \u001b[0mnew_input_scale_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_scale_val\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mweight_scale_val\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m             \u001b[0mnew_input_scale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrelay\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconst\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_input_scale_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"float32\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tvm/relay/frontend/tflite.py\u001b[0m in \u001b[0;36mget_scalar_from_constant\u001b[0;34m(expr)\u001b[0m\n\u001b[1;32m   4007\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_scalar_from_constant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4008\u001b[0m     \u001b[0;34m\"\"\"Returns scalar value from Relay constant scalar.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4009\u001b[0;31m     assert (\n\u001b[0m\u001b[1;32m   4010\u001b[0m         \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_expr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4011\u001b[0m     ), \"Expr is not a constant scalar.\"\n",
            "\u001b[0;31mAssertionError\u001b[0m: Expr is not a constant scalar."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # We can use TVM native schedules or rely on the CMSIS-NN kernels using TVM Bring-Your-Own-Code (BYOC) capability.\n",
        "USE_CMSIS_NN = True\n",
        "\n",
        "# USMP (Unified Static Memory Planning) performs memory planning of all tensors holistically to achieve best memory utilization\n",
        "DISABLE_USMP = False\n",
        "\n",
        "# Use the C runtime (crt)\n",
        "RUNTIME = Runtime(\"crt\")\n",
        "\n",
        "# We define the target by passing the board name to `tvm.target.target.micro`.\n",
        "# If your board is not included in the supported models, you can define the target such as:\n",
        "# TARGET = tvm.target.Target(\"c -keys=arm_cpu,cpu -mcpu=cortex-m4\")\n",
        "TARGET = tvm.target.target.micro(\"stm32l4r5zi\")\n",
        "\n",
        "# Use the AOT executor rather than graph or vm executors. Use unpacked API and C calling style.\n",
        "EXECUTOR = tvm.relay.backend.Executor(\n",
        "    \"aot\", {\"unpacked-api\": True, \"interface-api\": \"c\", \"workspace-byte-alignment\": 8}\n",
        ")\n",
        "\n",
        "# Now, we set the compilation configurations and compile the model for the target:\n",
        "config = {\"tir.disable_vectorize\": True}\n",
        "if USE_CMSIS_NN:\n",
        "    config[\"relay.ext.cmsisnn.options\"] = {\"mcpu\": TARGET.mcpu}\n",
        "if DISABLE_USMP:\n",
        "    config[\"tir.usmp.enable\"] = False\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3, config=config):\n",
        "    if USE_CMSIS_NN:\n",
        "        # When we are using CMSIS-NN, TVM searches for patterns in the\n",
        "        # relay graph that it can offload to the CMSIS-NN kernels.\n",
        "        relay_mod = cmsisnn.partition_for_cmsisnn(relay_mod, params, mcpu=TARGET.mcpu)\n",
        "    lowered = tvm.relay.build(\n",
        "        relay_mod, target=TARGET, params=params, runtime=RUNTIME, executor=EXECUTOR\n",
        "    )\n",
        "parameter_size = len(tvm.runtime.save_param_dict(lowered.get_params()))\n",
        "print(f\"Model parameter size: {parameter_size}\")\n",
        "\n",
        "# We need to pick a directory where our file will be saved.\n",
        "# If running on Google Colab, we'll save everything in ``/root/tutorial`` (aka ``~/tutorial``)\n",
        "# but you'll probably want to store it elsewhere if running locally.\n",
        "\n",
        "BUILD_DIR = pathlib.Path(\"/root/tutorial\")\n",
        "\n",
        "BUILD_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Now, we export the model into a tar file:\n",
        "TAR_PATH = pathlib.Path(BUILD_DIR) / \"model.tar\"\n",
        "export_model_library_format(lowered, TAR_PATH)"
      ],
      "metadata": {
        "id": "CfsPycLDQGsv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use TVM native schedules or rely on the CMSIS-NN kernels using TVM Bring-Your-Own-Code (BYOC) capability.\n",
        "USE_CMSIS_NN = True\n",
        "\n",
        "# USMP (Unified Static Memory Planning) performs memory planning of all tensors holistically to achieve best memory utilization\n",
        "DISABLE_USMP = False\n",
        "\n",
        "# Use the C runtime (crt)\n",
        "RUNTIME = Runtime(\"crt\")\n",
        "\n",
        "# We define the target by passing the board name to `tvm.target.target.micro`.\n",
        "# If your board is not included in the supported models, you can define the target such as:\n",
        "#TARGET = tvm.target.Target(\"c -keys=arm_cpu,cpu -mcpu=cortex-m4\")\n",
        "TARGET = tvm.target.target.micro(\"stm32l4r5zi\")\n",
        "\n",
        "# Use the AOT executor rather than graph or vm executors. Use unpacked API and C calling style.\n",
        "EXECUTOR = tvm.relay.backend.Executor(\n",
        "    \"aot\", {\"unpacked-api\": True, \"interface-api\": \"c\", \"workspace-byte-alignment\": 8}\n",
        ")\n",
        "\n",
        "# Now, we set the compilation configurations and compile the model for the target:\n",
        "config = {\"tir.disable_vectorize\": True}\n",
        "#if USE_CMSIS_NN:\n",
        "#    config[\"relay.ext.cmsisnn.options\"] = {\"mcpu\": TARGET.mcpu}\n",
        "#if DISABLE_USMP:\n",
        "#    config[\"tir.usmp.enable\"] = False\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3, config=config):\n",
        "    if USE_CMSIS_NN:\n",
        "        # When we are using CMSIS-NN, TVM searches for patterns in the\n",
        "        # relay graph that it can offload to the CMSIS-NN kernels.\n",
        "        relay_mod = cmsisnn.partition_for_cmsisnn(relay_mod, params, mcpu=TARGET.mcpu)\n",
        "        lowered = tvm.relay.build(\n",
        "        relay_mod, target=TARGET, params=params, runtime=RUNTIME, executor=EXECUTOR\n",
        "    )\n",
        "parameter_size = len(tvm.runtime.save_param_dict(lowered.get_params()))\n",
        "print(f\"Model parameter size: {parameter_size}\")\n",
        "\n",
        "# We need to pick a directory where our file will be saved.\n",
        "# If running on Google Colab, we'll save everything in ``/root/tutorial`` (aka ``~/tutorial``)\n",
        "# but you'll probably want to store it elsewhere if running locally.\n",
        "\n",
        "BUILD_DIR = pathlib.Path(\"/content/drive/MyDrive/Rar_files\")\n",
        "\n",
        "BUILD_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Now, we export the model into a tar file:\n",
        "TAR_PATH = pathlib.Path(BUILD_DIR) / \"model_meinMNIST.tar\"\n",
        "export_model_library_format(lowered, TAR_PATH)"
      ],
      "metadata": {
        "id": "SZT7gmJAQLQp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jfZBFStISGpC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}