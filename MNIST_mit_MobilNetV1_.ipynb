{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yvsim001/projekt/blob/main/MNIST_mit_MobilNetV1_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNo_QEIbsJqo",
        "outputId": "f9ae5640-a15b-4b94-c0ab-33223f3ab6e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.10/dist-packages (1.23.5)\n",
            "\u001b[33mWARNING: Ignoring invalid distribution -andas (/usr/local/lib/python3.10/dist-packages)\u001b[0m\u001b[33m\n",
            "\u001b[0mCollecting scipy==1.10.1\n",
            "  Using cached scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (58 kB)\n",
            "Requirement already satisfied: numpy<1.27.0,>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scipy==1.10.1) (1.23.5)\n",
            "Using cached scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "albumentations 1.4.15 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "mizani 0.11.4 requires pandas>=2.1.0, but you have pandas 2.0.0 which is incompatible.\n",
            "plotnine 0.13.6 requires pandas<3.0.0,>=2.1.0, but you have pandas 2.0.0 which is incompatible.\n",
            "scikit-image 0.24.0 requires pillow>=9.1, but you have pillow 9.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scipy-1.10.1\n",
            "Requirement already satisfied: pandas==2.0.0 in /usr/local/lib/python3.10/dist-packages (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0) (2024.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas==2.0.0) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas==2.0.0) (1.16.0)\n",
            "Collecting tensorflow==2.16.2\n",
            "  Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.11.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (18.1.1)\n",
            "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.16.2)\n",
            "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (24.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.20.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (71.0.4)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.16.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.64.1)\n",
            "Collecting tensorboard<2.17,>=2.16 (from tensorflow==2.16.2)\n",
            "  Downloading tensorboard-2.16.2-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (3.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow==2.16.2) (1.23.5)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow==2.16.2) (0.44.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (13.8.1)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow==2.16.2) (0.12.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow==2.16.2) (2024.8.30)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow==2.16.2) (3.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow==2.16.2) (2.1.5)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.0.0->tensorflow==2.16.2) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow==2.16.2) (0.1.2)\n",
            "Downloading tensorflow-2.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (590.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ml-dtypes, tensorboard, tensorflow\n",
            "  Attempting uninstall: ml-dtypes\n",
            "    Found existing installation: ml-dtypes 0.4.1\n",
            "    Uninstalling ml-dtypes-0.4.1:\n",
            "      Successfully uninstalled ml-dtypes-0.4.1\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "jax 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "jaxlib 0.4.33 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.16.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ml-dtypes-0.3.2 tensorboard-2.16.2 tensorflow-2.16.2\n",
            "Collecting scikit-learn==1.2.2\n",
            "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2) (3.5.0)\n",
            "Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m56.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.5.2\n",
            "    Uninstalling scikit-learn-1.5.2:\n",
            "      Successfully uninstalled scikit-learn-1.5.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.18.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed scikit-learn-1.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy==1.23.5\n",
        "!pip install scipy==1.10.1\n",
        "!pip install pandas==2.0.0\n",
        "!pip install tensorflow==2.16.2\n",
        "!pip install scikit-learn==1.2.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QH9KcNzsToAF"
      },
      "outputs": [],
      "source": [
        "# LOAD LIBRARIES\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5rZZXt4a7bR",
        "outputId": "6bd88948-983e-4f1e-dc98-6ab71b3ed11e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.16.2\n",
            "3.4.1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "print(tf.__version__)\n",
        "print(keras.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "z7PxmD06aL3M"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCdB68nrh0lF",
        "outputId": "51663bbe-f5a3-4f84-ce2a-2a7b45416937"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dmhm0r1Tw8K",
        "outputId": "57b896c0-bfad-4b95-872e-89f6ff314f2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float32')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Model / data parameters\n",
        "H, W, C = 28, 28, 1\n",
        "IN_SHAPE = (H, W, C)\n",
        "NB_CLASSES = 10\n",
        "\n",
        "# Load the data and split it between train and test sets\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "\n",
        "\n",
        "x_train = x_train.reshape(x_train.shape[0], H, W, C)\n",
        "x_test = x_test.reshape(x_test.shape[0], H, W, C)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, NB_CLASSES)\n",
        "y_test = keras.utils.to_categorical(y_test, NB_CLASSES)\n",
        "\n",
        "x_train.dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sbrziqY3Z8Py",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "0c5611e5-a9c7-4bd1-dfc9-91f2cdf4850e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x450 with 30 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "# PREVIEW IMAGES\n",
        "plt.figure(figsize=(15,4.5))\n",
        "for i in range(30):\n",
        "    plt.subplot(3, 10, i+1)\n",
        "    plt.imshow(x_train[i].reshape((28,28)),cmap=plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "k67KOwV7aEa9"
      },
      "outputs": [],
      "source": [
        "# CREATE MORE IMAGES VIA DATA AUGMENTATION\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "        rotation_range=10,\n",
        "        zoom_range = 0.10,\n",
        "        width_shift_range=0.1,\n",
        "        height_shift_range=0.1\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OleLq3-ycWKX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "64b6b5d8-1f14-427b-f407-4c8f2be85a00"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x450 with 30 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# PREVIEW AUGMENTED IMAGES\n",
        "X_train3 = x_train[9].reshape((1, 28, 28, 1))\n",
        "Y_train3 = y_train[9].reshape((1, 10))\n",
        "plt.figure(figsize=(15, 4.5))\n",
        "for i in range(30):\n",
        "    plt.subplot(3, 10, i + 1)\n",
        "    X_train2, Y_train2 = next(datagen.flow(X_train3, Y_train3))\n",
        "    plt.imshow(X_train2[0].reshape((28, 28)), cmap=plt.cm.binary)\n",
        "    plt.axis('off')\n",
        "    if i == 9: X_train3 = x_train[11].reshape((1, 28, 28, 1))\n",
        "    if i == 19: X_train3 = x_train[18].reshape((1, 28, 28, 1))\n",
        "plt.subplots_adjust(wspace=-0.1, hspace=-0.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Activation, Flatten, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D, DepthwiseConv2D, AveragePooling2D, MaxPooling2D\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "\n",
        "def mobilenet_v1():\n",
        "    # Mobilenet parameters\n",
        "    input_shape = [28,28,1]\n",
        "    num_classes = 10\n",
        "    num_filters = 8 # normally 32, but running with alpha=.25 per EEMBC requirement\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = inputs # Keras model uses ZeroPadding2D()\n",
        "\n",
        "    # 1st layer, pure conv\n",
        "    # Keras 2.2 model has padding='valid' and disables bias\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(0.0001))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x) # Keras uses ReLU6 instead of pure ReLU\n",
        "\n",
        "    # 2nd layer, depthwise separable conv\n",
        "    # Filter size is always doubled before the pointwise conv\n",
        "    # Keras uses ZeroPadding2D() and padding='valid'\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    num_filters = 2*num_filters\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 3rd layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    num_filters = 2*num_filters\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 4th layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 5th layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    num_filters = 2*num_filters\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 6th layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 7th layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    num_filters = 2*num_filters\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 8th-12th layers, identical depthwise separable convs\n",
        "    # 8th\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 9th\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 10th\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 11th\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 12th\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 13th layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=2,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    num_filters = 2*num_filters\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # 14th layer, depthwise separable conv\n",
        "    x = DepthwiseConv2D(kernel_size=3,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  depthwise_initializer='he_normal',\n",
        "                  depthwise_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(num_filters,\n",
        "                  kernel_size=1,\n",
        "                  strides=1,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    # Average pooling, max polling may be used also\n",
        "    # Keras employs GlobalAveragePooling2D\n",
        "    x = AveragePooling2D(pool_size=x.shape[1:3])(x)\n",
        "    #x = MaxPooling2D(pool_size=x.shape[1:3])(x)\n",
        "\n",
        "    # Keras inserts Dropout() and a pointwise Conv2D() here\n",
        "    # We are staying with the paper base structure\n",
        "\n",
        "    # Flatten, FC layer and classify\n",
        "    x = Flatten()(x)\n",
        "    outputs = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n",
        "model = mobilenet_v1()"
      ],
      "metadata": {
        "id": "LYgzuFMZVj13"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xEn3A9G_wTGP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vek6Ez3skz9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7f114b8-e3e2-4931-b303-478985c70ab0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m115s\u001b[0m 50ms/step - accuracy: 0.3507 - loss: 2.1428 - val_accuracy: 0.8873 - val_loss: 0.6436\n",
            "Epoch 2/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 49ms/step - accuracy: 0.8758 - loss: 0.6800 - val_accuracy: 0.9465 - val_loss: 0.4313\n",
            "Epoch 3/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m139s\u001b[0m 47ms/step - accuracy: 0.9367 - loss: 0.4558 - val_accuracy: 0.9608 - val_loss: 0.3493\n",
            "Epoch 4/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 47ms/step - accuracy: 0.9541 - loss: 0.3703 - val_accuracy: 0.9748 - val_loss: 0.2793\n",
            "Epoch 5/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 50ms/step - accuracy: 0.9653 - loss: 0.3050 - val_accuracy: 0.9778 - val_loss: 0.2489\n",
            "Epoch 6/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m146s\u001b[0m 52ms/step - accuracy: 0.9700 - loss: 0.2633 - val_accuracy: 0.9787 - val_loss: 0.2180\n",
            "Epoch 7/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m137s\u001b[0m 49ms/step - accuracy: 0.9733 - loss: 0.2326 - val_accuracy: 0.9785 - val_loss: 0.1993\n",
            "Epoch 8/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 48ms/step - accuracy: 0.9775 - loss: 0.2034 - val_accuracy: 0.9818 - val_loss: 0.1765\n",
            "Epoch 9/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 48ms/step - accuracy: 0.9794 - loss: 0.1846 - val_accuracy: 0.9853 - val_loss: 0.1623\n",
            "Epoch 10/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 49ms/step - accuracy: 0.9809 - loss: 0.1756 - val_accuracy: 0.9840 - val_loss: 0.1661\n",
            "Epoch 11/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 49ms/step - accuracy: 0.9832 - loss: 0.1586 - val_accuracy: 0.9847 - val_loss: 0.1494\n",
            "Epoch 12/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 46ms/step - accuracy: 0.9848 - loss: 0.1495 - val_accuracy: 0.9887 - val_loss: 0.1317\n",
            "Epoch 13/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 50ms/step - accuracy: 0.9852 - loss: 0.1436 - val_accuracy: 0.9867 - val_loss: 0.1321\n",
            "Epoch 14/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 47ms/step - accuracy: 0.9850 - loss: 0.1389 - val_accuracy: 0.9758 - val_loss: 0.1794\n",
            "Epoch 15/15\n",
            "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 49ms/step - accuracy: 0.9845 - loss: 0.1359 - val_accuracy: 0.9825 - val_loss: 0.1428\n"
          ]
        }
      ],
      "source": [
        "batch_size = 32\n",
        "epochs = 15\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "history=model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "jSDB5BvlpK9B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5fbfd5a9-e2cb-451c-d6c2-371a41a34c8b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN: Epochs=15, Train accuracy=0.98489, Validation accuracy=0.98867\n"
          ]
        }
      ],
      "source": [
        " # Print training and validation accuracy\n",
        "print(\"CNN: Epochs={0:d}, Train accuracy={1:.5f}, Validation accuracy={2:.5f}\".format(\n",
        "    epochs, max(history.history['accuracy']), max(history.history['val_accuracy'])\n",
        "))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test loss:\", score[0])\n",
        "print(\"Test accuracy:\", score[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "flSUtWjAbqBy",
        "outputId": "e5b44687-c7e7-42a7-8e8f-b69a7668b60c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m1\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │              \u001b[38;5;34m80\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_27               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │              \u001b[38;5;34m32\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_27 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_13                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │              \u001b[38;5;34m80\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_28               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │              \u001b[38;5;34m32\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_28 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m8\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_15 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │             \u001b[38;5;34m144\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_29               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_29 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m16\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_14                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │             \u001b[38;5;34m160\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_30               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │              \u001b[38;5;34m64\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_30 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_16 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m544\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_31               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_31 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_15                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m320\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_32               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_32 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_17 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │           \u001b[38;5;34m1,056\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_33               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_33 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_16                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m320\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_34               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │             \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_34 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m32\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_18 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_35               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_35 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_17                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m640\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_36               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_36 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_19 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_37               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_37 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_18                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m640\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_38               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_38 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_20 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_39               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_39 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_19                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_40               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_40 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_21 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_41               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_41 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_20                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_42               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_42 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_43               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_43 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_21                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_44               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_44 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_45               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_45 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_22                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_46               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_46 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_24 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_47               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_47 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_23                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_48               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_48 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_25 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m16,512\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_49               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_49 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_24                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m1,280\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_50               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_50 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_26 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_51               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_51 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_25                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m2,560\u001b[0m │\n",
              "│ (\u001b[38;5;33mDepthwiseConv2D\u001b[0m)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_52               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_52 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_27 (\u001b[38;5;33mConv2D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_53               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_53 (\u001b[38;5;33mActivation\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "│ (\u001b[38;5;33mAveragePooling2D\u001b[0m)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m2,570\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_27               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_13                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_28               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_28 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">144</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_29               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_29 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_14                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_30               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">544</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_31               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_15                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_32               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_33               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_16                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_34               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_34 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_35               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_35 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_17                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_36               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_36 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_37               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_37 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_18                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_38               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_38 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_39               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_39 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_19                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_40               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_40 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_41               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_41 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_20                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_42               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_43               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_43 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_21                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_44               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_44 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_45               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_45 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_22                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_46               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_46 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_24 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_47               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_47 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_23                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_48               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_48 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_25 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">16,512</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_49               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_49 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_24                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_50               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_26 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_51               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ depthwise_conv2d_25                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">DepthwiseConv2D</span>)                    │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_52               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_27 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_53               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ activation_53 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ average_pooling2d_1                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">AveragePooling2D</span>)                   │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,570</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m660,176\u001b[0m (2.52 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">660,176</span> (2.52 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m218,234\u001b[0m (852.48 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">218,234</span> (852.48 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m5,472\u001b[0m (21.38 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,472</span> (21.38 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m436,470\u001b[0m (1.67 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">436,470</span> (1.67 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test loss: 0.13164229691028595\n",
            "Test accuracy: 0.9842000007629395\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-NMn5l_br35"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "rtUPTo1qT9Hz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "6cc3b752-842a-45f7-bf97-3a86023fd434"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2s/step\n",
            "Predictions (in percentages) for each class:\n",
            "Class 0: 0.00%\n",
            "Class 1: 0.02%\n",
            "Class 2: 0.00%\n",
            "Class 3: 0.00%\n",
            "Class 4: 99.91%\n",
            "Class 5: 0.00%\n",
            "Class 6: 0.00%\n",
            "Class 7: 0.01%\n",
            "Class 8: 0.01%\n",
            "Class 9: 0.05%\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "test_images = x_test\n",
        "# For example, if test_images[4] is a single image with shape (28, 28, 1)\n",
        "img = test_images[4]\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(img.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Reshape the image to match the model's input requirements (1, 28, 28, 1)\n",
        "img_reshaped = np.expand_dims(img, axis=0)\n",
        "\n",
        "# Predict using the reshaped image\n",
        "prediction = model.predict(img_reshaped)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Predictions (in percentages) for each class:\")\n",
        "for idx, prob in enumerate(prediction[0]):\n",
        "    print(f\"Class {idx}: {prob*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNPIJKs2UMlx",
        "outputId": "4aed0a67-9dd9-4d7c-bfe7-c4301e0b5a58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved artifact at '/content/drive/MyDrive/trained_models/meinMNIST_V1'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name='keras_tensor_85')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 10), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137821279765072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279764544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279768592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279780560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279776688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279777568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279779328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279768768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279773168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277064176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279775808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821279769824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277069280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277074208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277067344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277075440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277068048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277062064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277075616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821277070160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275146896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275146544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275145312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275145488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275149888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275150592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275147072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275154992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275153760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275153936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275158336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275159744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275245904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275245552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275244320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275244496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821280505696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275251712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821276859632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275254704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821290631888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821276857168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275257872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275327120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275325360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275328880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275327648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275327824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275332224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275332928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275329408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275337328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275336096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275336272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275390544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275390016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275393184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275395120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275393888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275394064: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275398464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275399168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275395648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275403568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275402336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275402512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275255584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275331168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275510864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275510512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275509104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275507520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275513856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275514560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275511040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275518960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275517728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275517904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275555264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275555968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275554208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275560368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275559136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275559312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275563712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275564416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275560896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275568816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275567584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275567760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009430656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009431360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009434000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009435760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009434528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009434704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009439104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009439808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009436288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009444032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009442976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009443152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009546048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009546752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009544288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009551152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009549920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009550096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009554496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009555200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009558720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009610000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009558368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009558544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009612288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275505232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009623376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009691392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009618448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009620912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009694736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009695440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009691744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009556080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009698608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009698784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275504880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821275251008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009693152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009701072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009693680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009700016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009703360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009702656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009807488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009807136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009805904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009806080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009810480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009811184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009807664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009815584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009814352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009814528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009818928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009818224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009873728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009873376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009872144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009872320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009876720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009877424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009873904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009881824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009880592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009880768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009885168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009886576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009939968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009939616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009938384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009938560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009946128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137821009945424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
          ]
        }
      ],
      "source": [
        "model.save('/content/drive/MyDrive/trained_models/meinMNIST_V1.h5')\n",
        "model.export('/content/drive/MyDrive/trained_models/meinMNIST_V1')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bHpc5dB3nznJ",
        "outputId": "a7af1b69-da06-4683-cffc-9fe1e8df71c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "acc = 0.98\n"
          ]
        }
      ],
      "source": [
        "# test the model\n",
        "_, acc = model.evaluate(x_test, y_test, verbose=0)\n",
        "\n",
        "print(\"acc = {:.2f}\".format(acc))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the image from the specified path and resize it to 28x28\n",
        "# Convert the image to an array\n",
        "img_array = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,110,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,11,147,180,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,44,253,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,188,209,43,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,69,192,0,0,0,0,0,0,35,51,0,65,124,124,124,77,0,0,0,0,0,0,0,0,0,0,0,0,140,190,0,0,0,26,202,202,216,223,196,216,253,253,253,233,202,0,0,0,0,0,0,0,0,0,0,26,187,34,52,22,0,184,216,217,253,253,128,131,253,253,253,253,179,0,0,0,0,0,0,0,0,0,0,189,253,187,217,52,0,172,45,46,69,69,7,36,215,248,253,182,21,0,0,0,0,0,0,0,0,0,55,242,204,51,165,34,0,0,0,0,0,0,0,0,13,162,253,156,0,0,0,0,0,0,0,0,0,0,158,253,113,0,0,0,0,0,0,0,0,0,0,0,36,253,253,156,0,0,0,0,0,0,0,0,0,126,250,193,4,0,0,0,0,0,0,0,0,0,0,128,247,142,8,5,0,0,0,0,0,0,0,0,0,254,253,191,0,0,0,0,0,0,0,0,0,0,134,203,128,57,0,0,0,0,0,0,0,0,0,0,0,255,253,204,24,0,0,0,0,0,0,0,52,156,250,225,34,0,0,0,0,0,0,0,0,0,0,0,0,254,253,253,185,18,0,0,0,0,46,131,249,175,122,59,0,0,0,0,0,0,0,0,0,0,0,0,0,219,240,253,253,186,36,175,211,211,225,115,43,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,158,146,202,253,253,253,253,249,138,48,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,4,34,212,235,235,235,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "img_array = np.array(img_array)\n",
        "\n",
        "# Changing the type of img_array to 'float32'\n",
        "img_array = img_array.astype('float32')/255\n",
        "# Reshaping the array into 28x28x1\n",
        "img_array= np.array(img_array).reshape(28, 28, 1)\n",
        "# Display the resized image\n",
        "\n",
        "plt.imshow(img_array.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Reshape the image to match the model's input requirements (1, 28, 28, 1)\n",
        "img_reshaped = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict using the reshaped image\n",
        "prediction = model.predict(img_reshaped)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Predictions (in percentages) for each class:\")\n",
        "for idx, prob in enumerate(prediction[0]):\n",
        "    print(f\"Class {idx}: {prob*100:.2f}%\")"
      ],
      "metadata": {
        "id": "ilkHpzGmW2sj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "a37ad40d-7424-4789-97af-1b2bb933ef4c"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step\n",
            "Predictions (in percentages) for each class:\n",
            "Class 0: 0.96%\n",
            "Class 1: 0.44%\n",
            "Class 2: 0.00%\n",
            "Class 3: 0.06%\n",
            "Class 4: 0.02%\n",
            "Class 5: 62.76%\n",
            "Class 6: 22.77%\n",
            "Class 7: 0.00%\n",
            "Class 8: 12.97%\n",
            "Class 9: 0.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "7FpJAw5jn0SI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "89999b71-1233-4883-ee48-223e329bc8f0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step\n",
            "Predictions (in percentages) for each class:\n",
            "Class 0: 0.02%\n",
            "Class 1: 0.00%\n",
            "Class 2: 0.00%\n",
            "Class 3: 1.00%\n",
            "Class 4: 0.00%\n",
            "Class 5: 98.91%\n",
            "Class 6: 0.05%\n",
            "Class 7: 0.00%\n",
            "Class 8: 0.00%\n",
            "Class 9: 0.01%\n"
          ]
        }
      ],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the image from the specified path and resize it to 28x28\n",
        "# Convert the image to an array\n",
        "img_array = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,122,121,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,254,253,249,241,241,241,241,241,241,241,242,114,108,108,178,85,0,0,0,0,0,0,0,0,0,0,0,0,254,253,253,253,253,253,253,253,253,253,254,253,253,253,253,199,0,0,0,0,0,0,0,0,0,0,0,0,104,173,173,173,194,253,253,253,253,253,254,253,253,253,253,199,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,68,253,253,253,253,253,223,186,186,143,124,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,96,253,253,253,250,128,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,13,209,253,253,235,75,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,73,248,253,253,243,161,161,98,2,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,124,253,253,253,253,253,254,152,147,35,14,4,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,32,120,211,253,253,253,254,253,253,253,253,165,42,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,79,134,192,254,254,254,254,254,255,169,115,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,6,13,132,180,253,253,253,253,245,108,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,26,54,224,253,253,253,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,60,199,253,253,253,0,0,0,0,0,0,0,0,0,0,0,100,201,158,0,0,0,0,0,0,61,68,173,240,253,253,253,218,0,0,0,0,0,0,0,0,0,0,20,222,253,239,96,54,54,125,188,187,247,253,253,253,253,253,243,31,0,0,0,0,0,0,0,0,0,0,80,247,253,253,253,253,253,253,255,253,253,253,253,245,213,199,75,0,0,0,0,0,0,0,0,0,0,0,0,192,233,253,253,253,253,253,255,253,243,226,121,74,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,29,205,240,240,162,107,107,107,67,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "img_array = np.array(img_array)\n",
        "\n",
        "# Changing the type of img_array to 'float32'\n",
        "img_array = img_array.astype('float32')/255\n",
        "# Reshaping the array into 28x28x1\n",
        "img_array= np.array(img_array).reshape(28, 28, 1)\n",
        "# Display the resized image\n",
        "\n",
        "plt.imshow(img_array.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Reshape the image to match the model's input requirements (1, 28, 28, 1)\n",
        "img_reshaped = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict using the reshaped image\n",
        "prediction = model.predict(img_reshaped)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Predictions (in percentages) for each class:\")\n",
        "for idx, prob in enumerate(prediction[0]):\n",
        "    print(f\"Class {idx}: {prob*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the image from the specified path and resize it to 28x28\n",
        "# Convert the image to an array\n",
        "img_array = [0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,84,185,159,151,60,36,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,222,254,254,254,254,241,198,198,198,198,198,198,198,198,170,52,0,0,0,0,0,0,0,0,0,0,0,0,67,114,72,114,163,227,254,225,254,254,254,250,229,254,254,140,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,17,66,14,67,67,67,59,21,236,254,106,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,83,253,209,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,22,233,255,83,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,129,254,238,44,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,59,249,254,62,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,187,5,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,9,205,248,58,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,126,254,182,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,75,251,240,57,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,19,221,254,166,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,3,203,254,219,35,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,38,254,254,77,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,31,224,254,115,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,133,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,61,242,254,254,52,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,254,219,40,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,121,254,207,18,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0]\n",
        "img_array = np.array(img_array)\n",
        "\n",
        "# Changing the type of img_array to 'float32'\n",
        "img_array = img_array.astype('float32')/255\n",
        "# Reshaping the array into 28x28x1\n",
        "img_array= np.array(img_array).reshape(28, 28, 1)\n",
        "# Display the resized image\n",
        "\n",
        "plt.imshow(img_array.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Reshape the image to match the model's input requirements (1, 28, 28, 1)\n",
        "img_reshaped = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict using the reshaped image\n",
        "prediction = model.predict(img_reshaped)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Predictions (in percentages) for each class:\")\n",
        "for idx, prob in enumerate(prediction[0]):\n",
        "    print(f\"Class {idx}: {prob*100:.2f}%\")"
      ],
      "metadata": {
        "id": "Ww5VbZZO4zx2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "outputId": "4cf77ab3-4a59-408a-d6ce-0dbc030d4e72"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step\n",
            "Predictions (in percentages) for each class:\n",
            "Class 0: 0.00%\n",
            "Class 1: 0.00%\n",
            "Class 2: 0.00%\n",
            "Class 3: 0.00%\n",
            "Class 4: 0.00%\n",
            "Class 5: 0.00%\n",
            "Class 6: 0.00%\n",
            "Class 7: 100.00%\n",
            "Class 8: 0.00%\n",
            "Class 9: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 638
        },
        "id": "Qsae-lgZUBrf",
        "outputId": "f1bd63de-ee8b-4b32-b101-4de8b66b617f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "Predictions (in percentages) for each class:\n",
            "Class 0: 0.00%\n",
            "Class 1: 0.00%\n",
            "Class 2: 99.94%\n",
            "Class 3: 0.00%\n",
            "Class 4: 0.00%\n",
            "Class 5: 0.00%\n",
            "Class 6: 0.05%\n",
            "Class 7: 0.00%\n",
            "Class 8: 0.00%\n",
            "Class 9: 0.00%\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "# Load the image from the specified path and resize it to 28x28\n",
        "img_path = \"/content/drive/MyDrive/RANDOM_IMAGE_FOR_TEST/Nummer_2.jpg\"\n",
        "img = load_img(img_path, color_mode='grayscale', target_size=(28, 28))\n",
        "\n",
        "# Convert the image to an array\n",
        "img_array = 255 - img_to_array(img) #invert the color\n",
        "\n",
        "img_array = (img_array).astype('float32')/255 #normalize the image\n",
        "\n",
        "# Reshaping the array into 28x28x1\n",
        "img_array= np.array(img_array).reshape(28, 28, 1)\n",
        "\n",
        "# Display the resized image\n",
        "plt.imshow(img_array.squeeze(), cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# Reshape the image to match the model's input requirements (1, 28, 28, 1)\n",
        "img_reshaped = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Predict using the reshaped image\n",
        "prediction = model.predict(img_reshaped)\n",
        "\n",
        "# Print the prediction\n",
        "print(\"Predictions (in percentages) for each class:\")\n",
        "for idx, prob in enumerate(prediction[0]):\n",
        "    print(f\"Class {idx}: {prob*100:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "saved_model_dir =\"/content/drive/MyDrive/trained_models/meinMNIST_V1\"\n",
        "\n",
        "TF_LITE_MODEL_FILE_NAME=\"/content/drive/MyDrive/trained_models/meinMNIST_V1.tflite\"\n",
        "# Define the representative dataset generation function\n",
        "def representative_data_gen():\n",
        "    for input_value in tf.data.Dataset.from_tensor_slices(np.random.rand(100, 28, 28,1).astype(np.float32)).batch(1).take(100):\n",
        "        yield [input_value]\n",
        "\n",
        "# Convert the saved model to a TFLite model with full integer quantization\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "converter.representative_dataset = representative_data_gen\n",
        "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
        "converter.inference_input_type = tf.int8  # Ensure the input type is int8 for quantization\n",
        "converter.inference_output_type = tf.int8  # Ensure the output type is int8 for quantization\n",
        "tflite_model = converter.convert()\n",
        "\n",
        "\n",
        "# Save the model.\n",
        "tflite_model_name = TF_LITE_MODEL_FILE_NAME\n",
        "open(tflite_model_name, \"wb\").write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S4WVCwY8Ifci",
        "outputId": "4e87ef57-3b35-47a4-eeab-dec8325f9cbc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "310136"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the quantized TFLite model\n",
        "interpreter = tf.lite.Interpreter(model_path=\"/content/drive/MyDrive/trained_models/meinMNIST_V1.tflite\")\n",
        "\n",
        "\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "\n",
        "# Adjust the model interpreter to take 10,000 inputs at once instead of just 1\n",
        "interpreter.resize_tensor_input(input_details[0][\"index\"], (10000, 28,28,1))\n",
        "interpreter.resize_tensor_input(output_details[0][\"index\"], (10000, 10))\n",
        "\n",
        "interpreter.allocate_tensors()\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "\n",
        "\n",
        "# Set the test input and run\n",
        "interpreter.set_tensor(input_details[0][\"index\"], (x_test*255+128).astype('int8')) # Cast x_test to float32\n",
        "interpreter.invoke()\n",
        "\n",
        "# Get the result and check its accuracy\n",
        "output_data = (interpreter.get_tensor(output_details[0][\"index\"]))\n",
        "y_test = y_test.astype(np.uint8)\n",
        "\n",
        "predicted_classes = [np.argmax(y, axis=None, out=None) for y in output_data]\n",
        "true_classes = [np.argmax(y, axis=None, out=None) for y in y_test]\n",
        "\n",
        "accuracy = (np.array(predicted_classes) == np.array(true_classes)).mean()\n",
        "print(\"TFLite Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C8et5KqxLEAk",
        "outputId": "728a6320-b4ff-444d-db9b-b31759a3228e"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TFLite Accuracy: 0.9844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "UJFXEDJZ0Jf8"
      },
      "outputs": [],
      "source": [
        "def print_zeropoints_und_scaled(interpreter):\n",
        "  input_details = interpreter.get_input_details()\n",
        "  output_details = interpreter.get_output_details()\n",
        "  print(\"Input scale, zero_point = {}, {}\".format(input_details[0]['quantization'][0], input_details[0]['quantization'][1]))\n",
        "  print(\"Output scale, zero_point = {}, {}\".format(output_details[0]['quantization'][0], output_details[0]['quantization'][1]))\n",
        "\n",
        "def print_all_tensor_details(interpreter):\n",
        "  tensor_details = interpreter.get_tensor_details()\n",
        "  for tensor in tensor_details:\n",
        "    print(tensor)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_zeropoints_und_scaled(interpreter)"
      ],
      "metadata": {
        "id": "-qilonUJGe57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23a0a5b1-8efd-4173-b147-0038bba640ea"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input scale, zero_point = 0.0039215655997395515, -128\n",
            "Output scale, zero_point = 0.00390625, -128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print_all_tensor_details(interpreter)"
      ],
      "metadata": {
        "id": "Ob4_qlRMGew0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d386860f-b739-4c65-a38f-97860cfbe8d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'serving_default_keras_tensor_85:0', 'index': 0, 'shape': array([10000,    28,    28,     1], dtype=int32), 'shape_signature': array([-1, 28, 28,  1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0039215655997395515, -128), 'quantization_parameters': {'scales': array([0.00392157], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'arith.constant', 'index': 1, 'shape': array([2], dtype=int32), 'shape_signature': array([2], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst', 'index': 2, 'shape': array([10], dtype=int32), 'shape_signature': array([10], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (4.9423037125961855e-05, 0), 'quantization_parameters': {'scales': array([4.9423037e-05], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst1', 'index': 3, 'shape': array([ 10, 256], dtype=int32), 'shape_signature': array([ 10, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.005580682773143053, 0), 'quantization_parameters': {'scales': array([0.00558068], dtype=float32), 'zero_points': array([0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst2', 'index': 4, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.40824680e-06, 7.60014245e-06, 9.38061021e-06, 6.79454206e-06,\n",
            "       8.08112418e-06, 7.62457557e-06, 1.37121533e-05, 1.21181756e-05,\n",
            "       1.10131141e-05, 1.08355625e-05, 1.49581383e-05, 9.86271152e-06,\n",
            "       6.02971568e-06, 8.86840007e-06, 1.24466960e-05, 1.52983102e-05,\n",
            "       1.40220955e-05, 1.37626912e-05, 1.03841376e-05, 1.22087558e-05,\n",
            "       8.60121418e-06, 8.40080429e-06, 5.02252624e-06, 9.34540640e-06,\n",
            "       1.22786405e-05, 1.16782830e-05, 1.30263261e-05, 8.46576313e-06,\n",
            "       8.28963130e-06, 1.52376351e-05, 1.26255636e-05, 1.13783799e-05,\n",
            "       1.59756819e-05, 1.32778760e-05, 1.22075608e-05, 9.49047990e-06,\n",
            "       7.73165539e-06, 1.36397866e-05, 1.12880289e-05, 2.18417063e-05,\n",
            "       1.16503579e-05, 1.45562171e-05, 1.47596247e-05, 1.08303193e-05,\n",
            "       6.31986950e-06, 8.82204040e-06, 8.13471343e-06, 1.05303370e-05,\n",
            "       1.42419312e-05, 1.70303938e-05, 8.98759481e-06, 1.43669531e-05,\n",
            "       1.28176343e-05, 1.29708051e-05, 1.52557504e-05, 1.13442711e-05,\n",
            "       1.18359749e-05, 1.12877206e-05, 6.30043542e-06, 2.17221768e-05,\n",
            "       1.22790298e-05, 3.97186932e-06, 1.00756188e-05, 9.96145354e-06,\n",
            "       9.15760575e-06, 1.28520269e-05, 8.98007693e-06, 1.34880702e-05,\n",
            "       1.25141414e-05, 1.17820700e-05, 5.37950655e-06, 1.43566585e-05,\n",
            "       1.67454418e-05, 1.02637941e-05, 1.18532644e-05, 1.03282000e-05,\n",
            "       1.12979114e-05, 1.65688671e-05, 1.76449030e-05, 9.07479898e-06,\n",
            "       1.04271421e-05, 1.07523274e-05, 9.95782648e-06, 1.27123612e-05,\n",
            "       1.51247623e-05, 2.15382679e-05, 9.62716240e-06, 9.05759953e-06,\n",
            "       9.44134990e-06, 1.20639161e-05, 9.16138379e-06, 8.09672383e-06,\n",
            "       1.11384543e-05, 1.13767774e-05, 1.43138204e-05, 8.16273950e-06,\n",
            "       2.03464042e-05, 5.99945315e-06, 6.37500125e-06, 1.60402524e-05,\n",
            "       1.14341638e-05, 5.81716586e-06, 1.45639879e-05, 8.69043652e-06,\n",
            "       1.04286028e-05, 1.19653296e-05, 1.02752856e-05, 8.96440906e-06,\n",
            "       1.12912785e-05, 9.42749921e-06, 1.42004328e-05, 1.02093618e-05,\n",
            "       1.24781909e-05, 1.09859729e-05, 3.85416297e-06, 1.24717681e-05,\n",
            "       7.35874983e-06, 1.06895695e-05, 8.90560659e-06, 1.02780295e-05,\n",
            "       5.36484822e-06, 6.55281929e-06, 8.39892164e-06, 6.92503681e-06,\n",
            "       1.09088351e-05, 1.32529194e-05, 3.86917418e-06, 6.72130363e-06,\n",
            "       1.01549413e-05, 6.30556451e-06, 1.04904047e-05, 8.82773929e-06,\n",
            "       5.48485059e-06, 1.03043558e-05, 1.43920233e-05, 9.19794002e-06,\n",
            "       1.20147561e-05, 9.45121155e-06, 1.31981296e-05, 1.49184343e-05,\n",
            "       8.06558546e-06, 1.20854984e-05, 9.53097788e-06, 1.20264031e-05,\n",
            "       8.39988115e-06, 1.12346061e-05, 1.57779632e-05, 1.34100164e-05,\n",
            "       1.45269851e-05, 7.00859482e-06, 6.14338978e-06, 1.17769296e-05,\n",
            "       1.07394299e-05, 8.16023203e-06, 8.48668424e-06, 9.09099981e-06,\n",
            "       3.75859599e-06, 9.65210438e-06, 7.28396253e-06, 1.52281282e-05,\n",
            "       1.10513838e-05, 1.30039061e-05, 6.69279052e-06, 1.57729773e-05,\n",
            "       1.08613995e-05, 1.13617489e-05, 9.24253436e-06, 1.02494187e-05,\n",
            "       1.12845228e-05, 9.60661691e-06, 3.79130779e-06, 8.07394281e-06,\n",
            "       1.20716286e-05, 1.02193671e-05, 2.03376239e-05, 1.24361322e-05,\n",
            "       7.68565678e-06, 1.80131519e-05, 5.81822951e-06, 8.38850428e-06,\n",
            "       1.02220447e-05, 9.25709355e-06, 6.37669746e-06, 1.11086110e-05,\n",
            "       1.04104511e-05, 1.14757595e-05, 1.17748850e-05, 1.50490059e-05,\n",
            "       6.67181030e-06, 1.20051036e-05, 1.27251760e-05, 1.02017493e-05,\n",
            "       9.87306339e-06, 9.94621314e-06, 1.00683274e-05, 1.36972458e-05,\n",
            "       1.35053297e-05, 1.03060147e-05, 8.53522215e-06, 9.59190402e-06,\n",
            "       1.35778000e-05, 9.33306092e-06, 7.78505091e-06, 9.48910110e-06,\n",
            "       1.14858140e-05, 1.37160723e-05, 1.36006820e-05, 9.11267216e-06,\n",
            "       1.36167582e-05, 1.19692722e-05, 8.37265543e-06, 1.13925526e-05,\n",
            "       1.21511966e-05, 1.22469564e-05, 1.06792104e-05, 1.20525519e-05,\n",
            "       8.23793653e-06, 6.87917782e-06, 8.43283578e-06, 6.56384009e-06,\n",
            "       1.13712649e-05, 1.24471171e-05, 1.11599520e-05, 7.83181895e-06,\n",
            "       4.25515401e-09, 1.00664656e-05, 7.16998420e-06, 1.06517155e-05,\n",
            "       1.01513315e-05, 1.22067031e-05, 9.39485471e-06, 1.11732479e-05,\n",
            "       9.72733415e-06, 1.34396014e-05, 1.23651580e-05, 1.14205577e-05,\n",
            "       1.38053501e-05, 1.42930066e-05, 1.06505686e-05, 1.09076900e-05,\n",
            "       1.27852873e-05, 9.49386231e-06, 1.52684370e-05, 1.39809645e-05,\n",
            "       1.06532725e-05, 8.96220354e-06, 4.64698405e-06, 1.09401553e-05,\n",
            "       9.55116047e-06, 7.79522907e-06, 9.85515453e-06, 1.29881300e-05,\n",
            "       1.21897074e-05, 1.10855444e-05, 1.02874365e-05, 9.19228842e-06],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst3', 'index': 5, 'shape': array([256,   1,   1, 256], dtype=int32), 'shape_signature': array([256,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.1676172e-03, 1.1978620e-03, 1.4784823e-03, 1.0708909e-03,\n",
            "       1.2736697e-03, 1.2017129e-03, 2.1611787e-03, 1.9099512e-03,\n",
            "       1.7357820e-03, 1.7077980e-03, 2.3575590e-03, 1.5544666e-03,\n",
            "       9.5034624e-04, 1.3977527e-03, 1.9617295e-03, 2.4111737e-03,\n",
            "       2.2100289e-03, 2.1691441e-03, 1.6366487e-03, 1.9242276e-03,\n",
            "       1.3556413e-03, 1.3240547e-03, 7.9160265e-04, 1.4729338e-03,\n",
            "       1.9352422e-03, 1.8406195e-03, 2.0530852e-03, 1.3342928e-03,\n",
            "       1.3065326e-03, 2.4016106e-03, 1.9899209e-03, 1.7933517e-03,\n",
            "       2.5179344e-03, 2.0927321e-03, 1.9240392e-03, 1.4957989e-03,\n",
            "       1.2185897e-03, 2.1497731e-03, 1.7791115e-03, 3.4424814e-03,\n",
            "       1.8362183e-03, 2.2942121e-03, 2.3262713e-03, 1.7069717e-03,\n",
            "       9.9607755e-04, 1.3904459e-03, 1.2821159e-03, 1.6596912e-03,\n",
            "       2.2446774e-03, 2.6841681e-03, 1.4165390e-03, 2.2643821e-03,\n",
            "       2.0201933e-03, 2.0443345e-03, 2.4044658e-03, 1.7879758e-03,\n",
            "       1.8654735e-03, 1.7790628e-03, 9.9301455e-04, 3.4236421e-03,\n",
            "       1.9353036e-03, 6.2600814e-04, 1.5880229e-03, 1.5700293e-03,\n",
            "       1.4433345e-03, 2.0256138e-03, 1.4153541e-03, 2.1258609e-03,\n",
            "       1.9723596e-03, 1.8569775e-03, 8.4786647e-04, 2.2627595e-03,\n",
            "       2.6392569e-03, 1.6176814e-03, 1.8681985e-03, 1.6278324e-03,\n",
            "       1.7806690e-03, 2.6114266e-03, 2.7810212e-03, 1.4302832e-03,\n",
            "       1.6434266e-03, 1.6946793e-03, 1.5694576e-03, 2.0036011e-03,\n",
            "       2.3838207e-03, 3.3946563e-03, 1.5173415e-03, 1.4275725e-03,\n",
            "       1.4880555e-03, 1.9013993e-03, 1.4439299e-03, 1.2761283e-03,\n",
            "       1.7555369e-03, 1.7930991e-03, 2.2560079e-03, 1.2865332e-03,\n",
            "       3.2068063e-03, 9.4557658e-04, 1.0047669e-03, 2.5281115e-03,\n",
            "       1.8021438e-03, 9.1684615e-04, 2.2954368e-03, 1.3697037e-03,\n",
            "       1.6436569e-03, 1.8858610e-03, 1.6194924e-03, 1.4128847e-03,\n",
            "       1.7796236e-03, 1.4858725e-03, 2.2381367e-03, 1.6091022e-03,\n",
            "       1.9666934e-03, 1.7315042e-03, 6.0745637e-04, 1.9656811e-03,\n",
            "       1.1598159e-03, 1.6847879e-03, 1.4036167e-03, 1.6199249e-03,\n",
            "       8.4555621e-04, 1.0327928e-03, 1.3237579e-03, 1.0914583e-03,\n",
            "       1.7193465e-03, 2.0887987e-03, 6.0982234e-04, 1.0593478e-03,\n",
            "       1.6005250e-03, 9.9382293e-04, 1.6533976e-03, 1.3913440e-03,\n",
            "       8.6446980e-04, 1.6240743e-03, 2.2683335e-03, 1.4496916e-03,\n",
            "       1.8936512e-03, 1.4896098e-03, 2.0801632e-03, 2.3513013e-03,\n",
            "       1.2712206e-03, 1.9048010e-03, 1.5021818e-03, 1.8954868e-03,\n",
            "       1.3239091e-03, 1.7706915e-03, 2.4867719e-03, 2.1135588e-03,\n",
            "       2.2896049e-03, 1.1046279e-03, 9.6826250e-04, 1.8561672e-03,\n",
            "       1.6926465e-03, 1.2861380e-03, 1.3375902e-03, 1.4328366e-03,\n",
            "       5.9239403e-04, 1.5212726e-03, 1.1480286e-03, 2.4001123e-03,\n",
            "       1.7418136e-03, 2.0495516e-03, 1.0548538e-03, 2.4859863e-03,\n",
            "       1.7118702e-03, 1.7907304e-03, 1.4567201e-03, 1.6154156e-03,\n",
            "       1.7785588e-03, 1.5141033e-03, 5.9754978e-04, 1.2725379e-03,\n",
            "       1.9026150e-03, 1.6106791e-03, 3.2054223e-03, 1.9600645e-03,\n",
            "       1.2113398e-03, 2.8390612e-03, 9.1701385e-04, 1.3221160e-03,\n",
            "       1.6111011e-03, 1.4590147e-03, 1.0050342e-03, 1.7508334e-03,\n",
            "       1.6407960e-03, 1.8086997e-03, 1.8558451e-03, 2.3718807e-03,\n",
            "       1.0515471e-03, 1.8921299e-03, 2.0056209e-03, 1.6079025e-03,\n",
            "       1.5560980e-03, 1.5676272e-03, 1.5868737e-03, 2.1588292e-03,\n",
            "       2.1285813e-03, 1.6243358e-03, 1.3452403e-03, 1.5117844e-03,\n",
            "       2.1400033e-03, 1.4709880e-03, 1.2270055e-03, 1.4955816e-03,\n",
            "       1.8102844e-03, 2.1617964e-03, 2.1436098e-03, 1.4362524e-03,\n",
            "       2.1461435e-03, 1.8864825e-03, 1.3196181e-03, 1.7955855e-03,\n",
            "       1.9151557e-03, 1.9302485e-03, 1.6831553e-03, 1.8996083e-03,\n",
            "       1.2983850e-03, 1.0842304e-03, 1.3291031e-03, 1.0345299e-03,\n",
            "       1.7922303e-03, 1.9617958e-03, 1.7589252e-03, 1.2343766e-03,\n",
            "       6.7065679e-07, 1.5865803e-03, 1.1300645e-03, 1.6788217e-03,\n",
            "       1.5999560e-03, 1.9239041e-03, 1.4807273e-03, 1.7610207e-03,\n",
            "       1.5331296e-03, 2.1182217e-03, 1.9488782e-03, 1.7999994e-03,\n",
            "       2.1758676e-03, 2.2527273e-03, 1.6786410e-03, 1.7191661e-03,\n",
            "       2.0150950e-03, 1.4963320e-03, 2.4064654e-03, 2.2035462e-03,\n",
            "       1.6790672e-03, 1.4125369e-03, 7.3241326e-04, 1.7242829e-03,\n",
            "       1.5053628e-03, 1.2286097e-03, 1.5532754e-03, 2.0470652e-03,\n",
            "       1.9212253e-03, 1.7471977e-03, 1.6214076e-03, 1.4488008e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst4', 'index': 6, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.34696584e-11, 3.71110018e-11, 9.96206218e-05, 3.71110018e-11,\n",
            "       7.72732434e-10, 1.81580413e-04, 1.50735388e-04, 3.71110018e-11,\n",
            "       7.34217974e-05, 1.09229455e-04, 3.71110018e-11, 3.71110018e-11,\n",
            "       1.17111536e-04, 3.71110018e-11, 3.71110018e-11, 3.71110018e-11,\n",
            "       9.59097015e-05, 8.73668905e-05, 1.11334484e-05, 8.30763602e-05,\n",
            "       3.71110018e-11, 1.75361216e-04, 3.71110018e-11, 1.64310011e-04,\n",
            "       3.71110018e-11, 3.71110018e-11, 4.46219173e-11, 5.64620848e-07,\n",
            "       1.51361675e-07, 1.63679972e-04, 2.85847909e-05, 1.29159889e-04,\n",
            "       3.71110018e-11, 4.66766542e-05, 3.71110018e-11, 2.25601234e-05,\n",
            "       3.71110018e-11, 1.13602852e-08, 3.71110018e-11, 2.76420942e-05,\n",
            "       8.39514105e-05, 6.63892351e-05, 4.71078489e-11, 7.14805137e-05,\n",
            "       3.04947184e-06, 1.09718394e-08, 3.71110018e-11, 3.71110018e-11,\n",
            "       8.53004967e-05, 6.90672823e-05, 3.71110018e-11, 3.71110018e-11,\n",
            "       3.71110018e-11, 9.78270400e-05, 7.55212559e-11, 3.71110018e-11,\n",
            "       6.79891964e-05, 3.71110018e-11, 1.38093572e-04, 9.34630880e-05,\n",
            "       1.20680252e-05, 3.71110018e-11, 3.71110018e-11, 3.71110018e-11,\n",
            "       9.88428219e-05, 7.58433016e-05, 7.51309781e-05, 5.11785614e-11,\n",
            "       6.84885745e-05, 1.08548236e-04, 2.70026044e-06, 9.50818139e-05,\n",
            "       1.11941088e-04, 2.23476354e-06, 3.71110018e-11, 8.21525603e-08,\n",
            "       8.78515930e-05, 1.21969613e-04, 3.71110018e-11, 3.71110018e-11,\n",
            "       1.17644922e-10, 6.96529014e-06, 1.50126201e-04, 1.34646834e-04,\n",
            "       5.16935434e-05, 7.35906838e-08, 3.71110018e-11, 1.07416468e-04,\n",
            "       2.89547570e-05, 3.71110018e-11, 9.42636761e-05, 5.22129449e-05,\n",
            "       8.71888842e-05, 1.49496525e-04, 3.71110018e-11, 8.85584314e-11,\n",
            "       3.71110018e-11, 1.13189300e-04, 6.62558232e-05, 4.92411573e-06,\n",
            "       6.73603812e-11, 4.65345262e-11, 3.71110018e-11, 3.71110018e-11,\n",
            "       9.29399976e-05, 3.71110018e-11, 3.71110018e-11, 3.71110018e-11,\n",
            "       1.59982889e-07, 1.52722043e-06, 2.30404098e-07, 3.69260715e-06,\n",
            "       3.71110018e-11, 3.49593734e-07, 5.65899541e-07, 3.71869078e-07,\n",
            "       3.23187948e-07, 9.29685995e-10, 6.75682531e-05, 5.59931432e-05,\n",
            "       3.71110018e-11, 1.54117372e-10, 1.00047087e-04, 1.90436526e-06,\n",
            "       8.64824397e-05, 4.13600246e-05, 3.71110018e-11, 2.75755099e-08,\n",
            "       3.71110018e-11, 1.06279265e-04, 1.03359336e-04, 8.84583351e-05,\n",
            "       3.62693015e-07, 1.05607051e-10, 3.71110018e-11, 9.05072884e-05,\n",
            "       3.71110018e-11, 9.63994244e-05, 6.20881263e-11, 8.58353985e-07,\n",
            "       1.36084297e-10, 3.71110018e-11, 1.96360289e-10, 1.52290711e-04,\n",
            "       3.71110018e-11, 4.52164295e-06, 1.80228642e-04, 4.44808137e-07,\n",
            "       8.02259092e-05, 1.11912217e-04, 3.71110018e-11, 3.71110018e-11,\n",
            "       9.52520495e-05, 1.91840869e-07, 2.64480313e-05, 3.71110018e-11,\n",
            "       4.81393784e-07, 3.71110018e-11, 1.07992055e-04, 9.33347328e-05,\n",
            "       6.35168399e-05, 8.29053242e-05, 3.71110018e-11, 5.97071448e-05,\n",
            "       2.51410370e-07, 3.71110018e-11, 8.60213913e-06, 1.18594414e-06,\n",
            "       1.03432460e-04, 3.71110018e-11, 5.25103189e-07, 3.71110018e-11,\n",
            "       4.49578984e-05, 7.11532877e-08, 5.19446812e-11, 9.15399214e-05,\n",
            "       1.89573440e-10, 7.13576519e-05, 3.71110018e-11, 7.94721564e-05,\n",
            "       1.53741508e-09, 3.27351736e-05, 5.63435236e-08, 7.83114407e-11,\n",
            "       1.15220304e-04, 6.43393949e-11, 6.55008407e-05, 3.71110018e-11,\n",
            "       3.71110018e-11, 5.06076105e-07, 1.06080683e-04, 8.04820520e-05,\n",
            "       1.00634679e-06, 3.71110018e-11, 4.50461108e-08, 1.04018138e-04,\n",
            "       3.71110018e-11, 3.71110018e-11, 3.85265935e-07, 3.71110018e-11,\n",
            "       7.53638305e-05, 1.03710874e-04, 3.71110018e-11, 6.98259391e-05,\n",
            "       3.71110018e-11, 3.71110018e-11, 3.71110018e-11, 9.17807635e-11,\n",
            "       3.71110018e-11, 3.71110018e-11, 4.42943668e-11, 1.68505998e-04,\n",
            "       3.71110018e-11, 8.72728851e-05, 3.71110018e-11, 2.32427013e-07,\n",
            "       7.48942693e-05, 1.12203466e-04, 3.71110018e-11, 8.14796804e-05,\n",
            "       1.19155782e-04, 1.06465251e-07, 4.25970537e-10, 4.02146545e-11,\n",
            "       3.71110018e-11, 3.73222065e-06, 2.93133451e-09, 7.08664794e-11,\n",
            "       7.21063116e-05, 3.25388044e-07, 3.71110018e-11, 3.71110018e-11,\n",
            "       5.47736440e-11, 1.98208772e-06, 5.71957759e-11, 3.99327099e-11,\n",
            "       3.71110018e-11, 3.71110018e-11, 5.64801085e-05, 3.71110018e-11,\n",
            "       7.28358355e-05, 5.93071564e-11, 3.71110018e-11, 1.09088476e-04,\n",
            "       9.26485882e-05, 1.21987087e-10, 3.27038086e-09, 6.67182321e-05,\n",
            "       1.09173088e-04, 6.49886767e-09, 1.88394811e-08, 1.08255183e-04,\n",
            "       1.61204662e-04, 1.07876211e-07, 1.41437369e-04, 2.90323205e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst5', 'index': 7, 'shape': array([  1,   3,   3, 256], dtype=int32), 'shape_signature': array([  1,   3,   3, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.61158089e-09, 3.93700805e-09, 1.05684884e-02, 3.93700805e-09,\n",
            "       8.19771415e-08, 1.92633849e-02, 1.59911178e-02, 3.93700805e-09,\n",
            "       7.78912427e-03, 1.15878638e-02, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.24240527e-02, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.01748062e-02, 9.26852226e-03, 1.18111807e-03, 8.81335139e-03,\n",
            "       3.93700805e-09, 1.86036080e-02, 3.93700805e-09, 1.74312145e-02,\n",
            "       3.93700805e-09, 3.93700805e-09, 4.73382089e-09, 5.98991319e-05,\n",
            "       1.60575601e-05, 1.73643753e-02, 3.03248479e-03, 1.37022305e-02,\n",
            "       3.93700805e-09, 4.95180255e-03, 3.93700805e-09, 2.39334372e-03,\n",
            "       3.93700805e-09, 1.20518257e-06, 3.93700805e-09, 2.93247658e-03,\n",
            "       8.90618283e-03, 7.04305852e-03, 4.99754682e-09, 7.58317858e-03,\n",
            "       3.23510409e-04, 1.16397337e-06, 3.93700805e-09, 3.93700805e-09,\n",
            "       9.04930383e-03, 7.32716545e-03, 3.93700805e-09, 3.93700805e-09,\n",
            "       3.93700805e-09, 1.03782117e-02, 8.01184985e-09, 3.93700805e-09,\n",
            "       7.21279392e-03, 3.93700805e-09, 1.46499816e-02, 9.91525128e-03,\n",
            "       1.28026481e-03, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.04859732e-02, 8.04601517e-03, 7.97044672e-03, 5.42939826e-09,\n",
            "       7.26577174e-03, 1.15155950e-02, 2.86463473e-04, 1.00869779e-02,\n",
            "       1.18755335e-02, 2.37080152e-04, 3.93700805e-09, 8.71534758e-06,\n",
            "       9.31994338e-03, 1.29394336e-02, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.24806387e-08, 7.38929200e-04, 1.59264915e-02, 1.42843267e-02,\n",
            "       5.48403105e-03, 7.80704067e-06, 3.93700805e-09, 1.13955289e-02,\n",
            "       3.07173352e-03, 3.93700805e-09, 1.00001842e-02, 5.53913321e-03,\n",
            "       9.24963783e-03, 1.58596914e-02, 3.93700805e-09, 9.39492928e-09,\n",
            "       3.93700805e-09, 1.20079536e-02, 7.02890521e-03, 5.22386399e-04,\n",
            "       7.14608461e-09, 4.93672481e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       9.85975843e-03, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.69721607e-05, 1.62018769e-04, 2.44429611e-05, 3.91738926e-04,\n",
            "       3.93700805e-09, 3.70874732e-05, 6.00347848e-05, 3.94506060e-05,\n",
            "       3.42861531e-05, 9.86279289e-08, 7.16813747e-03, 5.94016444e-03,\n",
            "       3.93700805e-09, 1.63499045e-08, 1.06137311e-02, 2.02029070e-04,\n",
            "       9.17469338e-03, 4.38777544e-03, 3.93700805e-09, 2.92541290e-06,\n",
            "       3.93700805e-09, 1.12748863e-02, 1.09651182e-02, 9.38431080e-03,\n",
            "       3.84771411e-05, 1.12035723e-08, 3.93700805e-09, 9.60167870e-03,\n",
            "       3.93700805e-09, 1.02267601e-02, 6.58676491e-09, 9.10605013e-05,\n",
            "       1.44368233e-08, 3.93700805e-09, 2.08313438e-08, 1.61561184e-02,\n",
            "       3.93700805e-09, 4.79689130e-04, 1.91199798e-02, 4.71885178e-05,\n",
            "       8.51095468e-03, 1.18724713e-02, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.01050381e-02, 2.03518903e-05, 2.80580157e-03, 3.93700805e-09,\n",
            "       5.10697937e-05, 3.93700805e-09, 1.14565911e-02, 9.90163442e-03,\n",
            "       6.73833350e-03, 8.79520644e-03, 3.93700805e-09, 6.33417303e-03,\n",
            "       2.66714615e-05, 3.93700805e-09, 9.12578194e-04, 1.25813676e-04,\n",
            "       1.09728761e-02, 3.93700805e-09, 5.57068051e-05, 3.93700805e-09,\n",
            "       4.76946449e-03, 7.54846405e-06, 5.51067370e-09, 9.71122831e-03,\n",
            "       2.01113437e-08, 7.57014472e-03, 3.93700805e-09, 8.43099039e-03,\n",
            "       1.63100296e-07, 3.47278803e-03, 5.97733515e-06, 8.30785307e-09,\n",
            "       1.22234169e-02, 6.82559609e-09, 6.94881054e-03, 3.93700805e-09,\n",
            "       3.93700805e-09, 5.36882762e-05, 1.12538189e-02, 8.53812788e-03,\n",
            "       1.06760664e-04, 3.93700805e-09, 4.77882259e-06, 1.10350093e-02,\n",
            "       3.93700805e-09, 3.93700805e-09, 4.08718442e-05, 3.93700805e-09,\n",
            "       7.99514912e-03, 1.10024121e-02, 3.93700805e-09, 7.40764895e-03,\n",
            "       3.93700805e-09, 3.93700805e-09, 3.93700805e-09, 9.73677849e-09,\n",
            "       3.93700805e-09, 3.93700805e-09, 4.69907224e-09, 1.78763550e-02,\n",
            "       3.93700805e-09, 9.25854966e-03, 3.93700805e-09, 2.46575673e-05,\n",
            "       7.94533454e-03, 1.19033689e-02, 3.93700805e-09, 8.64396337e-03,\n",
            "       1.26409214e-02, 1.12946163e-05, 4.51900881e-08, 4.26626645e-09,\n",
            "       3.93700805e-09, 3.95941403e-04, 3.10977526e-07, 7.51803686e-09,\n",
            "       7.64956791e-03, 3.45195549e-05, 3.93700805e-09, 3.93700805e-09,\n",
            "       5.81079096e-09, 2.10274447e-04, 6.06774853e-09, 4.23635571e-09,\n",
            "       3.93700805e-09, 3.93700805e-09, 5.99182537e-03, 3.93700805e-09,\n",
            "       7.72696082e-03, 6.29173913e-09, 3.93700805e-09, 1.15729077e-02,\n",
            "       9.82884318e-03, 1.29412872e-08, 3.46946052e-07, 7.07796030e-03,\n",
            "       1.15818838e-02, 6.89447688e-07, 1.99863075e-06, 1.14845056e-02,\n",
            "       1.71017759e-02, 1.14443019e-05, 1.50047159e-02, 3.07996199e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst6', 'index': 8, 'shape': array([256], dtype=int32), 'shape_signature': array([256], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.32579736e-11, 3.33401882e-11, 8.13581482e-06, 3.33401882e-11,\n",
            "       6.39612668e-11, 6.92593176e-06, 8.09123594e-06, 3.33401882e-11,\n",
            "       1.47520632e-05, 8.44715851e-06, 3.33401882e-11, 3.33401882e-11,\n",
            "       9.31499471e-06, 3.33401882e-11, 3.33401882e-11, 3.33401882e-11,\n",
            "       1.08279673e-05, 1.06732987e-05, 5.41269003e-07, 1.40050561e-05,\n",
            "       3.57031384e-11, 1.14609302e-05, 3.33401882e-11, 1.55830894e-05,\n",
            "       3.33401882e-11, 3.33401882e-11, 6.87039869e-11, 8.74697051e-11,\n",
            "       1.38036305e-09, 1.00493589e-05, 7.20790513e-06, 1.17943000e-05,\n",
            "       3.33401882e-11, 1.48346580e-05, 3.33401882e-11, 8.37739299e-06,\n",
            "       3.33401882e-11, 7.10408607e-11, 3.33401882e-11, 7.95856795e-06,\n",
            "       1.28008642e-05, 1.21161311e-05, 3.33401882e-11, 1.54078662e-05,\n",
            "       9.93877507e-07, 5.92028163e-11, 3.33401882e-11, 3.33401882e-11,\n",
            "       1.73158642e-05, 1.29618456e-05, 3.33401882e-11, 3.33401882e-11,\n",
            "       3.33401882e-11, 1.37261732e-05, 9.59053878e-11, 3.33401882e-11,\n",
            "       1.16748488e-05, 3.33401882e-11, 1.23258615e-05, 9.28649297e-06,\n",
            "       7.76682828e-06, 3.33401882e-11, 3.33401882e-11, 3.33401882e-11,\n",
            "       1.25141660e-05, 1.31436082e-05, 1.02817148e-05, 4.04857432e-11,\n",
            "       1.01776886e-05, 1.20903987e-05, 1.16640198e-10, 1.46956627e-05,\n",
            "       7.51561083e-06, 4.48860601e-06, 3.33401882e-11, 1.74751269e-10,\n",
            "       1.09412567e-05, 1.25061797e-05, 3.33401882e-11, 3.33401882e-11,\n",
            "       6.64020089e-11, 3.66298636e-08, 1.09334278e-05, 8.46331295e-06,\n",
            "       7.19789841e-06, 3.33401882e-11, 3.33401882e-11, 1.05017234e-05,\n",
            "       9.60054149e-06, 5.13181199e-11, 1.49916013e-05, 5.93032928e-06,\n",
            "       9.20766342e-06, 1.45896411e-05, 3.77424585e-11, 3.64852697e-11,\n",
            "       7.84067533e-11, 1.19011047e-05, 1.33140175e-05, 1.56458427e-05,\n",
            "       3.33401882e-11, 5.96330832e-11, 3.33401882e-11, 8.09073780e-11,\n",
            "       7.27113002e-06, 3.33401882e-11, 3.33401882e-11, 3.33401882e-11,\n",
            "       9.73108035e-06, 1.48541257e-09, 3.33401882e-11, 7.86605087e-11,\n",
            "       3.33401882e-11, 7.07323989e-06, 1.28213460e-05, 6.08593384e-11,\n",
            "       4.49395884e-06, 1.12431106e-10, 9.76845968e-06, 7.91989896e-06,\n",
            "       3.33401882e-11, 1.37796830e-10, 1.08846652e-05, 1.25519591e-05,\n",
            "       1.28953097e-05, 1.03745633e-05, 3.33401882e-11, 8.61605856e-11,\n",
            "       3.33401882e-11, 1.11233503e-05, 1.14178911e-05, 1.08208515e-05,\n",
            "       1.31380323e-10, 3.33401882e-11, 3.33401882e-11, 1.23105765e-05,\n",
            "       3.86574071e-11, 1.03909115e-05, 3.33401882e-11, 5.48713575e-11,\n",
            "       9.99665073e-11, 3.33401882e-11, 3.95331719e-11, 7.83754058e-06,\n",
            "       3.33401882e-11, 4.17246338e-06, 8.01068472e-06, 9.05182151e-06,\n",
            "       8.77540697e-06, 1.08922541e-05, 3.33401882e-11, 3.33401882e-11,\n",
            "       8.73053523e-06, 3.75484331e-11, 5.57820670e-07, 3.33401882e-11,\n",
            "       1.40621351e-05, 3.33401882e-11, 1.03581851e-05, 1.15871762e-05,\n",
            "       1.22830079e-05, 1.50211517e-05, 3.33401882e-11, 1.06049683e-05,\n",
            "       1.60530964e-10, 3.33401882e-11, 2.49563037e-10, 9.74397972e-06,\n",
            "       1.59557694e-05, 3.33401882e-11, 3.65413394e-11, 3.33401882e-11,\n",
            "       1.19820361e-05, 4.50394895e-11, 3.33401882e-11, 1.77745842e-05,\n",
            "       7.97384797e-11, 1.40031270e-05, 3.33401882e-11, 1.27740659e-05,\n",
            "       6.33854982e-11, 8.29411692e-06, 1.85163190e-10, 6.15689028e-11,\n",
            "       1.39456506e-05, 6.17109558e-11, 9.93627600e-06, 4.31409353e-11,\n",
            "       3.33401882e-11, 1.20367868e-10, 1.70030798e-05, 1.13513515e-05,\n",
            "       3.88899579e-10, 3.33401882e-11, 2.07259383e-08, 9.73811802e-06,\n",
            "       3.33401882e-11, 3.33401882e-11, 1.00676766e-10, 3.33401882e-11,\n",
            "       1.55374291e-05, 6.87799638e-06, 3.33401882e-11, 1.66606951e-05,\n",
            "       9.47015660e-11, 3.33401882e-11, 3.33401882e-11, 3.33401882e-11,\n",
            "       3.33401882e-11, 3.33401882e-11, 3.33401882e-11, 1.09644061e-05,\n",
            "       3.33401882e-11, 9.05554225e-06, 3.33401882e-11, 1.10158489e-05,\n",
            "       1.69043469e-05, 1.31806028e-05, 3.33401882e-11, 1.03244047e-05,\n",
            "       9.78385742e-06, 8.88304916e-11, 9.69362091e-11, 4.06924355e-11,\n",
            "       3.91837743e-11, 7.57321504e-06, 1.32833120e-10, 1.16607307e-10,\n",
            "       1.30438930e-05, 1.00509670e-10, 3.33401882e-11, 3.33401882e-11,\n",
            "       3.33401882e-11, 5.34996207e-06, 2.29612579e-10, 5.03155885e-11,\n",
            "       3.33401882e-11, 3.33401882e-11, 9.42561928e-06, 3.33401882e-11,\n",
            "       1.09992643e-05, 7.33195171e-11, 3.33401882e-11, 1.21596140e-05,\n",
            "       1.12006101e-05, 3.33401882e-11, 3.33401882e-11, 9.39433085e-06,\n",
            "       9.86724899e-06, 3.33401882e-11, 8.88408166e-11, 7.04231888e-06,\n",
            "       1.10241090e-05, 6.39582068e-11, 8.47515730e-06, 1.10593319e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst7', 'index': 9, 'shape': array([256,   1,   1, 128], dtype=int32), 'shape_signature': array([256,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.10815923e-09, 3.93700805e-09, 9.60725476e-04, 3.93700805e-09,\n",
            "       7.55292806e-09, 8.17855296e-04, 9.55461350e-04, 3.93700805e-09,\n",
            "       1.74201152e-03, 9.97490832e-04, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.09997008e-03, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.27863092e-03, 1.26036676e-03, 6.39162681e-05, 1.65380049e-03,\n",
            "       4.21603952e-09, 1.35337492e-03, 3.93700805e-09, 1.84014416e-03,\n",
            "       3.93700805e-09, 3.93700805e-09, 8.11297607e-09, 1.03289439e-08,\n",
            "       1.63001502e-07, 1.18668820e-03, 8.51152407e-04, 1.39274122e-03,\n",
            "       3.93700805e-09, 1.75176479e-03, 3.93700805e-09, 9.89252469e-04,\n",
            "       3.93700805e-09, 8.38892866e-09, 3.93700805e-09, 9.39795107e-04,\n",
            "       1.51160231e-03, 1.43074500e-03, 3.93700805e-09, 1.81945262e-03,\n",
            "       1.17362986e-04, 6.99102154e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       2.04476039e-03, 1.53061200e-03, 3.93700805e-09, 3.93700805e-09,\n",
            "       3.93700805e-09, 1.62086834e-03, 1.13250795e-08, 3.93700805e-09,\n",
            "       1.37863576e-03, 3.93700805e-09, 1.45551120e-03, 1.09660439e-03,\n",
            "       9.17153375e-04, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.47774734e-03, 1.55207561e-03, 1.21412612e-03, 4.78079798e-09,\n",
            "       1.20184210e-03, 1.42770633e-03, 1.37735698e-08, 1.73535140e-03,\n",
            "       8.87488131e-04, 5.30041347e-04, 3.93700805e-09, 2.06356709e-08,\n",
            "       1.29200879e-03, 1.47680426e-03, 3.93700805e-09, 3.93700805e-09,\n",
            "       7.84114462e-09, 4.32547267e-06, 1.29108434e-03, 9.99398413e-04,\n",
            "       8.49970733e-04, 3.93700805e-09, 3.93700805e-09, 1.24010607e-03,\n",
            "       1.13368919e-03, 6.05994943e-09, 1.77029765e-03, 7.00288627e-04,\n",
            "       1.08729582e-03, 1.72283174e-03, 4.45685444e-09, 4.30839808e-09,\n",
            "       9.25873689e-09, 1.40535343e-03, 1.57219858e-03, 1.84755446e-03,\n",
            "       3.93700805e-09, 7.04182979e-09, 3.93700805e-09, 9.55402513e-09,\n",
            "       8.58618354e-04, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.14910398e-03, 1.75406370e-07, 3.93700805e-09, 9.28870136e-09,\n",
            "       3.93700805e-09, 8.35250306e-04, 1.51402096e-03, 7.18663351e-09,\n",
            "       5.30673424e-04, 1.32765354e-08, 1.15351798e-03, 9.35228891e-04,\n",
            "       3.93700805e-09, 1.62718710e-08, 1.28532620e-03, 1.48221012e-03,\n",
            "       1.52275502e-03, 1.22509024e-03, 3.93700805e-09, 1.01743556e-08,\n",
            "       3.93700805e-09, 1.31351152e-03, 1.34829269e-03, 1.27779064e-03,\n",
            "       1.55141713e-08, 3.93700805e-09, 3.93700805e-09, 1.45370630e-03,\n",
            "       4.56489690e-09, 1.22702075e-03, 3.93700805e-09, 6.47953691e-09,\n",
            "       1.18046408e-08, 3.93700805e-09, 4.66831240e-09, 9.25503555e-04,\n",
            "       3.93700805e-09, 4.92709340e-04, 9.45949403e-04, 1.06889301e-03,\n",
            "       1.03625236e-03, 1.28622225e-03, 3.93700805e-09, 3.93700805e-09,\n",
            "       1.03095360e-03, 4.43394299e-09, 6.58707868e-05, 3.93700805e-09,\n",
            "       1.66054070e-03, 3.93700805e-09, 1.22315623e-03, 1.36828283e-03,\n",
            "       1.45045074e-03, 1.77378708e-03, 3.93700805e-09, 1.25229789e-03,\n",
            "       1.89564524e-08, 3.93700805e-09, 2.94698896e-08, 1.15062715e-03,\n",
            "       1.88415241e-03, 3.93700805e-09, 4.31501901e-09, 3.93700805e-09,\n",
            "       1.41491019e-03, 5.31853139e-09, 3.93700805e-09, 2.09892890e-03,\n",
            "       9.41599509e-09, 1.65357266e-03, 3.93700805e-09, 1.50843780e-03,\n",
            "       7.48493711e-09, 9.79418750e-04, 2.18651728e-08, 7.27042293e-09,\n",
            "       1.64678553e-03, 7.28719751e-09, 1.17333466e-03, 5.09433873e-09,\n",
            "       3.93700805e-09, 1.42137555e-08, 2.00782507e-03, 1.34043524e-03,\n",
            "       4.59235814e-08, 3.93700805e-09, 2.44744228e-06, 1.14993507e-03,\n",
            "       3.93700805e-09, 3.93700805e-09, 1.18885124e-08, 3.93700805e-09,\n",
            "       1.83475227e-03, 8.12194834e-04, 3.93700805e-09, 1.96739426e-03,\n",
            "       1.11829257e-08, 3.93700805e-09, 3.93700805e-09, 3.93700805e-09,\n",
            "       3.93700805e-09, 3.93700805e-09, 3.93700805e-09, 1.29474245e-03,\n",
            "       3.93700805e-09, 1.06933236e-03, 3.93700805e-09, 1.30081712e-03,\n",
            "       1.99616607e-03, 1.55644410e-03, 3.93700805e-09, 1.21916726e-03,\n",
            "       1.15533615e-03, 1.04896341e-08, 1.14468053e-08, 4.80520557e-09,\n",
            "       4.62705385e-09, 8.94290395e-04, 1.56857265e-08, 1.37696858e-08,\n",
            "       1.54030067e-03, 1.18687806e-08, 3.93700805e-09, 3.93700805e-09,\n",
            "       3.93700805e-09, 6.31755393e-04, 2.71140213e-08, 5.94156457e-09,\n",
            "       3.93700805e-09, 3.93700805e-09, 1.11303327e-03, 3.93700805e-09,\n",
            "       1.29885867e-03, 8.65800587e-09, 3.93700805e-09, 1.43587973e-03,\n",
            "       1.32263475e-03, 3.93700805e-09, 3.93700805e-09, 1.10933860e-03,\n",
            "       1.16518361e-03, 3.93700805e-09, 1.04908535e-08, 8.31598998e-04,\n",
            "       1.30179245e-03, 7.55256657e-09, 1.00079714e-03, 1.30595185e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst8', 'index': 10, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.88179129e-05, 9.98353062e-05, 7.04364211e-05, 8.28614939e-05,\n",
            "       9.02225220e-05, 1.00561352e-04, 8.59705397e-05, 8.23354567e-05,\n",
            "       9.51692855e-05, 7.28354862e-05, 5.77849733e-06, 6.12993172e-05,\n",
            "       1.36070339e-05, 6.53065726e-11, 5.80740852e-05, 5.67033421e-05,\n",
            "       9.32901385e-05, 5.96397658e-05, 9.63974235e-05, 7.59030372e-05,\n",
            "       8.78521023e-05, 9.75797593e-05, 1.13820024e-04, 8.97333957e-05,\n",
            "       1.00232413e-04, 2.18437091e-08, 6.96784409e-05, 1.09728520e-04,\n",
            "       6.91920213e-05, 1.20717363e-04, 8.15639651e-05, 7.59257746e-05,\n",
            "       1.81794367e-05, 1.10292211e-04, 1.30122033e-04, 6.58839199e-05,\n",
            "       9.28194859e-05, 7.81642593e-05, 7.46242440e-05, 1.13970862e-04,\n",
            "       1.75011339e-10, 9.20028251e-05, 7.89249170e-05, 8.47447009e-05,\n",
            "       9.21158426e-05, 5.95445693e-10, 7.81797789e-05, 2.43813738e-05,\n",
            "       6.13495722e-05, 8.15622698e-05, 8.87765200e-05, 9.69950925e-05,\n",
            "       7.66660378e-05, 1.14331277e-04, 9.97096722e-05, 7.90638078e-05,\n",
            "       7.65922814e-05, 6.78043652e-05, 1.25730148e-04, 5.90875543e-11,\n",
            "       1.99714736e-06, 9.31657996e-05, 7.83950309e-05, 6.99865923e-05,\n",
            "       9.32971307e-05, 8.07571560e-05, 8.95472112e-05, 1.06274158e-04,\n",
            "       8.32036967e-05, 6.89989974e-05, 4.97669857e-11, 9.48600209e-05,\n",
            "       6.00273561e-05, 9.32688345e-05, 7.05144994e-05, 6.70685258e-05,\n",
            "       7.14537964e-05, 1.08088199e-04, 6.38915808e-05, 6.51396185e-05,\n",
            "       9.05406923e-05, 7.28181403e-05, 7.43748824e-05, 8.92913231e-05,\n",
            "       9.15312266e-05, 1.12526650e-04, 6.67104468e-05, 8.06142343e-05,\n",
            "       1.64794510e-05, 8.62153902e-05, 8.63446120e-11, 8.25591342e-05,\n",
            "       8.05011223e-05, 9.55022479e-05, 1.19111122e-04, 8.44582464e-05,\n",
            "       4.97669857e-11, 4.97669857e-11, 9.48150482e-05, 1.04694889e-04,\n",
            "       5.47653835e-05, 7.95758315e-05, 8.05347518e-05, 7.98185210e-05,\n",
            "       9.22798718e-05, 7.40273972e-05, 7.05182829e-05, 8.10824019e-07,\n",
            "       5.21187260e-11, 8.89416640e-07, 8.98897852e-05, 8.50755241e-05,\n",
            "       1.26577201e-04, 6.83460457e-05, 9.80168188e-05, 8.55161150e-11,\n",
            "       9.09733862e-05, 6.76258933e-05, 1.06692612e-04, 1.28047643e-04,\n",
            "       1.55584323e-10, 6.32779662e-11, 9.91011038e-05, 6.93310964e-11,\n",
            "       1.48041709e-05, 8.27772383e-05, 7.85986995e-05, 6.02345681e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst9', 'index': 11, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([7.02628167e-03, 7.89785478e-03, 5.57214301e-03, 6.55507622e-03,\n",
            "       7.13739824e-03, 7.95529131e-03, 6.80102920e-03, 6.51346194e-03,\n",
            "       7.52873113e-03, 5.76193025e-03, 4.57130198e-04, 4.84931748e-03,\n",
            "       1.07643660e-03, 5.16632692e-09, 4.59417328e-03, 4.48573520e-03,\n",
            "       7.38007389e-03, 4.71803220e-03, 7.62588764e-03, 6.00460079e-03,\n",
            "       6.94987737e-03, 7.71942083e-03, 9.00416914e-03, 7.09870411e-03,\n",
            "       7.92926922e-03, 1.72803038e-06, 5.51218027e-03, 8.68049543e-03,\n",
            "       5.47369989e-03, 9.54980962e-03, 6.45243004e-03, 6.00639964e-03,\n",
            "       1.43815402e-03, 8.72508809e-03, 1.02938022e-02, 5.21200011e-03,\n",
            "       7.34284148e-03, 6.18348317e-03, 5.90343680e-03, 9.01610218e-03,\n",
            "       1.38449430e-08, 7.27823609e-03, 6.24365825e-03, 6.70405431e-03,\n",
            "       7.28717679e-03, 4.71050150e-08, 6.18471112e-03, 1.92878209e-03,\n",
            "       4.85329330e-03, 6.45229593e-03, 7.02300714e-03, 7.67316855e-03,\n",
            "       6.06496073e-03, 9.04461369e-03, 7.88791571e-03, 6.25464553e-03,\n",
            "       6.05912600e-03, 5.36392443e-03, 9.94636491e-03, 4.67434758e-09,\n",
            "       1.57991992e-04, 7.37023773e-03, 6.20173942e-03, 5.53655764e-03,\n",
            "       7.38062710e-03, 6.38860418e-03, 7.08397571e-03, 8.40722490e-03,\n",
            "       6.58214744e-03, 5.45842992e-03, 3.93700805e-09, 7.50426576e-03,\n",
            "       4.74869413e-03, 7.37838866e-03, 5.57832001e-03, 5.30571258e-03,\n",
            "       5.65262651e-03, 8.55073147e-03, 5.05438820e-03, 5.15311910e-03,\n",
            "       7.16256863e-03, 5.76055842e-03, 5.88370999e-03, 7.06373248e-03,\n",
            "       7.24092871e-03, 8.90185218e-03, 5.27738547e-03, 6.37729792e-03,\n",
            "       1.30367011e-03, 6.82039885e-03, 6.83062140e-09, 6.53115660e-03,\n",
            "       6.36834977e-03, 7.55507126e-03, 9.42274183e-03, 6.68139337e-03,\n",
            "       3.93700805e-09, 3.93700805e-09, 7.50070764e-03, 8.28229077e-03,\n",
            "       4.33242554e-03, 6.29515108e-03, 6.37101009e-03, 6.31434983e-03,\n",
            "       7.30015291e-03, 5.85622108e-03, 5.57861896e-03, 6.41433435e-05,\n",
            "       4.12305168e-09, 7.03607147e-05, 7.11107580e-03, 6.73022540e-03,\n",
            "       1.00133745e-02, 5.40677598e-03, 7.75399618e-03, 6.76508005e-09,\n",
            "       7.19679845e-03, 5.34980558e-03, 8.44032783e-03, 1.01296995e-02,\n",
            "       1.23080941e-08, 5.00584596e-09, 7.83977285e-03, 5.48470203e-09,\n",
            "       1.17114070e-03, 6.54841075e-03, 6.21785130e-03, 4.76508634e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst10', 'index': 12, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([4.55757909e-05, 3.84101077e-05, 4.76736022e-05, 4.35107977e-05,\n",
            "       3.66008135e-05, 4.98012305e-05, 4.94574269e-05, 3.21278130e-05,\n",
            "       4.86232566e-05, 2.31924623e-05, 2.23628831e-05, 1.18510634e-05,\n",
            "       5.22753453e-06, 1.16657808e-10, 2.67469586e-05, 3.79350458e-05,\n",
            "       2.38325847e-05, 2.91670021e-05, 3.68853289e-05, 3.05788235e-05,\n",
            "       3.23203167e-05, 5.09182100e-05, 4.44534635e-05, 3.91919639e-05,\n",
            "       5.49692522e-05, 1.31311434e-10, 5.87292852e-05, 4.47064995e-05,\n",
            "       4.77828580e-05, 4.35555885e-05, 4.89622580e-05, 3.10422183e-05,\n",
            "       1.44485875e-05, 3.40881597e-05, 3.49804686e-05, 2.93809226e-05,\n",
            "       5.17541557e-05, 4.54593719e-05, 4.77842004e-05, 2.10675607e-05,\n",
            "       8.06617204e-11, 8.08971818e-05, 4.62273383e-05, 6.89273875e-05,\n",
            "       3.67060165e-05, 6.80325518e-11, 3.37840538e-05, 1.86089146e-05,\n",
            "       4.38904572e-05, 3.06555594e-05, 4.10587963e-05, 3.04594814e-05,\n",
            "       6.43190288e-05, 3.19876272e-05, 4.33378627e-05, 3.72095128e-05,\n",
            "       3.25128749e-05, 2.79713258e-05, 4.20449760e-05, 9.16667575e-11,\n",
            "       1.27415512e-06, 5.18919114e-05, 2.07726571e-05, 3.20224208e-05,\n",
            "       3.80178171e-05, 2.79500964e-05, 4.44857651e-05, 3.95660172e-05,\n",
            "       2.69558495e-05, 3.16540973e-05, 6.80325518e-11, 3.43534157e-05,\n",
            "       2.75846214e-05, 7.76767120e-05, 2.33613609e-05, 2.79521846e-05,\n",
            "       2.30696023e-05, 3.61158927e-05, 3.35836157e-05, 4.10503781e-05,\n",
            "       3.61811617e-05, 5.05825992e-05, 4.04821476e-05, 2.30364094e-05,\n",
            "       6.23243759e-05, 3.00967804e-05, 3.09144452e-05, 3.74600422e-05,\n",
            "       4.18558329e-06, 3.28665374e-05, 6.80325518e-11, 4.14177375e-05,\n",
            "       4.37331764e-05, 3.12717821e-05, 1.64467692e-05, 2.65316685e-05,\n",
            "       6.80325518e-11, 6.80325518e-11, 1.90128194e-05, 4.78662951e-05,\n",
            "       3.19957762e-05, 4.68930448e-05, 3.43583051e-05, 4.67118225e-05,\n",
            "       3.57321733e-05, 2.95230075e-05, 3.74930532e-05, 1.41643308e-10,\n",
            "       1.27526892e-10, 3.76568892e-08, 7.35146459e-05, 3.51049530e-05,\n",
            "       3.86278261e-05, 6.21162180e-05, 6.46991321e-05, 7.22467017e-11,\n",
            "       5.70239645e-05, 2.37777040e-05, 3.33514108e-05, 3.71936803e-05,\n",
            "       6.80325518e-11, 6.80325518e-11, 4.62830685e-05, 6.80325518e-11,\n",
            "       2.24521627e-05, 6.38034107e-05, 1.80814204e-05, 2.06614877e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst11', 'index': 13, 'shape': array([128,   1,   1, 128], dtype=int32), 'shape_signature': array([128,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.6374471e-03, 2.2227727e-03, 2.7588464e-03, 2.5179470e-03,\n",
            "       2.1180699e-03, 2.8819710e-03, 2.8620753e-03, 1.8592196e-03,\n",
            "       2.8138023e-03, 1.3421356e-03, 1.2941282e-03, 6.8581483e-04,\n",
            "       3.0251467e-04, 6.7509260e-09, 1.5478324e-03, 2.1952812e-03,\n",
            "       1.3791792e-03, 1.6878791e-03, 2.1345345e-03, 1.7695804e-03,\n",
            "       1.8703598e-03, 2.9466101e-03, 2.5724985e-03, 2.2680184e-03,\n",
            "       3.1810417e-03, 7.5989233e-09, 3.3986329e-03, 2.5871417e-03,\n",
            "       2.7651689e-03, 2.5205391e-03, 2.8334202e-03, 1.7963969e-03,\n",
            "       8.3613215e-04, 1.9726639e-03, 2.0243013e-03, 1.7002586e-03,\n",
            "       2.9949858e-03, 2.6307099e-03, 2.7652467e-03, 1.2191687e-03,\n",
            "       4.6678514e-09, 4.6814773e-03, 2.6751517e-03, 3.9887917e-03,\n",
            "       2.1241580e-03, 3.9370081e-09, 1.9550654e-03, 1.0768881e-03,\n",
            "       2.5399176e-03, 1.7740212e-03, 2.3760509e-03, 1.7626742e-03,\n",
            "       3.7221082e-03, 1.8511072e-03, 2.5079392e-03, 2.1532949e-03,\n",
            "       1.8815029e-03, 1.6186859e-03, 2.4331207e-03, 5.3047069e-09,\n",
            "       7.3734685e-05, 3.0029577e-03, 1.2021028e-03, 1.8531207e-03,\n",
            "       2.2000710e-03, 1.6174574e-03, 2.5743679e-03, 2.2896647e-03,\n",
            "       1.5599208e-03, 1.8318060e-03, 3.9370081e-09, 1.9880142e-03,\n",
            "       1.5963075e-03, 4.4951104e-03, 1.3519097e-03, 1.6175782e-03,\n",
            "       1.3350258e-03, 2.0900078e-03, 1.9434661e-03, 2.3755638e-03,\n",
            "       2.0937847e-03, 2.9271885e-03, 2.3426807e-03, 1.3331049e-03,\n",
            "       3.6066787e-03, 1.7416849e-03, 1.7890027e-03, 2.1677930e-03,\n",
            "       2.4221750e-04, 1.9019692e-03, 3.9370081e-09, 2.3968227e-03,\n",
            "       2.5308160e-03, 1.8096816e-03, 9.5176592e-04, 1.5353737e-03,\n",
            "       3.9370081e-09, 3.9370081e-09, 1.1002618e-03, 2.7699973e-03,\n",
            "       1.8515787e-03, 2.7136758e-03, 1.9882971e-03, 2.7031887e-03,\n",
            "       2.0678020e-03, 1.7084809e-03, 2.1697034e-03, 8.1968237e-09,\n",
            "       7.3799140e-09, 2.1791843e-06, 4.2542540e-03, 2.0315051e-03,\n",
            "       2.2353721e-03, 3.5946327e-03, 3.7441046e-03, 4.1808788e-09,\n",
            "       3.2999469e-03, 1.3760033e-03, 1.9300287e-03, 2.1523787e-03,\n",
            "       3.9370081e-09, 3.9370081e-09, 2.6783769e-03, 3.9370081e-09,\n",
            "       1.2992949e-03, 3.6922698e-03, 1.0463623e-03, 1.1956694e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst12', 'index': 14, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.33361507e-04, 1.01709789e-04, 8.76882259e-05, 5.07238428e-06,\n",
            "       1.13937604e-05, 2.49054865e-05, 1.24296101e-04, 5.66974856e-10,\n",
            "       1.85666732e-10, 1.35194656e-04, 2.05027745e-10, 9.22781110e-05,\n",
            "       6.94121773e-05, 1.04264080e-04, 1.11211534e-06, 1.36641189e-04,\n",
            "       1.08373526e-04, 7.55808505e-05, 9.72816924e-05, 9.98231189e-05,\n",
            "       1.16694122e-04, 5.53904101e-05, 8.93571487e-05, 1.01794350e-04,\n",
            "       3.54438635e-06, 7.79520124e-05, 1.27827752e-06, 2.66831757e-05,\n",
            "       1.03583901e-04, 9.72508278e-05, 9.73318529e-05, 1.01536680e-04,\n",
            "       7.38638410e-05, 9.76298688e-05, 2.82678414e-09, 7.50831241e-05,\n",
            "       1.22205340e-04, 9.60713369e-05, 1.06939966e-04, 7.02052785e-05,\n",
            "       1.38801348e-04, 2.09086738e-05, 5.16196621e-07, 1.19350218e-04,\n",
            "       2.70771602e-06, 8.17732216e-05, 1.45135630e-06, 1.14743249e-04,\n",
            "       1.56411062e-09, 1.13092491e-09, 9.25746644e-05, 1.03335165e-04,\n",
            "       1.27277148e-04, 1.04478844e-04, 1.12676971e-04, 8.59789288e-05,\n",
            "       9.76150186e-05, 7.07768704e-05, 9.38340818e-05, 7.31361943e-05,\n",
            "       3.74189071e-08, 6.78535130e-08, 9.39585370e-05, 3.99639066e-05,\n",
            "       1.15396595e-10, 7.59606877e-10, 9.49949390e-05, 1.17558702e-04,\n",
            "       8.92493635e-10, 1.03545499e-04, 1.23700564e-04, 9.84981816e-05,\n",
            "       1.36071423e-04, 1.45189872e-04, 8.02206196e-05, 7.09686137e-05,\n",
            "       1.25001185e-04, 1.94001059e-05, 9.89023320e-05, 1.34160975e-04,\n",
            "       1.04934436e-04, 2.66750385e-06, 8.91631862e-05, 3.48464710e-06,\n",
            "       1.09298315e-04, 1.21246427e-04, 8.03539369e-05, 1.32008281e-04,\n",
            "       1.11787289e-04, 8.22415241e-05, 9.80727345e-05, 6.24964650e-06,\n",
            "       2.75584534e-06, 3.70967646e-05, 1.11417015e-04, 1.38783074e-08,\n",
            "       1.83115105e-06, 9.03364853e-05, 1.06640007e-04, 1.31100154e-04,\n",
            "       1.20250792e-04, 9.83569917e-05, 9.78347452e-05, 6.78154856e-06,\n",
            "       1.03111262e-04, 9.76465017e-05, 8.27823824e-05, 7.81205308e-05,\n",
            "       7.63810334e-11, 9.46656655e-05, 8.32889928e-05, 8.63073801e-05,\n",
            "       8.90073716e-05, 1.03223167e-04, 7.38009185e-05, 1.16127194e-04,\n",
            "       6.67162749e-05, 1.11138128e-04, 1.03534927e-04, 8.37666885e-05,\n",
            "       9.56602307e-05, 1.19726923e-04, 1.03583974e-04, 1.11518762e-04,\n",
            "       9.04132394e-05, 8.43069138e-05, 9.84215803e-05, 3.45749795e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst13', 'index': 15, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.01184407e-02, 7.71695282e-03, 6.65310491e-03, 3.84853309e-04,\n",
            "       8.64470494e-04, 1.88963581e-03, 9.43062734e-03, 4.30176712e-08,\n",
            "       1.40869574e-08, 1.02575263e-02, 1.55559210e-08, 7.00135017e-03,\n",
            "       5.26645966e-03, 7.91075267e-03, 8.43787202e-05, 1.03672780e-02,\n",
            "       8.22254550e-03, 5.73449116e-03, 7.38098286e-03, 7.57380668e-03,\n",
            "       8.85384809e-03, 4.20259638e-03, 6.77972985e-03, 7.72336870e-03,\n",
            "       2.68920645e-04, 5.91439614e-03, 9.69858229e-05, 2.02451320e-03,\n",
            "       7.85914622e-03, 7.37864152e-03, 7.38478871e-03, 7.70381885e-03,\n",
            "       5.60421776e-03, 7.40739983e-03, 2.14474539e-07, 5.69672743e-03,\n",
            "       9.27199703e-03, 7.28915073e-03, 8.11377820e-03, 5.32663427e-03,\n",
            "       1.05311740e-02, 1.58638856e-03, 3.91650101e-05, 9.05537233e-03,\n",
            "       2.05440563e-04, 6.20432012e-03, 1.10117704e-04, 8.70583113e-03,\n",
            "       1.18672631e-07, 8.58058442e-08, 7.02385046e-03, 7.84027390e-03,\n",
            "       9.65680648e-03, 7.92704709e-03, 8.54905788e-03, 6.52341684e-03,\n",
            "       7.40627339e-03, 5.37000177e-03, 7.11940508e-03, 5.54900942e-03,\n",
            "       2.83905752e-06, 5.14820022e-06, 7.12884776e-03, 3.03215231e-03,\n",
            "       8.75540174e-09, 5.76331018e-08, 7.20748166e-03, 8.91944580e-03,\n",
            "       6.77155185e-08, 7.85623211e-03, 9.38544329e-03, 7.47328112e-03,\n",
            "       1.03240479e-02, 1.10158855e-02, 6.08652085e-03, 5.38454996e-03,\n",
            "       9.48412344e-03, 1.47193018e-03, 7.50394445e-03, 1.01790978e-02,\n",
            "       7.96161406e-03, 2.02389579e-04, 6.76501356e-03, 2.64388102e-04,\n",
            "       8.29271134e-03, 9.19924211e-03, 6.09663595e-03, 1.00157680e-02,\n",
            "       8.48155562e-03, 6.23985147e-03, 7.44100148e-03, 4.74174885e-04,\n",
            "       2.09092250e-04, 2.81461584e-03, 8.45346227e-03, 1.05297875e-06,\n",
            "       1.38933596e-04, 6.85403449e-03, 8.09101947e-03, 9.94686689e-03,\n",
            "       9.12370067e-03, 7.46256858e-03, 7.42294453e-03, 5.14531508e-04,\n",
            "       7.82328565e-03, 7.40866177e-03, 6.28088741e-03, 5.92718227e-03,\n",
            "       5.79520254e-09, 7.18249893e-03, 6.31932542e-03, 6.54833717e-03,\n",
            "       6.75319135e-03, 7.83177651e-03, 5.59944334e-03, 8.81083403e-03,\n",
            "       5.06191561e-03, 8.43230262e-03, 7.85543025e-03, 6.35556877e-03,\n",
            "       7.25795887e-03, 9.08395369e-03, 7.85915181e-03, 8.46118201e-03,\n",
            "       6.85985805e-03, 6.39655720e-03, 7.46746873e-03, 2.62328237e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst14', 'index': 16, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.4810331e-05, 4.0169358e-05, 2.0941379e-05, 1.4851194e-07,\n",
            "       8.8355737e-06, 4.3884183e-06, 3.2675776e-05, 8.2121830e-11,\n",
            "       5.7960258e-11, 2.8853838e-05, 1.2531941e-10, 9.6852609e-06,\n",
            "       1.2220273e-05, 3.6115212e-05, 6.1183153e-10, 2.4292398e-05,\n",
            "       2.5499034e-05, 2.5749059e-05, 2.7657068e-05, 2.7697144e-05,\n",
            "       4.6384332e-05, 8.4118728e-06, 4.4722561e-05, 3.6611113e-05,\n",
            "       3.1335663e-08, 4.7529935e-05, 1.3053174e-10, 4.0602122e-06,\n",
            "       3.1931657e-05, 2.0587186e-05, 4.2009640e-05, 3.6244073e-05,\n",
            "       2.5804080e-05, 3.3256321e-05, 1.3330555e-10, 2.6485684e-05,\n",
            "       4.6937672e-05, 4.0179420e-05, 3.2614891e-05, 2.1837321e-05,\n",
            "       4.6388002e-05, 1.0460723e-05, 2.0181241e-09, 3.5938610e-05,\n",
            "       3.7652690e-08, 1.7324248e-05, 2.6020544e-10, 2.7829836e-05,\n",
            "       7.6073203e-11, 1.0583609e-10, 2.1221835e-05, 2.9892952e-05,\n",
            "       3.5711197e-05, 2.2661088e-05, 3.9974271e-05, 1.2344843e-05,\n",
            "       3.0279956e-05, 8.5933871e-06, 3.4474670e-05, 3.1189164e-05,\n",
            "       6.5700084e-11, 2.0732127e-10, 5.9233116e-05, 6.3742659e-06,\n",
            "       5.7960258e-11, 5.7960258e-11, 3.2860975e-05, 2.4635186e-05,\n",
            "       7.4400985e-11, 2.5024343e-05, 3.4872093e-05, 1.2439097e-05,\n",
            "       4.0984993e-05, 3.6716072e-05, 2.5889782e-05, 2.5639692e-05,\n",
            "       2.5178686e-05, 4.4712019e-06, 2.5244939e-05, 2.6147784e-05,\n",
            "       1.5386413e-05, 1.2022748e-09, 1.4282646e-05, 1.3463412e-07,\n",
            "       3.2597680e-05, 3.1098120e-05, 1.1428229e-05, 5.3552580e-05,\n",
            "       2.6827420e-05, 3.2124593e-05, 2.8802271e-05, 2.5427371e-06,\n",
            "       1.5576403e-07, 1.3771331e-05, 2.1697790e-05, 5.7960258e-11,\n",
            "       2.2665508e-10, 1.3445992e-05, 3.5335979e-05, 4.7020483e-05,\n",
            "       3.6639576e-05, 8.5024922e-06, 4.0638362e-05, 8.2478813e-08,\n",
            "       2.4820714e-05, 5.7991892e-05, 3.9397597e-05, 1.0155076e-05,\n",
            "       5.7960258e-11, 2.0982448e-05, 9.3864810e-06, 2.7881801e-05,\n",
            "       2.1875770e-05, 4.8969330e-05, 4.7218127e-05, 3.8771839e-05,\n",
            "       8.5819174e-06, 3.1063348e-05, 3.8003564e-05, 2.1387934e-05,\n",
            "       8.6548298e-06, 6.6057466e-05, 2.8047218e-05, 3.5700345e-05,\n",
            "       2.4265284e-05, 9.1692264e-06, 3.5209854e-05, 1.0905290e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst15', 'index': 17, 'shape': array([128,   1,   1, 128], dtype=int32), 'shape_signature': array([128,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.72304604e-03, 2.72854348e-03, 1.42246392e-03, 1.00878215e-05,\n",
            "       6.00165105e-04, 2.98087660e-04, 2.21953448e-03, 5.57820679e-09,\n",
            "       3.93700805e-09, 1.95992552e-03, 8.51244497e-09, 6.57880970e-04,\n",
            "       8.30074132e-04, 2.45316164e-03, 4.15592645e-08, 1.65008521e-03,\n",
            "       1.73204718e-03, 1.74903043e-03, 1.87863375e-03, 1.88135600e-03,\n",
            "       3.15070176e-03, 5.71384793e-04, 3.03782430e-03, 2.48684618e-03,\n",
            "       2.12850591e-06, 3.22851795e-03, 8.86649776e-09, 2.75793951e-04,\n",
            "       2.16898951e-03, 1.39840506e-03, 2.85354652e-03, 2.46191467e-03,\n",
            "       1.75276771e-03, 2.25896854e-03, 9.05491149e-09, 1.79906643e-03,\n",
            "       3.18828784e-03, 2.72922707e-03, 2.21539894e-03, 1.48332166e-03,\n",
            "       3.15095112e-03, 7.10555003e-04, 1.37083077e-07, 2.44116574e-03,\n",
            "       2.55759642e-06, 1.17676670e-03, 1.76747132e-08, 1.89036923e-03,\n",
            "       5.16734788e-09, 7.18902138e-09, 1.44151424e-03, 2.03050836e-03,\n",
            "       2.42571835e-03, 1.53927691e-03, 2.71529215e-03, 8.38535663e-04,\n",
            "       2.05679610e-03, 5.83714340e-04, 2.34172610e-03, 2.11855490e-03,\n",
            "       4.46274351e-09, 1.40825032e-08, 4.02346812e-03, 4.32978326e-04,\n",
            "       3.93700805e-09, 3.93700805e-09, 2.23211432e-03, 1.67336944e-03,\n",
            "       5.05376097e-09, 1.69980328e-03, 2.36872165e-03, 8.44938040e-04,\n",
            "       2.78394623e-03, 2.49397568e-03, 1.75858918e-03, 1.74160150e-03,\n",
            "       1.71028730e-03, 3.03710840e-04, 1.71478756e-03, 1.77611411e-03,\n",
            "       1.04513741e-03, 8.16657106e-08, 9.70162859e-04, 9.14515658e-06,\n",
            "       2.21422967e-03, 2.11237068e-03, 7.76273839e-04, 3.63761210e-03,\n",
            "       1.82227907e-03, 2.18209485e-03, 1.95642281e-03, 1.72717948e-04,\n",
            "       1.05804265e-05, 9.35431337e-04, 1.47384393e-03, 3.93700805e-09,\n",
            "       1.53957718e-08, 9.13332391e-04, 2.40023155e-03, 3.19391303e-03,\n",
            "       2.48877960e-03, 5.77540195e-04, 2.76040100e-03, 5.60245508e-06,\n",
            "       1.68597163e-03, 3.93915689e-03, 2.67612096e-03, 6.89793611e-04,\n",
            "       3.93700805e-09, 1.42525369e-03, 6.37586054e-04, 1.89389894e-03,\n",
            "       1.48593343e-03, 3.32629029e-03, 3.20733804e-03, 2.63361563e-03,\n",
            "       5.82935230e-04, 2.11000862e-03, 2.58142967e-03, 1.45279663e-03,\n",
            "       5.87887887e-04, 4.48701903e-03, 1.90513511e-03, 2.42498145e-03,\n",
            "       1.64824352e-03, 6.22828782e-04, 2.39166431e-03, 7.40752614e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst16', 'index': 18, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.37546036e-05, 8.97535647e-05, 9.92118803e-05, 1.25253678e-07,\n",
            "       1.40574219e-10, 1.07941152e-04, 4.46590720e-09, 8.36133258e-05,\n",
            "       1.05279192e-04, 1.09206274e-04, 1.09855901e-04, 6.90278175e-05,\n",
            "       6.61981612e-05, 1.10694690e-10, 7.80112605e-05, 1.15057555e-04,\n",
            "       7.56900699e-05, 1.81433146e-10, 1.77552035e-08, 7.18126248e-05,\n",
            "       1.12268172e-04, 3.47534547e-06, 8.14956948e-05, 8.91444870e-05,\n",
            "       1.10480208e-07, 3.00097986e-06, 2.56739097e-09, 8.70762015e-05,\n",
            "       1.08155880e-04, 6.88709115e-05, 9.77005693e-05, 9.52193080e-09,\n",
            "       8.49967546e-05, 2.17580176e-09, 1.00791431e-10, 1.05945313e-04,\n",
            "       8.58258572e-05, 8.51897494e-05, 1.44920690e-04, 1.35517213e-04,\n",
            "       3.25252258e-05, 9.09051159e-05, 1.31734239e-04, 9.12694759e-06,\n",
            "       8.43675880e-05, 5.33755519e-05, 2.89978402e-06, 5.81063159e-06,\n",
            "       1.01608144e-04, 1.01204649e-04, 5.56574014e-05, 1.99682690e-05,\n",
            "       1.02999584e-04, 6.66044434e-05, 8.95128032e-05, 9.16321005e-05,\n",
            "       9.33203119e-05, 8.83816174e-05, 8.69116629e-05, 7.88180623e-05,\n",
            "       8.36390245e-05, 7.19567936e-07, 2.27208724e-10, 8.87883216e-05,\n",
            "       9.24343476e-05, 9.58057717e-05, 2.06264561e-09, 8.36119580e-05,\n",
            "       1.46393219e-07, 7.38461452e-08, 1.20235047e-04, 5.84410518e-05,\n",
            "       8.48079329e-10, 1.99627870e-10, 8.72858800e-05, 4.83687509e-05,\n",
            "       1.64551039e-10, 8.23155206e-05, 1.01366320e-04, 2.19586058e-10,\n",
            "       1.81374744e-05, 9.59713943e-05, 5.40219153e-05, 8.28883349e-05,\n",
            "       7.62917480e-05, 7.15566566e-05, 6.42073646e-05, 1.03431688e-04,\n",
            "       1.08878608e-04, 1.11858179e-04, 2.90979500e-07, 9.49539753e-05,\n",
            "       2.19932073e-10, 3.25451924e-06, 8.99981969e-05, 8.00894195e-05,\n",
            "       1.16860836e-04, 8.94754339e-05, 5.65597220e-05, 8.15507883e-05,\n",
            "       3.82213057e-06, 1.10000714e-04, 1.18459473e-04, 1.11527443e-04,\n",
            "       7.31306136e-05, 1.36343398e-04, 7.22614641e-05, 1.07708149e-06,\n",
            "       1.79842807e-10, 8.30430508e-05, 1.11814603e-04, 8.48669879e-05,\n",
            "       7.89483820e-05, 8.25919833e-10, 5.36572564e-09, 1.01017453e-04,\n",
            "       6.47327251e-05, 1.60896434e-07, 1.12776310e-04, 7.55245055e-05,\n",
            "       9.01186650e-05, 7.89633123e-05, 1.18408272e-04, 9.03094187e-05,\n",
            "       2.59794518e-07, 6.53133975e-06, 7.02429970e-05, 1.26995612e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst17', 'index': 19, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([5.54059166e-03, 7.80003006e-03, 8.62200465e-03, 1.08851655e-05,\n",
            "       1.22165975e-08, 9.38062184e-03, 3.88109498e-07, 7.26641295e-03,\n",
            "       9.14928410e-03, 9.49056726e-03, 9.54702310e-03, 5.99886011e-03,\n",
            "       5.75294858e-03, 9.61991731e-09, 6.77956548e-03, 9.99907218e-03,\n",
            "       6.57784240e-03, 1.57674407e-08, 1.54301529e-06, 6.24087313e-03,\n",
            "       9.75666102e-03, 3.02024768e-04, 7.08238035e-03, 7.74709834e-03,\n",
            "       9.60127818e-06, 2.60800036e-04, 2.23119017e-07, 7.56735401e-03,\n",
            "       9.39928275e-03, 5.98522369e-03, 8.49066395e-03, 8.27503015e-07,\n",
            "       7.38663971e-03, 1.89087970e-07, 8.75927508e-09, 9.20717325e-03,\n",
            "       7.45869288e-03, 7.40341190e-03, 1.25943264e-02, 1.17771178e-02,\n",
            "       2.82660336e-03, 7.90010579e-03, 1.14483591e-02, 7.93177052e-04,\n",
            "       7.33196223e-03, 4.63860016e-03, 2.52005615e-04, 5.04972704e-04,\n",
            "       8.83025210e-03, 8.79518595e-03, 4.83690435e-03, 1.73534162e-03,\n",
            "       8.95117503e-03, 5.78825688e-03, 7.77910696e-03, 7.96328392e-03,\n",
            "       8.10999796e-03, 7.68080074e-03, 7.55305495e-03, 6.84968056e-03,\n",
            "       7.26864627e-03, 6.25340253e-05, 1.97455652e-08, 7.71614537e-03,\n",
            "       8.03300366e-03, 8.32599681e-03, 1.79254144e-07, 7.26629421e-03,\n",
            "       1.27222966e-05, 6.41759652e-06, 1.04490221e-02, 5.07881725e-03,\n",
            "       7.37023029e-08, 1.73486523e-08, 7.58557580e-03, 4.20348439e-03,\n",
            "       1.43003014e-08, 7.15362700e-03, 8.80923588e-03, 1.90831173e-08,\n",
            "       1.57623645e-03, 8.34039040e-03, 4.69477242e-03, 7.20340759e-03,\n",
            "       6.63013151e-03, 6.21862849e-03, 5.57993865e-03, 8.98872688e-03,\n",
            "       9.46209114e-03, 9.72103048e-03, 2.52875616e-05, 8.25197157e-03,\n",
            "       1.91131875e-08, 2.82833877e-04, 7.82128982e-03, 6.96016802e-03,\n",
            "       1.01557868e-02, 7.77585944e-03, 4.91532031e-03, 7.08716782e-03,\n",
            "       3.32162104e-04, 9.55960806e-03, 1.02947159e-02, 9.69228800e-03,\n",
            "       6.35541324e-03, 1.18489172e-02, 6.27987972e-03, 9.36037250e-05,\n",
            "       1.56292330e-08, 7.21685309e-03, 9.71724372e-03, 7.37536233e-03,\n",
            "       6.86100591e-03, 7.17765332e-08, 4.66308165e-07, 8.77891760e-03,\n",
            "       5.62559487e-03, 1.39826989e-05, 9.80082061e-03, 6.56345440e-03,\n",
            "       7.83175882e-03, 6.86230371e-03, 1.02902660e-02, 7.84833636e-03,\n",
            "       2.25774329e-05, 5.67605835e-04, 6.10446511e-03, 1.10365488e-02],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst18', 'index': 20, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.11456934e-05, 2.88844676e-05, 2.94973688e-05, 8.36154410e-11,\n",
            "       6.66466951e-11, 3.68316178e-05, 5.27465641e-11, 2.70203363e-05,\n",
            "       1.82935837e-05, 3.05266512e-05, 2.57266784e-05, 2.32531511e-05,\n",
            "       2.29056513e-05, 1.05864054e-10, 2.26251377e-05, 2.30742771e-05,\n",
            "       1.38410060e-05, 1.08074348e-10, 6.29756594e-11, 3.96516880e-05,\n",
            "       2.67621581e-05, 1.07627261e-06, 2.49382720e-05, 3.07602786e-05,\n",
            "       7.93008881e-10, 1.87006265e-06, 5.27465641e-11, 3.04665937e-05,\n",
            "       3.39264625e-05, 2.36221895e-05, 1.77069978e-05, 5.27465641e-11,\n",
            "       2.59899898e-05, 5.27465641e-11, 1.19214402e-10, 3.69009285e-05,\n",
            "       5.47482523e-05, 3.01809960e-05, 1.91563595e-05, 2.76746287e-05,\n",
            "       2.50800294e-05, 3.66978238e-05, 2.30012211e-05, 9.72680664e-06,\n",
            "       2.12017658e-05, 1.50455762e-05, 3.83489805e-07, 1.74880029e-06,\n",
            "       2.83479349e-05, 4.39733521e-05, 2.20400907e-05, 9.33140836e-06,\n",
            "       3.00652391e-05, 2.25153472e-05, 2.00527757e-05, 4.11344190e-05,\n",
            "       2.76085630e-05, 2.98947689e-05, 2.98885134e-05, 2.58892651e-05,\n",
            "       2.51792699e-05, 5.27465641e-11, 5.27465641e-11, 1.56307251e-05,\n",
            "       2.45449482e-05, 2.46761792e-05, 5.27465641e-11, 3.12897282e-05,\n",
            "       6.26013894e-11, 5.27465641e-11, 3.00707270e-05, 1.53279525e-05,\n",
            "       6.91382576e-11, 5.30378449e-11, 2.42538481e-05, 1.66684913e-05,\n",
            "       9.45014761e-11, 2.59117023e-05, 2.68022923e-05, 5.67351860e-11,\n",
            "       1.72496730e-05, 2.77535710e-05, 1.76782542e-05, 2.29595989e-05,\n",
            "       2.62117501e-05, 4.03808262e-05, 1.78937225e-05, 4.63947690e-05,\n",
            "       3.45950684e-05, 2.82719993e-05, 2.97612268e-10, 2.95110221e-05,\n",
            "       5.27465641e-11, 1.10662359e-06, 3.28517235e-05, 1.50151000e-05,\n",
            "       2.85897950e-05, 4.21281657e-05, 1.25115275e-05, 1.92984480e-05,\n",
            "       1.18334881e-07, 3.37743040e-05, 3.12013362e-05, 2.36859760e-05,\n",
            "       2.83223217e-05, 3.11241638e-05, 1.84597229e-05, 2.49444270e-07,\n",
            "       5.27465641e-11, 1.83397624e-05, 3.02236185e-05, 2.81922585e-05,\n",
            "       3.25770670e-05, 6.02484312e-11, 5.27465641e-11, 4.15533577e-05,\n",
            "       2.68629410e-05, 1.47420132e-10, 3.09386996e-05, 3.00533266e-05,\n",
            "       3.09839343e-05, 1.90494793e-05, 3.27001326e-05, 2.09893842e-05,\n",
            "       1.78011939e-09, 9.26302437e-06, 2.72930793e-05, 2.87834609e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst19', 'index': 21, 'shape': array([128,   1,   1, 128], dtype=int32), 'shape_signature': array([128,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.32471712e-03, 2.15593912e-03, 2.20168615e-03, 6.24106367e-09,\n",
            "       4.97451502e-09, 2.74911523e-03, 3.93700805e-09, 2.01680022e-03,\n",
            "       1.36543461e-03, 2.27851188e-03, 1.92024151e-03, 1.73561717e-03,\n",
            "       1.70967984e-03, 7.90170240e-09, 1.68874220e-03, 1.72226608e-03,\n",
            "       1.03309390e-03, 8.06667888e-09, 4.70050843e-09, 2.95960531e-03,\n",
            "       1.99752976e-03, 8.03330840e-05, 1.86139473e-03, 2.29594973e-03,\n",
            "       5.91902491e-08, 1.39581636e-04, 3.93700805e-09, 2.27402919e-03,\n",
            "       2.53227400e-03, 1.76316232e-03, 1.32165186e-03, 3.93700805e-09,\n",
            "       1.93989510e-03, 3.93700805e-09, 8.89817287e-09, 2.75428849e-03,\n",
            "       4.08641435e-03, 2.25271215e-03, 1.42983231e-03, 2.06563668e-03,\n",
            "       1.87197560e-03, 2.73912866e-03, 1.71681307e-03, 7.26009661e-04,\n",
            "       1.58250157e-03, 1.12300308e-03, 2.86237118e-05, 1.30530607e-04,\n",
            "       2.11589225e-03, 3.28217470e-03, 1.64507423e-03, 6.96497154e-04,\n",
            "       2.24407203e-03, 1.68054749e-03, 1.49674085e-03, 3.07027646e-03,\n",
            "       2.06070556e-03, 2.23134807e-03, 2.23088125e-03, 1.93237700e-03,\n",
            "       1.87938288e-03, 3.93700805e-09, 3.93700805e-09, 1.16667862e-03,\n",
            "       1.83203700e-03, 1.84183219e-03, 3.93700805e-09, 2.33546807e-03,\n",
            "       4.67257300e-09, 3.93700805e-09, 2.24448158e-03, 1.14407972e-03,\n",
            "       5.16048537e-09, 3.95874933e-09, 1.81030936e-03, 1.24413765e-03,\n",
            "       7.05359815e-09, 1.93405175e-03, 2.00052536e-03, 4.23471924e-09,\n",
            "       1.28751714e-03, 2.07152893e-03, 1.31950644e-03, 1.71370641e-03,\n",
            "       1.95644726e-03, 3.01402831e-03, 1.33558898e-03, 3.46290949e-03,\n",
            "       2.58217892e-03, 2.11022445e-03, 2.22138059e-08, 2.20270525e-03,\n",
            "       3.93700805e-09, 8.25984825e-05, 2.45205546e-03, 1.12072832e-03,\n",
            "       2.13394477e-03, 3.14444979e-03, 9.33861476e-04, 1.44043786e-03,\n",
            "       8.83252596e-06, 2.52091698e-03, 2.32887035e-03, 1.76792324e-03,\n",
            "       2.11398047e-03, 2.32311036e-03, 1.37783529e-03, 1.86185425e-05,\n",
            "       3.93700805e-09, 1.36888144e-03, 2.25589355e-03, 2.10427260e-03,\n",
            "       2.43155519e-03, 4.49694815e-09, 3.93700805e-09, 3.10154608e-03,\n",
            "       2.00505229e-03, 1.10034515e-08, 2.30926718e-03, 2.24318285e-03,\n",
            "       2.31264345e-03, 1.42185483e-03, 2.44074059e-03, 1.56664941e-03,\n",
            "       1.32868266e-07, 6.91392925e-04, 2.03715777e-03, 2.14840006e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst20', 'index': 22, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.37567782e-04, 7.18053416e-05, 9.56337026e-05, 1.29191496e-04,\n",
            "       1.68310171e-10, 1.22920566e-04, 8.85271438e-05, 9.98309019e-07,\n",
            "       9.76475858e-05, 1.32783262e-05, 8.41578658e-05, 8.09228586e-05,\n",
            "       7.78852552e-07, 1.02955259e-04, 4.85906930e-05, 8.56889747e-05,\n",
            "       1.03672261e-04, 9.46758155e-05, 8.38293563e-05, 6.42444364e-09,\n",
            "       6.30485520e-05, 7.33918641e-05, 6.68245761e-08, 1.82879628e-10,\n",
            "       1.22174315e-04, 1.20697936e-04, 4.14134738e-05, 1.76430592e-10,\n",
            "       1.02452454e-04, 9.73393981e-05, 7.61085685e-05, 7.33867782e-05,\n",
            "       8.48543568e-05, 9.15845885e-05, 9.38130397e-05, 1.24703947e-04,\n",
            "       7.85583470e-05, 8.00229682e-05, 1.07976819e-04, 9.16202262e-05,\n",
            "       9.20787425e-05, 6.80712546e-05, 1.27158026e-04, 2.57445759e-10,\n",
            "       1.16498020e-04, 9.39285237e-05, 8.03062867e-05, 7.70921906e-05,\n",
            "       9.60505931e-05, 8.07277218e-07, 1.04993931e-04, 7.77582609e-05,\n",
            "       5.90158393e-08, 8.32525475e-05, 1.16211464e-04, 8.52564990e-05,\n",
            "       8.59515130e-05, 7.14695416e-05, 1.15637362e-04, 8.79712097e-05,\n",
            "       1.07890497e-04, 1.06505919e-04, 9.79263277e-05, 9.95301816e-05,\n",
            "       9.06432761e-05, 1.00120960e-04, 8.22799702e-05, 9.09280643e-05,\n",
            "       8.33060549e-05, 6.13326556e-10, 9.70328692e-05, 7.51458865e-05,\n",
            "       1.02513215e-04, 6.47939232e-05, 9.16350462e-09, 1.03569932e-04,\n",
            "       1.05758831e-04, 8.37054031e-05, 6.24589234e-07, 1.12275367e-04,\n",
            "       9.52285700e-05, 9.45237916e-05, 1.07870415e-04, 1.04474282e-04,\n",
            "       2.00150660e-10, 8.39963395e-05, 1.20867582e-04, 4.41245840e-09,\n",
            "       6.10122879e-05, 6.57826022e-05, 8.92138487e-05, 6.24117747e-05,\n",
            "       1.19887998e-04, 8.40210778e-05, 9.56923977e-05, 1.00165038e-04,\n",
            "       8.63188325e-05, 1.05231084e-04, 7.44745194e-05, 9.77883537e-05,\n",
            "       1.06976415e-07, 8.06445896e-05, 1.80711395e-05, 8.43258313e-05,\n",
            "       9.05746201e-05, 2.09003286e-08, 8.66384944e-05, 7.13906775e-05,\n",
            "       8.88194991e-05, 7.17182265e-05, 8.33166923e-05, 1.00080739e-04,\n",
            "       7.67638485e-05, 7.37054961e-07, 8.19203851e-05, 8.31534562e-05,\n",
            "       1.04222301e-04, 1.25335631e-04, 1.59533556e-05, 6.73699251e-05,\n",
            "       9.83518039e-05, 1.02920967e-04, 6.80868252e-05, 2.50308080e-10,\n",
            "       2.63667477e-10, 1.19280958e-04, 8.73409736e-05, 9.59047008e-11],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst21', 'index': 23, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.1885642e-02, 6.2038694e-03, 8.2626026e-03, 1.1161943e-02,\n",
            "       1.4541736e-08, 1.0620145e-02, 7.6486073e-03, 8.6252345e-05,\n",
            "       8.4365988e-03, 1.1472267e-03, 7.2711082e-03, 6.9916085e-03,\n",
            "       6.7291643e-05, 8.8951737e-03, 4.1981600e-03, 7.4033937e-03,\n",
            "       8.9571215e-03, 8.1798425e-03, 7.2427252e-03, 5.5506189e-07,\n",
            "       5.4472964e-03, 6.3409423e-03, 5.7735388e-06, 1.5800515e-08,\n",
            "       1.0555670e-02, 1.0428113e-02, 3.5780596e-03, 1.5243328e-08,\n",
            "       8.8517321e-03, 8.4099723e-03, 6.5756617e-03, 6.3405028e-03,\n",
            "       7.3312842e-03, 7.9127653e-03, 8.1053004e-03, 1.0774227e-02,\n",
            "       6.7873183e-03, 6.9138594e-03, 9.3290284e-03, 7.9158442e-03,\n",
            "       7.9554599e-03, 5.8812499e-03, 1.0986255e-02, 2.2242912e-08,\n",
            "       1.0065247e-02, 8.1152776e-03, 6.9383378e-03, 6.6606449e-03,\n",
            "       8.2986215e-03, 6.9747490e-05, 9.0713119e-03, 6.7181922e-03,\n",
            "       5.0988765e-06, 7.1928902e-03, 1.0040489e-02, 7.3660286e-03,\n",
            "       7.4260766e-03, 6.1748568e-03, 9.9908877e-03, 7.6005752e-03,\n",
            "       9.3215704e-03, 9.2019448e-03, 8.4606819e-03, 8.5992524e-03,\n",
            "       7.8314375e-03, 8.6502945e-03, 7.1088611e-03, 7.8560431e-03,\n",
            "       7.1975132e-03, 5.2990455e-08, 8.3834883e-03, 6.4924872e-03,\n",
            "       8.8569820e-03, 5.5980938e-03, 7.9171252e-07, 8.9482805e-03,\n",
            "       9.1373976e-03, 7.2320160e-03, 5.3963533e-05, 9.7004166e-03,\n",
            "       8.2275998e-03, 8.1667081e-03, 9.3198353e-03, 9.0264147e-03,\n",
            "       1.7292704e-08, 7.2571523e-03, 1.0442770e-02, 3.8122951e-07,\n",
            "       5.2713663e-03, 5.6835143e-03, 7.7079372e-03, 5.3922799e-03,\n",
            "       1.0358136e-02, 7.2592897e-03, 8.2676737e-03, 8.6541027e-03,\n",
            "       7.4578123e-03, 9.0918010e-03, 6.4344821e-03, 8.4487610e-03,\n",
            "       9.2425953e-06, 6.9675664e-03, 1.5613183e-03, 7.2856201e-03,\n",
            "       7.8255059e-03, 1.8057557e-06, 7.4854307e-03, 6.1680432e-03,\n",
            "       7.6738661e-03, 6.1963429e-03, 7.1984320e-03, 8.6468197e-03,\n",
            "       6.6322763e-03, 6.3680396e-05, 7.0777931e-03, 7.1843285e-03,\n",
            "       9.0046441e-03, 1.0828802e-02, 1.3783450e-03, 5.8206562e-03,\n",
            "       8.4974421e-03, 8.8922111e-03, 5.8825957e-03, 2.1626228e-08,\n",
            "       2.2780458e-08, 1.0305689e-02, 7.5461236e-03, 8.2860163e-09],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst22', 'index': 24, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.3412143e-05, 2.4806126e-05, 2.7692824e-05, 3.8135120e-05,\n",
            "       7.7891263e-11, 2.9353823e-05, 2.5515108e-05, 4.9729752e-11,\n",
            "       4.0068197e-05, 3.5498949e-06, 2.1161188e-05, 1.8885010e-05,\n",
            "       2.0647905e-08, 2.2289596e-05, 1.5935851e-05, 4.4524157e-05,\n",
            "       3.3556131e-05, 3.3622488e-05, 3.5896217e-05, 8.2436599e-11,\n",
            "       2.5648322e-05, 2.3881707e-05, 2.0069414e-10, 4.9729752e-11,\n",
            "       2.5294174e-05, 3.3206965e-05, 1.8823372e-05, 4.9729752e-11,\n",
            "       2.4181118e-05, 3.6253587e-05, 2.1079892e-05, 2.1493099e-05,\n",
            "       1.6020273e-05, 2.6501479e-05, 2.4420870e-05, 2.8543525e-05,\n",
            "       3.1467716e-05, 1.8382247e-05, 2.0991381e-05, 2.7065953e-05,\n",
            "       3.0813033e-05, 2.0241101e-05, 2.5858237e-05, 5.4063452e-11,\n",
            "       3.4030843e-05, 2.7307740e-05, 3.1121628e-05, 3.0945921e-05,\n",
            "       3.6130241e-05, 1.0099432e-07, 2.5126030e-05, 1.3394561e-05,\n",
            "       6.5068027e-11, 3.7848316e-05, 2.0561971e-05, 2.3418117e-05,\n",
            "       2.1454700e-05, 2.3522905e-05, 3.4793600e-05, 3.0180796e-05,\n",
            "       2.8559012e-05, 4.1498024e-05, 2.9211109e-05, 2.6268099e-05,\n",
            "       2.7694412e-05, 1.7393457e-05, 2.5263418e-05, 2.1271877e-05,\n",
            "       3.1388521e-05, 4.9729752e-11, 1.9449062e-05, 1.7018981e-05,\n",
            "       2.0972815e-05, 1.9864954e-05, 4.9729752e-11, 2.8170569e-05,\n",
            "       3.9572878e-05, 2.8792678e-05, 2.0074811e-09, 3.1414595e-05,\n",
            "       1.8854069e-05, 2.8482556e-05, 3.5818346e-05, 3.4787437e-05,\n",
            "       8.6000457e-11, 2.9182156e-05, 1.9299194e-05, 4.9729752e-11,\n",
            "       1.8686887e-05, 2.5754975e-05, 3.6041078e-05, 2.4322529e-05,\n",
            "       2.7929249e-05, 3.1910713e-05, 1.7517648e-05, 2.2010829e-05,\n",
            "       1.9214796e-05, 3.0450501e-05, 1.4485774e-05, 1.8189470e-05,\n",
            "       4.9729752e-11, 2.6616925e-05, 1.8356068e-05, 2.9568349e-05,\n",
            "       2.1548429e-05, 6.9796155e-11, 2.0914489e-05, 2.6409893e-05,\n",
            "       1.8446548e-05, 2.5248239e-05, 2.3204046e-05, 2.4014500e-05,\n",
            "       1.2570171e-05, 1.7824517e-07, 2.4965595e-05, 3.6585989e-05,\n",
            "       3.8574697e-05, 3.1487612e-05, 2.4537667e-05, 2.5849402e-05,\n",
            "       2.5950279e-05, 3.2695960e-05, 2.6637537e-05, 5.5274271e-11,\n",
            "       4.9729752e-11, 2.2992162e-05, 1.7169550e-05, 1.4779411e-10],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst23', 'index': 25, 'shape': array([128,   1,   1, 128], dtype=int32), 'shape_signature': array([128,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.6451745e-03, 1.9638529e-03, 2.1923871e-03, 3.0190835e-03,\n",
            "       6.1665002e-09, 2.3238852e-03, 2.0199816e-03, 3.9370081e-09,\n",
            "       3.1721215e-03, 2.8103829e-04, 1.6752902e-03, 1.4950896e-03,\n",
            "       1.6346546e-06, 1.7646240e-03, 1.2616104e-03, 3.5248911e-03,\n",
            "       2.6565737e-03, 2.6618270e-03, 2.8418337e-03, 6.5263457e-09,\n",
            "       2.0305279e-03, 1.8906684e-03, 1.5888565e-08, 3.9370081e-09,\n",
            "       2.0024907e-03, 2.6289308e-03, 1.4902098e-03, 3.9370081e-09,\n",
            "       1.9143722e-03, 2.8701262e-03, 1.6688542e-03, 1.7015669e-03,\n",
            "       1.2682938e-03, 2.0980707e-03, 1.9333528e-03, 2.2597355e-03,\n",
            "       2.4912381e-03, 1.4552869e-03, 1.6618470e-03, 2.1427590e-03,\n",
            "       2.4394081e-03, 1.6024488e-03, 2.0471464e-03, 4.2800985e-09,\n",
            "       2.6941558e-03, 2.1619007e-03, 2.4638390e-03, 2.4499286e-03,\n",
            "       2.8603610e-03, 7.9955244e-06, 1.9891791e-03, 1.0604215e-03,\n",
            "       5.1513096e-09, 2.9963779e-03, 1.6278514e-03, 1.8539669e-03,\n",
            "       1.6985270e-03, 1.8622628e-03, 2.7545418e-03, 2.3893551e-03,\n",
            "       2.2609616e-03, 3.2853179e-03, 2.3125869e-03, 2.0795944e-03,\n",
            "       2.1925129e-03, 1.3770063e-03, 2.0000557e-03, 1.6840532e-03,\n",
            "       2.4849684e-03, 3.9370081e-09, 1.5397446e-03, 1.3473597e-03,\n",
            "       1.6603770e-03, 1.5726698e-03, 3.9370081e-09, 2.2302093e-03,\n",
            "       3.1329079e-03, 2.2794604e-03, 1.5892839e-07, 2.4870324e-03,\n",
            "       1.4926401e-03, 2.2549087e-03, 2.8356691e-03, 2.7540540e-03,\n",
            "       6.8084893e-09, 2.3102947e-03, 1.5278797e-03, 3.9370081e-09,\n",
            "       1.4794046e-03, 2.0389713e-03, 2.8533021e-03, 1.9255675e-03,\n",
            "       2.2111044e-03, 2.5263091e-03, 1.3868383e-03, 1.7425546e-03,\n",
            "       1.5211982e-03, 2.4107071e-03, 1.1468106e-03, 1.4400251e-03,\n",
            "       3.9370081e-09, 2.1072102e-03, 1.4532143e-03, 2.3408688e-03,\n",
            "       1.7059473e-03, 5.5256262e-09, 1.6557595e-03, 2.0908199e-03,\n",
            "       1.4603774e-03, 1.9988541e-03, 1.8370192e-03, 1.9011814e-03,\n",
            "       9.9515601e-04, 1.4111324e-05, 1.9764777e-03, 2.8964416e-03,\n",
            "       3.0538838e-03, 2.4928132e-03, 1.9425994e-03, 2.0464470e-03,\n",
            "       2.0544333e-03, 2.5884758e-03, 2.1088421e-03, 4.3759569e-09,\n",
            "       3.9370081e-09, 1.8202448e-03, 1.3592800e-03, 1.1700573e-08],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst24', 'index': 26, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.15427916e-04, 1.24793733e-04, 8.25653697e-05, 9.81922567e-05,\n",
            "       8.23696319e-05, 9.12493051e-05, 1.25052204e-04, 9.75323783e-05,\n",
            "       2.15171487e-04, 3.45527005e-05, 1.52969675e-04, 7.53062122e-05,\n",
            "       7.42039701e-05, 3.39685300e-07, 1.21800760e-04, 3.19165555e-10,\n",
            "       9.69068205e-05, 9.98199425e-07, 1.10696281e-04, 4.10126034e-07,\n",
            "       9.56764634e-05, 9.19506274e-05, 9.15226919e-05, 1.16881653e-04,\n",
            "       1.20412711e-04, 3.15975994e-05, 1.02832084e-04, 6.26419642e-05,\n",
            "       1.00264217e-04, 1.17502517e-04, 1.14609342e-04, 1.47979699e-06,\n",
            "       1.17127056e-04, 1.04938263e-04, 6.52783492e-05, 8.12678627e-05,\n",
            "       8.32256846e-05, 9.52129340e-05, 1.15556133e-04, 9.43033156e-05,\n",
            "       9.12426331e-05, 1.10472211e-04, 1.02104343e-04, 1.22687139e-04,\n",
            "       1.44190315e-04, 3.97843069e-05, 8.39411296e-05, 1.02797079e-04,\n",
            "       9.71039190e-05, 8.07663309e-05, 1.04865182e-06, 9.76620140e-05,\n",
            "       1.11041576e-04, 2.48570245e-07, 1.82041418e-04, 1.13413240e-04,\n",
            "       1.10596447e-04, 1.15026276e-04, 9.63988641e-05, 1.01524136e-04,\n",
            "       1.17200645e-04, 1.28144355e-04, 7.97164685e-05, 1.23746810e-04,\n",
            "       7.46397855e-05, 1.10621389e-04, 9.92786299e-05, 8.89728690e-05,\n",
            "       1.31761859e-04, 1.01935126e-04, 1.25476799e-04, 9.85166407e-05,\n",
            "       9.70374313e-05, 1.08172928e-04, 1.10427267e-04, 9.82347774e-05,\n",
            "       8.72970413e-05, 1.04908890e-04, 8.43926900e-05, 1.55438916e-04,\n",
            "       1.04745777e-04, 1.23460821e-04, 1.16204101e-04, 7.93900253e-05,\n",
            "       9.97213065e-05, 9.14384073e-05, 1.23790072e-04, 1.13828981e-04,\n",
            "       7.47897066e-05, 1.10230889e-04, 1.29498483e-04, 9.51597249e-05,\n",
            "       1.17622069e-04, 7.72263520e-05, 8.10236234e-05, 7.52821943e-05,\n",
            "       1.00939564e-04, 1.22374142e-04, 1.18133983e-04, 1.13004884e-04,\n",
            "       8.96385900e-05, 7.94137304e-05, 1.05660234e-04, 1.01489342e-04,\n",
            "       1.05011743e-04, 6.83662583e-05, 6.89852168e-05, 1.11915171e-04,\n",
            "       1.08947592e-04, 1.23344289e-04, 1.00747486e-04, 6.47099077e-05,\n",
            "       1.11097608e-04, 9.85972201e-06, 7.55688379e-05, 1.00983336e-04,\n",
            "       1.48945881e-04, 1.14569011e-04, 1.04133935e-04, 1.50481035e-04,\n",
            "       1.01576625e-04, 1.47402126e-04, 1.30975590e-04, 9.22813415e-05,\n",
            "       1.31561916e-04, 9.19347149e-05, 7.70038969e-05, 1.13211179e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst25', 'index': 27, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.75819957e-03, 1.05499793e-02, 6.98002195e-03, 8.30110814e-03,\n",
            "       6.96347421e-03, 7.71415606e-03, 1.05718300e-02, 8.24532285e-03,\n",
            "       1.81904547e-02, 2.92106252e-03, 1.29319550e-02, 6.36633718e-03,\n",
            "       6.27315463e-03, 2.87167713e-05, 1.02969557e-02, 2.69820450e-08,\n",
            "       8.19243863e-03, 8.43871167e-05, 9.35819000e-03, 3.46717825e-05,\n",
            "       8.08842480e-03, 7.77344545e-03, 7.73726776e-03, 9.88109782e-03,\n",
            "       1.01796109e-02, 2.67124013e-03, 8.69335607e-03, 5.29571017e-03,\n",
            "       8.47627036e-03, 9.93358530e-03, 9.68899764e-03, 1.25101054e-04,\n",
            "       9.90184397e-03, 8.87141097e-03, 5.51858870e-03, 6.87033124e-03,\n",
            "       7.03584403e-03, 8.04923847e-03, 9.76903923e-03, 7.97234010e-03,\n",
            "       7.71359168e-03, 9.33924783e-03, 8.63183383e-03, 1.03718890e-02,\n",
            "       1.21897534e-02, 3.36333900e-03, 7.09632738e-03, 8.69039726e-03,\n",
            "       8.20910092e-03, 6.82793185e-03, 8.86523339e-05, 8.25628173e-03,\n",
            "       9.38738137e-03, 2.10139642e-05, 1.53896613e-02, 9.58788022e-03,\n",
            "       9.34975035e-03, 9.72424541e-03, 8.14949628e-03, 8.58278293e-03,\n",
            "       9.90806520e-03, 1.08332392e-02, 6.73917728e-03, 1.04614729e-02,\n",
            "       6.30999776e-03, 9.35185887e-03, 8.39294959e-03, 7.52170756e-03,\n",
            "       1.11390604e-02, 8.61752778e-03, 1.06077250e-02, 8.32853187e-03,\n",
            "       8.20348039e-03, 9.14486777e-03, 9.33544803e-03, 8.30470305e-03,\n",
            "       7.38003431e-03, 8.86892807e-03, 7.13450229e-03, 1.31407036e-02,\n",
            "       8.85513891e-03, 1.04372958e-02, 9.82381776e-03, 6.71158032e-03,\n",
            "       8.43037292e-03, 7.73014268e-03, 1.04651302e-02, 9.62302648e-03,\n",
            "       6.32267212e-03, 9.31884628e-03, 1.09477164e-02, 8.04474019e-03,\n",
            "       9.94369201e-03, 6.52866438e-03, 6.84968336e-03, 6.36430690e-03,\n",
            "       8.53336416e-03, 1.03454292e-02, 9.98696871e-03, 9.55335796e-03,\n",
            "       7.57798692e-03, 6.71358407e-03, 8.93244613e-03, 8.57984181e-03,\n",
            "       8.87762289e-03, 5.77963796e-03, 5.83196478e-03, 9.46123432e-03,\n",
            "       9.21035744e-03, 1.04274442e-02, 8.51712562e-03, 5.47053292e-03,\n",
            "       9.39211808e-03, 8.33534345e-04, 6.38853945e-03, 8.53706431e-03,\n",
            "       1.25917867e-02, 9.68558807e-03, 8.80341418e-03, 1.27215665e-02,\n",
            "       8.58722068e-03, 1.24612777e-02, 1.10725900e-02, 7.80140329e-03,\n",
            "       1.11221578e-02, 7.77209969e-03, 6.50985818e-03, 9.57079791e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst26', 'index': 28, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.7981808e-05, 5.0339069e-05, 3.1239419e-05, 4.5197798e-05,\n",
            "       3.9906969e-05, 5.4269367e-05, 4.1183557e-05, 3.3487020e-05,\n",
            "       3.9784867e-05, 3.2848795e-05, 4.1508083e-05, 2.3852186e-05,\n",
            "       4.5332359e-05, 9.8783558e-11, 4.7386548e-05, 7.7282292e-11,\n",
            "       5.5762623e-05, 2.3229092e-09, 4.1427422e-05, 1.1463422e-10,\n",
            "       4.5367571e-05, 6.3345004e-05, 3.5849847e-05, 3.8731643e-05,\n",
            "       3.9969407e-05, 1.9082638e-05, 4.1289353e-05, 3.5029760e-05,\n",
            "       4.4889781e-05, 4.5770612e-05, 5.2259162e-05, 1.3704799e-06,\n",
            "       2.6252097e-05, 3.6243528e-05, 3.9566643e-05, 4.4678629e-05,\n",
            "       4.7667396e-05, 4.2622894e-05, 4.2314401e-05, 3.9085968e-05,\n",
            "       2.7274960e-05, 3.2550102e-05, 3.1696720e-05, 4.3460743e-05,\n",
            "       5.2343734e-05, 1.8726099e-05, 4.5996479e-05, 4.4553803e-05,\n",
            "       5.4843928e-05, 4.6585646e-05, 9.7985051e-09, 4.3940803e-05,\n",
            "       2.8864923e-05, 6.0675354e-10, 3.1237192e-05, 4.1012740e-05,\n",
            "       3.1816922e-05, 4.4224143e-05, 3.3710861e-05, 4.3297638e-05,\n",
            "       3.7690188e-05, 4.0402316e-05, 3.9726430e-05, 4.9598824e-05,\n",
            "       3.2998305e-05, 3.8575305e-05, 4.8962349e-05, 3.0506979e-05,\n",
            "       4.4954799e-05, 4.0434395e-05, 3.6585901e-05, 3.1446965e-05,\n",
            "       4.6933728e-05, 3.0911364e-05, 3.0819338e-05, 4.4654800e-05,\n",
            "       4.9487477e-05, 2.8612090e-05, 4.6623420e-05, 4.8712121e-05,\n",
            "       3.9629682e-05, 4.2452757e-05, 3.1070536e-05, 3.8796617e-05,\n",
            "       4.1004550e-05, 2.7138469e-05, 4.0015966e-05, 3.4003933e-05,\n",
            "       3.8246155e-05, 3.8370454e-05, 3.2588392e-05, 4.4391316e-05,\n",
            "       4.9266218e-05, 4.2314619e-05, 3.3372173e-05, 3.3989854e-05,\n",
            "       3.9370192e-05, 4.3172669e-05, 5.6169793e-05, 5.3068798e-05,\n",
            "       4.7692432e-05, 3.3522716e-05, 4.0266761e-05, 4.7501566e-05,\n",
            "       3.0447012e-05, 4.3491487e-05, 2.8218918e-05, 6.2521038e-05,\n",
            "       3.0879535e-05, 4.7904356e-05, 4.2579628e-05, 5.3648397e-05,\n",
            "       2.9251489e-05, 3.4789631e-05, 3.7635735e-05, 4.0058258e-05,\n",
            "       4.5912249e-05, 3.1179832e-05, 2.4120862e-05, 4.4673994e-05,\n",
            "       4.3629239e-05, 4.3860098e-05, 5.0267852e-05, 4.5725657e-05,\n",
            "       4.5526060e-05, 3.7065409e-05, 5.6387216e-05, 5.6056004e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst27', 'index': 29, 'shape': array([128,   1,   1, 128], dtype=int32), 'shape_signature': array([128,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.9349152e-03, 2.5644337e-03, 1.5914362e-03, 2.3025209e-03,\n",
            "       2.0329889e-03, 2.7646557e-03, 2.0980225e-03, 1.7059362e-03,\n",
            "       2.0267689e-03, 1.6734230e-03, 2.1145549e-03, 1.2151069e-03,\n",
            "       2.3093759e-03, 5.0323514e-09, 2.4140228e-03, 3.9370081e-09,\n",
            "       2.8407269e-03, 1.1833645e-07, 2.1104459e-03, 5.8398348e-09,\n",
            "       2.3111696e-03, 3.2269978e-03, 1.8263062e-03, 1.9731142e-03,\n",
            "       2.0361699e-03, 9.7213080e-04, 2.1034121e-03, 1.7845283e-03,\n",
            "       2.2868295e-03, 2.3317018e-03, 2.6622494e-03, 6.9816648e-05,\n",
            "       1.3373661e-03, 1.8463616e-03, 2.0156517e-03, 2.2760727e-03,\n",
            "       2.4283300e-03, 2.1713469e-03, 2.1556313e-03, 1.9911646e-03,\n",
            "       1.3894740e-03, 1.6582067e-03, 1.6147327e-03, 2.2140297e-03,\n",
            "       2.6665577e-03, 9.5396762e-04, 2.3432083e-03, 2.2697137e-03,\n",
            "       2.7939256e-03, 2.3732223e-03, 4.9916730e-07, 2.2384855e-03,\n",
            "       1.4704717e-03, 3.0909973e-08, 1.5913227e-03, 2.0893204e-03,\n",
            "       1.6208561e-03, 2.2529198e-03, 1.7173395e-03, 2.2057206e-03,\n",
            "       1.9200591e-03, 2.0582236e-03, 2.0237919e-03, 2.5267233e-03,\n",
            "       1.6810396e-03, 1.9651498e-03, 2.4942991e-03, 1.5541234e-03,\n",
            "       2.2901418e-03, 2.0598578e-03, 1.8638031e-03, 1.6020093e-03,\n",
            "       2.3909546e-03, 1.5747240e-03, 1.5700359e-03, 2.2748588e-03,\n",
            "       2.5210509e-03, 1.4575917e-03, 2.3751466e-03, 2.4815518e-03,\n",
            "       2.0188631e-03, 2.1626796e-03, 1.5828328e-03, 1.9764241e-03,\n",
            "       2.0889034e-03, 1.3825207e-03, 2.0385417e-03, 1.7322694e-03,\n",
            "       1.9483819e-03, 1.9547141e-03, 1.6601572e-03, 2.2614361e-03,\n",
            "       2.5097793e-03, 2.1556425e-03, 1.7000855e-03, 1.7315523e-03,\n",
            "       2.0056439e-03, 2.1993543e-03, 2.8614695e-03, 2.7034949e-03,\n",
            "       2.4296055e-03, 1.7077547e-03, 2.0513181e-03, 2.4198822e-03,\n",
            "       1.5510685e-03, 2.2155959e-03, 1.4375622e-03, 3.1850224e-03,\n",
            "       1.5731027e-03, 2.4404016e-03, 2.1691429e-03, 2.7330215e-03,\n",
            "       1.4901647e-03, 1.7722955e-03, 1.9172850e-03, 2.0406961e-03,\n",
            "       2.3389172e-03, 1.5884007e-03, 1.2287941e-03, 2.2758367e-03,\n",
            "       2.2226134e-03, 2.2343742e-03, 2.5608058e-03, 2.3294117e-03,\n",
            "       2.3192435e-03, 1.8882309e-03, 2.8725457e-03, 2.8556727e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst28', 'index': 30, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.3462149e-04, 1.9637708e-04, 2.0294478e-04, 1.7462549e-04,\n",
            "       1.7801306e-04, 2.0582967e-04, 2.0126253e-04, 2.2959705e-04,\n",
            "       1.8981387e-04, 1.7289314e-04, 2.5656022e-04, 2.5325804e-04,\n",
            "       2.1215856e-04, 1.8529163e-04, 2.4607740e-04, 2.6594719e-04,\n",
            "       1.2953659e-04, 2.7796824e-04, 1.6817050e-04, 2.3826830e-04,\n",
            "       2.8791829e-04, 1.7009907e-04, 2.7477375e-04, 1.7719166e-04,\n",
            "       1.5376812e-04, 2.8333921e-04, 1.6646809e-04, 1.8519271e-04,\n",
            "       1.6960698e-04, 2.1257305e-04, 1.5421826e-04, 1.5426039e-04,\n",
            "       1.9383032e-04, 2.0697685e-04, 2.1234388e-04, 2.3042857e-04,\n",
            "       2.9957073e-04, 2.1637234e-04, 1.5040033e-04, 1.9908813e-04,\n",
            "       1.7745621e-04, 1.9888005e-04, 2.2431530e-04, 1.9140363e-04,\n",
            "       2.2305688e-04, 1.6494891e-04, 2.1835727e-04, 2.7643252e-04,\n",
            "       1.5972383e-04, 2.1625626e-04, 1.5131485e-04, 1.9294204e-04,\n",
            "       1.9044887e-04, 3.3488794e-04, 2.1356906e-04, 1.8748968e-04,\n",
            "       2.4158739e-04, 3.6010702e-04, 2.3046325e-04, 1.7660287e-04,\n",
            "       1.7722056e-04, 1.7444760e-04, 2.4385296e-04, 2.3424655e-04,\n",
            "       3.1729261e-04, 2.1764122e-04, 1.6453445e-04, 2.2227837e-04,\n",
            "       2.5546690e-04, 1.9381806e-04, 1.4936404e-04, 2.0603927e-04,\n",
            "       2.0899223e-04, 2.1597695e-04, 2.6144300e-04, 1.8562673e-04,\n",
            "       2.2245827e-04, 1.8489372e-04, 2.5668432e-04, 1.8095497e-04,\n",
            "       2.1804249e-04, 2.0797146e-04, 2.7536185e-04, 3.3945622e-04,\n",
            "       2.4448763e-04, 2.6971710e-04, 1.5157789e-04, 2.4670907e-04,\n",
            "       2.6952705e-04, 2.3149770e-04, 2.5453305e-04, 2.6657645e-04,\n",
            "       2.7280711e-04, 2.4515921e-06, 2.1013504e-04, 1.9058562e-04,\n",
            "       2.1238823e-04, 2.8452559e-04, 1.8164661e-04, 1.7280497e-04,\n",
            "       2.4299634e-04, 2.2708463e-04, 2.2868208e-04, 1.9818550e-04,\n",
            "       2.9492241e-04, 1.8065529e-04, 2.7280219e-04, 2.5010871e-04,\n",
            "       2.2348987e-04, 1.9142796e-04, 2.2527415e-04, 2.8996856e-04,\n",
            "       1.9835772e-04, 1.3629589e-04, 2.3307349e-04, 2.1931290e-04,\n",
            "       2.4274565e-04, 1.7521034e-04, 1.7920278e-04, 2.4727391e-04,\n",
            "       2.6322453e-04, 1.3525593e-04, 1.6784787e-04, 1.6968258e-04,\n",
            "       2.1587257e-04, 1.8380392e-04, 1.9718884e-04, 2.3689364e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst29', 'index': 31, 'shape': array([  1,   3,   3, 128], dtype=int32), 'shape_signature': array([  1,   3,   3, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01066162, 0.00892373, 0.00922217, 0.00793529, 0.00808923,\n",
            "       0.00935327, 0.00914573, 0.0104333 , 0.00862548, 0.00785657,\n",
            "       0.01165856, 0.0115085 , 0.00964087, 0.00841998, 0.0111822 ,\n",
            "       0.01208512, 0.00588637, 0.01263137, 0.00764197, 0.01082734,\n",
            "       0.01308352, 0.00772961, 0.01248621, 0.00805191, 0.0069875 ,\n",
            "       0.01287544, 0.00756461, 0.00841549, 0.00770725, 0.0096597 ,\n",
            "       0.00700795, 0.00700987, 0.008808  , 0.0094054 , 0.00964929,\n",
            "       0.01047109, 0.01361303, 0.00983235, 0.00683446, 0.00904692,\n",
            "       0.00806393, 0.00903747, 0.01019329, 0.00869772, 0.0101361 ,\n",
            "       0.00749557, 0.00992255, 0.01256159, 0.00725814, 0.00982707,\n",
            "       0.00687602, 0.00876763, 0.00865434, 0.01521791, 0.00970496,\n",
            "       0.00851987, 0.01097816, 0.01636391, 0.01047266, 0.00802515,\n",
            "       0.00805322, 0.00792721, 0.01108112, 0.01064458, 0.01441834,\n",
            "       0.00989001, 0.00747674, 0.01010073, 0.01160887, 0.00880744,\n",
            "       0.00678737, 0.00936279, 0.00949698, 0.00981438, 0.01188044,\n",
            "       0.00843521, 0.0101089 , 0.0084019 , 0.0116642 , 0.00822292,\n",
            "       0.00990824, 0.0094506 , 0.01251294, 0.0154255 , 0.01110996,\n",
            "       0.01225643, 0.00688797, 0.0112109 , 0.01224779, 0.01051967,\n",
            "       0.01156644, 0.01211371, 0.01239684, 0.0001114 , 0.00954891,\n",
            "       0.00866055, 0.0096513 , 0.01292935, 0.00825435, 0.00785257,\n",
            "       0.01104219, 0.01031913, 0.01039172, 0.0090059 , 0.0134018 ,\n",
            "       0.0082093 , 0.01239662, 0.01136539, 0.01015578, 0.00869883,\n",
            "       0.01023686, 0.01317669, 0.00901373, 0.00619353, 0.01059128,\n",
            "       0.00996597, 0.0110308 , 0.00796187, 0.0081433 , 0.01123657,\n",
            "       0.01196139, 0.00614627, 0.00762731, 0.00771068, 0.00980964,\n",
            "       0.00835238, 0.00896061, 0.01076487], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst30', 'index': 32, 'shape': array([128], dtype=int32), 'shape_signature': array([128], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([9.08454967e-05, 6.07661168e-05, 6.54647738e-05, 5.54684484e-05,\n",
            "       6.19412458e-05, 7.21445758e-05, 7.94728694e-05, 1.02325757e-04,\n",
            "       5.73026955e-05, 7.55595538e-05, 8.38626656e-05, 7.95250235e-05,\n",
            "       7.42087796e-05, 7.24510974e-05, 8.26849064e-05, 1.12354923e-04,\n",
            "       9.13932308e-05, 7.76481174e-05, 5.89817064e-05, 7.94624357e-05,\n",
            "       1.10575878e-04, 1.07957734e-04, 7.53849890e-05, 7.74994623e-05,\n",
            "       6.64194013e-05, 1.01857411e-04, 6.67481363e-05, 9.85523438e-05,\n",
            "       7.50570034e-05, 7.77480891e-05, 6.32109659e-05, 5.23272429e-05,\n",
            "       6.35060933e-05, 7.00163291e-05, 1.09977904e-04, 8.19659908e-05,\n",
            "       6.96107309e-05, 6.01202264e-05, 6.21728323e-05, 9.13263866e-05,\n",
            "       6.06533285e-05, 7.89671612e-05, 9.14027696e-05, 9.44966814e-05,\n",
            "       7.76503803e-05, 7.30636675e-05, 7.15693459e-05, 1.08425615e-04,\n",
            "       8.12092112e-05, 4.68903963e-05, 8.12622093e-05, 7.42495758e-05,\n",
            "       8.99022125e-05, 1.01655176e-04, 8.24608142e-05, 1.09883949e-04,\n",
            "       1.04020088e-04, 8.64710310e-05, 8.51899022e-05, 7.25005957e-05,\n",
            "       7.63289936e-05, 8.70039221e-05, 8.29618875e-05, 8.92956377e-05,\n",
            "       6.96383358e-05, 7.20032549e-05, 4.88495025e-05, 7.17840812e-05,\n",
            "       7.39243187e-05, 8.38074920e-05, 7.38367526e-05, 7.92980645e-05,\n",
            "       7.08651278e-05, 8.32687438e-05, 5.56775813e-05, 7.48808015e-05,\n",
            "       4.35883958e-05, 6.72630194e-05, 8.40905050e-05, 7.50200343e-05,\n",
            "       7.12805777e-05, 5.99634295e-05, 1.06402593e-04, 8.21563372e-05,\n",
            "       9.18786827e-05, 1.03271334e-04, 1.27028659e-04, 8.87572678e-05,\n",
            "       9.44322310e-05, 8.12611688e-05, 6.69721558e-05, 9.81373232e-05,\n",
            "       1.18689903e-04, 4.82261386e-09, 6.62346210e-05, 7.69412727e-05,\n",
            "       7.01685713e-05, 7.90548729e-05, 7.56304507e-05, 5.06220968e-05,\n",
            "       7.57277739e-05, 8.96403144e-05, 7.52950364e-05, 9.35727949e-05,\n",
            "       8.96240599e-05, 1.48986568e-04, 6.25788889e-05, 7.19316668e-05,\n",
            "       7.46055375e-05, 6.88322543e-05, 8.42707159e-05, 7.96422610e-05,\n",
            "       7.69478138e-05, 8.04004085e-05, 1.11500558e-04, 8.82923268e-05,\n",
            "       7.44445497e-05, 9.05050547e-05, 9.26086723e-05, 6.76661875e-05,\n",
            "       6.11340802e-05, 5.47252494e-05, 1.09332876e-04, 7.09884189e-05,\n",
            "       6.64816107e-05, 1.12323425e-04, 5.77659303e-05, 9.47427834e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst31', 'index': 33, 'shape': array([128,   1,   1,  64], dtype=int32), 'shape_signature': array([128,   1,   1,  64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.2814052e-03, 2.1949161e-03, 2.3646350e-03, 2.0035605e-03,\n",
            "       2.2373626e-03, 2.6059144e-03, 2.8706174e-03, 3.6960805e-03,\n",
            "       2.0698148e-03, 2.7292657e-03, 3.0291802e-03, 2.8725015e-03,\n",
            "       2.6804749e-03, 2.6169862e-03, 2.9866386e-03, 4.0583410e-03,\n",
            "       3.3011895e-03, 2.8047061e-03, 2.1304619e-03, 2.8702407e-03,\n",
            "       3.9940807e-03, 3.8995114e-03, 2.7229604e-03, 2.7993366e-03,\n",
            "       2.3991168e-03, 3.6791635e-03, 2.4109909e-03, 3.5597819e-03,\n",
            "       2.7111133e-03, 2.8083173e-03, 2.2832258e-03, 1.8900979e-03,\n",
            "       2.2938862e-03, 2.5290404e-03, 3.9724815e-03, 2.9606710e-03,\n",
            "       2.5143900e-03, 2.1715860e-03, 2.2457277e-03, 3.2987751e-03,\n",
            "       2.1908421e-03, 2.8523509e-03, 3.3015341e-03, 3.4132884e-03,\n",
            "       2.8047878e-03, 2.6391125e-03, 2.5851366e-03, 3.9164117e-03,\n",
            "       2.9333355e-03, 1.6937150e-03, 2.9352498e-03, 2.6819485e-03,\n",
            "       3.2473330e-03, 3.6718585e-03, 2.9785442e-03, 3.9690877e-03,\n",
            "       3.7572808e-03, 3.1233963e-03, 3.0771210e-03, 2.6187741e-03,\n",
            "       2.7570585e-03, 3.1426447e-03, 2.9966433e-03, 3.2254229e-03,\n",
            "       2.5153870e-03, 2.6008098e-03, 1.7644794e-03, 2.5928931e-03,\n",
            "       2.6701998e-03, 3.0271872e-03, 2.6670368e-03, 2.8643035e-03,\n",
            "       2.5596996e-03, 3.0077272e-03, 2.0111145e-03, 2.7047487e-03,\n",
            "       1.5744444e-03, 2.4295889e-03, 3.0374099e-03, 2.7097780e-03,\n",
            "       2.5747060e-03, 2.1659224e-03, 3.8433387e-03, 2.9675465e-03,\n",
            "       3.3187245e-03, 3.7302354e-03, 4.5883670e-03, 3.2059767e-03,\n",
            "       3.4109605e-03, 2.9352123e-03, 2.4190827e-03, 3.5447911e-03,\n",
            "       4.2871651e-03, 1.7419630e-07, 2.3924424e-03, 2.7791744e-03,\n",
            "       2.5345394e-03, 2.8555193e-03, 2.7318266e-03, 1.8285067e-03,\n",
            "       2.7353419e-03, 3.2378731e-03, 2.7197113e-03, 3.3799170e-03,\n",
            "       3.2372859e-03, 5.3815027e-03, 2.2603946e-03, 2.5982237e-03,\n",
            "       2.6948061e-03, 2.4862709e-03, 3.0439193e-03, 2.8767362e-03,\n",
            "       2.7794107e-03, 2.9041208e-03, 4.0274807e-03, 3.1891826e-03,\n",
            "       2.6889909e-03, 3.2691080e-03, 3.3450923e-03, 2.4441518e-03,\n",
            "       2.2082073e-03, 1.9767156e-03, 3.9491826e-03, 2.5641529e-03,\n",
            "       2.4013638e-03, 4.0572034e-03, 2.0865472e-03, 3.4221779e-03],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst32', 'index': 34, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.43584111e-04, 1.45490209e-04, 1.82663600e-04, 1.52796580e-04,\n",
            "       1.31417270e-04, 1.74965127e-04, 1.97339265e-04, 1.34210844e-04,\n",
            "       1.34361617e-04, 1.93002576e-04, 1.17235431e-04, 1.28091488e-04,\n",
            "       1.29262364e-04, 1.16911178e-04, 1.21625366e-04, 1.60052383e-04,\n",
            "       1.65379490e-04, 1.40013217e-04, 1.33390495e-04, 1.34770948e-04,\n",
            "       1.67187987e-04, 1.74837667e-04, 1.39149881e-04, 1.10501445e-04,\n",
            "       1.64739831e-04, 1.40392352e-04, 1.71671083e-04, 2.06071476e-04,\n",
            "       1.12951966e-04, 1.82046744e-04, 1.37242023e-04, 1.17251642e-04,\n",
            "       1.62119613e-04, 1.20511082e-04, 8.97298451e-05, 1.04580118e-04,\n",
            "       1.00542260e-04, 1.24694387e-04, 1.06781365e-04, 9.99779513e-05,\n",
            "       1.30009939e-04, 1.15929724e-04, 1.45099941e-04, 1.47607396e-04,\n",
            "       9.67005471e-05, 1.43663812e-04, 9.82406636e-05, 2.45866104e-04,\n",
            "       1.11203342e-04, 1.25538631e-04, 1.72194894e-04, 1.28267653e-04,\n",
            "       1.29334090e-04, 1.28633386e-04, 9.27063084e-05, 2.14788495e-04,\n",
            "       1.66267331e-04, 1.21776138e-04, 1.50821128e-04, 1.46287464e-04,\n",
            "       1.12902446e-04, 1.32250163e-04, 1.15551673e-04, 1.14741153e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst33', 'index': 35, 'shape': array([ 1,  3,  3, 64], dtype=int32), 'shape_signature': array([ 1,  3,  3, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00824859, 0.00835809, 0.01049362, 0.00877782, 0.00754963,\n",
            "       0.01005136, 0.0113367 , 0.00771011, 0.00771878, 0.01108757,\n",
            "       0.00673491, 0.00735857, 0.00742583, 0.00671629, 0.00698711,\n",
            "       0.00919465, 0.00950068, 0.00804345, 0.00766299, 0.00774229,\n",
            "       0.00960458, 0.01004403, 0.00799385, 0.00634806, 0.00946394,\n",
            "       0.00806523, 0.00986212, 0.01183835, 0.00648884, 0.01045818,\n",
            "       0.00788425, 0.00673585, 0.00931341, 0.00692309, 0.00515478,\n",
            "       0.00600789, 0.00577593, 0.00716341, 0.00613435, 0.00574351,\n",
            "       0.00746878, 0.0066599 , 0.00833567, 0.00847972, 0.00555523,\n",
            "       0.00825317, 0.00564371, 0.01412446, 0.00638838, 0.00721191,\n",
            "       0.00989221, 0.00736869, 0.00742996, 0.0073897 , 0.00532577,\n",
            "       0.01233912, 0.00955169, 0.00699577, 0.00866434, 0.00840389,\n",
            "       0.00648599, 0.00759748, 0.00663819, 0.00659162], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst34', 'index': 36, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.61483131e-05, 6.88589134e-05, 6.54527757e-05, 9.15964920e-05,\n",
            "       8.86420748e-05, 8.42108857e-05, 8.49993521e-05, 6.78927317e-05,\n",
            "       8.12419821e-05, 8.80185180e-05, 9.03831678e-05, 8.74313118e-05,\n",
            "       1.14127601e-04, 9.14192715e-05, 8.52098601e-05, 1.13416791e-04,\n",
            "       9.54519783e-05, 1.02688347e-04, 1.10752801e-04, 9.07127396e-05,\n",
            "       1.31881607e-04, 9.59794997e-05, 8.71783195e-05, 8.43728194e-05,\n",
            "       9.53214403e-05, 8.90420779e-05, 1.07633328e-04, 9.47971712e-05,\n",
            "       9.86238665e-05, 1.10978697e-04, 1.03361061e-04, 7.40285104e-05,\n",
            "       7.85716911e-05, 9.02543397e-05, 1.20745746e-04, 1.19500306e-04,\n",
            "       1.20809127e-04, 9.13638360e-05, 7.33255729e-05, 1.27568608e-04,\n",
            "       1.03723294e-04, 8.25191237e-05, 6.76595082e-05, 8.06389507e-05,\n",
            "       9.12729374e-05, 8.88393915e-05, 9.25740678e-05, 6.93933616e-05,\n",
            "       9.55385403e-05, 1.03268692e-04, 8.08357436e-05, 7.97178363e-05,\n",
            "       9.69126486e-05, 8.12959552e-05, 1.31317895e-04, 7.46880323e-05,\n",
            "       9.19687373e-05, 1.10537025e-04, 7.22857512e-05, 9.59641620e-05,\n",
            "       8.85094560e-05, 1.02757564e-04, 8.88780778e-05, 1.03282939e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst35', 'index': 37, 'shape': array([64,  1,  1, 64], dtype=int32), 'shape_signature': array([64,  1,  1, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00297619, 0.00237889, 0.00226122, 0.00316441, 0.00306235,\n",
            "       0.00290926, 0.0029365 , 0.00234551, 0.00280669, 0.0030408 ,\n",
            "       0.0031225 , 0.00302052, 0.0039428 , 0.00315829, 0.00294377,\n",
            "       0.00391825, 0.00329761, 0.00354761, 0.00382621, 0.00313388,\n",
            "       0.00455616, 0.00331583, 0.00301178, 0.00291486, 0.0032931 ,\n",
            "       0.00307617, 0.00371844, 0.00327499, 0.00340719, 0.00383402,\n",
            "       0.00357085, 0.00255749, 0.00271444, 0.00311805, 0.00417144,\n",
            "       0.00412842, 0.00417363, 0.00315638, 0.0025332 , 0.00440715,\n",
            "       0.00358336, 0.00285081, 0.00233745, 0.00278586, 0.00315324,\n",
            "       0.00306916, 0.00319819, 0.00239735, 0.0033006 , 0.00356766,\n",
            "       0.00279266, 0.00275404, 0.00334807, 0.00280856, 0.00453668,\n",
            "       0.00258027, 0.00317727, 0.00381876, 0.00249728, 0.0033153 ,\n",
            "       0.00305776, 0.00355   , 0.0030705 , 0.00356815], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst36', 'index': 38, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.7489206e-04, 1.3995066e-04, 1.8653952e-04, 2.0119580e-04,\n",
            "       2.3403922e-04, 1.8980299e-04, 2.1072601e-04, 2.6128499e-04,\n",
            "       2.4536313e-04, 1.7729923e-04, 2.1325794e-04, 1.8640852e-04,\n",
            "       1.4020517e-04, 1.1315427e-04, 2.1244302e-04, 2.2876554e-04,\n",
            "       2.5162380e-04, 2.0652769e-04, 2.2789536e-04, 1.6824607e-04,\n",
            "       2.8584339e-04, 1.3230092e-04, 1.4726925e-04, 1.2547456e-04,\n",
            "       9.4699142e-05, 1.4894769e-04, 2.2641417e-04, 1.5387980e-04,\n",
            "       1.3574987e-04, 1.1316987e-04, 1.6022132e-04, 2.1355240e-04,\n",
            "       2.6260590e-04, 1.5620046e-04, 1.3103145e-04, 1.8006064e-04,\n",
            "       1.2253717e-04, 1.4104140e-04, 1.4854966e-04, 1.1271633e-04,\n",
            "       1.2988644e-04, 1.6491076e-04, 1.8508540e-04, 1.5513078e-04,\n",
            "       3.1515918e-04, 1.8893430e-04, 1.7042419e-04, 1.4890371e-04,\n",
            "       1.5002581e-04, 2.1150478e-04, 2.3789954e-04, 3.7195385e-04,\n",
            "       2.7293139e-04, 2.0600307e-04, 2.4511258e-04, 1.2646572e-04,\n",
            "       1.9033263e-04, 3.3262488e-04, 2.4661975e-04, 1.4143252e-04,\n",
            "       1.8453975e-04, 3.0586866e-04, 2.1486428e-04, 2.9575583e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst37', 'index': 39, 'shape': array([ 1,  3,  3, 64], dtype=int32), 'shape_signature': array([ 1,  3,  3, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00818713, 0.00655143, 0.00873237, 0.00941847, 0.01095595,\n",
            "       0.00888514, 0.0098646 , 0.01223139, 0.01148605, 0.00829981,\n",
            "       0.00998313, 0.00872624, 0.00656335, 0.00529703, 0.00994498,\n",
            "       0.01070908, 0.01177913, 0.00966807, 0.01066834, 0.00787601,\n",
            "       0.01338103, 0.00619333, 0.00689403, 0.00587377, 0.0044331 ,\n",
            "       0.00697261, 0.010599  , 0.00720349, 0.00635478, 0.00529776,\n",
            "       0.00750035, 0.00999691, 0.01229323, 0.00731213, 0.0061339 ,\n",
            "       0.00842908, 0.00573626, 0.00660249, 0.00695397, 0.00527653,\n",
            "       0.0060803 , 0.00771988, 0.0086643 , 0.00726205, 0.01475337,\n",
            "       0.00884448, 0.00797797, 0.00697055, 0.00702308, 0.00990106,\n",
            "       0.01113666, 0.01741207, 0.01277659, 0.00964351, 0.01147432,\n",
            "       0.00592017, 0.00890994, 0.01557099, 0.01154487, 0.0066208 ,\n",
            "       0.00863876, 0.01431846, 0.01005832, 0.01384506], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst38', 'index': 40, 'shape': array([64], dtype=int32), 'shape_signature': array([64], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.49106946e-05, 1.03715909e-04, 1.14338967e-04, 1.16192052e-04,\n",
            "       1.21496683e-04, 1.47184983e-04, 1.12526381e-04, 1.40647113e-04,\n",
            "       1.11130736e-04, 6.32466836e-05, 9.38033481e-05, 9.17511861e-05,\n",
            "       1.06839594e-04, 8.50914730e-05, 1.41790937e-04, 1.01065321e-04,\n",
            "       9.75220246e-05, 9.09464288e-05, 1.15926159e-04, 8.73895988e-05,\n",
            "       7.36953807e-05, 9.29546586e-05, 1.02002108e-04, 9.22363251e-05,\n",
            "       9.26408029e-05, 9.66895896e-05, 6.87161810e-05, 9.48474262e-05,\n",
            "       1.50339562e-04, 8.63995519e-05, 9.88263346e-05, 9.93693320e-05,\n",
            "       8.66661576e-05, 6.17779297e-05, 8.48583441e-05, 1.12851732e-04,\n",
            "       9.64457868e-05, 8.87660644e-05, 6.92591930e-05, 9.28953450e-05,\n",
            "       1.15210576e-04, 1.33036257e-04, 1.21067329e-04, 1.01924488e-04,\n",
            "       8.81768137e-05, 1.45905928e-04, 1.04937440e-04, 1.17315285e-04,\n",
            "       9.45659558e-05, 9.23068001e-05, 7.36820512e-05, 9.16513527e-05,\n",
            "       7.15485367e-05, 1.49669708e-04, 8.44628375e-05, 1.33344802e-04,\n",
            "       9.80413897e-05, 6.86906133e-05, 7.70605184e-05, 8.28419725e-05,\n",
            "       1.00002828e-04, 8.60319487e-05, 1.18029573e-04, 7.44245554e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst39', 'index': 41, 'shape': array([64,  1,  1, 32], dtype=int32), 'shape_signature': array([64,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00324116, 0.00395898, 0.00436447, 0.00443521, 0.00463769,\n",
            "       0.00561825, 0.00429528, 0.00536869, 0.00424201, 0.00241421,\n",
            "       0.0035806 , 0.00350227, 0.00407821, 0.00324806, 0.00541235,\n",
            "       0.0038578 , 0.00372255, 0.00347155, 0.00442506, 0.00333578,\n",
            "       0.00281305, 0.0035482 , 0.00389356, 0.00352078, 0.00353622,\n",
            "       0.00369077, 0.00262299, 0.00362045, 0.00573866, 0.00329799,\n",
            "       0.00377233, 0.00379306, 0.00330816, 0.00235815, 0.00323916,\n",
            "       0.0043077 , 0.00368147, 0.00338832, 0.00264372, 0.00354594,\n",
            "       0.00439774, 0.00507817, 0.0046213 , 0.00389059, 0.00336583,\n",
            "       0.00556943, 0.0040056 , 0.00447808, 0.00360971, 0.00352347,\n",
            "       0.00281254, 0.00349846, 0.0027311 , 0.00571309, 0.00322406,\n",
            "       0.00508995, 0.00374237, 0.00262201, 0.0029415 , 0.00316219,\n",
            "       0.00381724, 0.00328396, 0.00450535, 0.00284089], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
            "      dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst40', 'index': 42, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.35297407e-04, 7.87782483e-05, 1.10887340e-04, 8.62294983e-05,\n",
            "       1.26340543e-04, 1.77969501e-04, 1.61921009e-04, 1.39305223e-04,\n",
            "       7.56993613e-05, 1.03697130e-04, 9.81105113e-05, 1.04074905e-04,\n",
            "       1.29249078e-04, 1.71102918e-04, 1.14050577e-04, 1.19516350e-04,\n",
            "       1.50239939e-04, 8.85697591e-05, 1.63491219e-04, 1.48508101e-04,\n",
            "       1.23148362e-04, 1.07485823e-04, 1.18325683e-04, 1.34982445e-04,\n",
            "       9.26825742e-05, 1.41502445e-04, 1.06614214e-04, 2.49294681e-04,\n",
            "       1.17906588e-04, 1.34483780e-04, 1.90872204e-04, 1.62183700e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst41', 'index': 43, 'shape': array([ 1,  3,  3, 32], dtype=int32), 'shape_signature': array([ 1,  3,  3, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00760668, 0.00442906, 0.0062343 , 0.00484799, 0.0071031 ,\n",
            "       0.01000578, 0.0091035 , 0.007832  , 0.00425596, 0.00583005,\n",
            "       0.00551596, 0.00585129, 0.00726663, 0.00961973, 0.00641214,\n",
            "       0.00671944, 0.00844677, 0.00497956, 0.00919179, 0.00834941,\n",
            "       0.00692363, 0.00604306, 0.00665249, 0.00758897, 0.00521079,\n",
            "       0.00795553, 0.00599405, 0.01401582, 0.00662893, 0.00756093,\n",
            "       0.0107312 , 0.00911827], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst42', 'index': 44, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.0153099e-05, 7.9067817e-05, 5.4234373e-05, 7.8446283e-05,\n",
            "       5.3900345e-05, 5.2577008e-05, 4.6664223e-05, 7.0576687e-05,\n",
            "       6.1994651e-05, 9.1494156e-05, 6.6570145e-05, 4.7016820e-05,\n",
            "       6.7025794e-05, 8.5944179e-05, 5.1288876e-05, 6.4460735e-05,\n",
            "       5.5204793e-05, 8.4733962e-05, 5.5550423e-05, 5.0131668e-05,\n",
            "       7.0437280e-05, 5.6443503e-05, 7.7050026e-05, 5.8183552e-05,\n",
            "       8.5908658e-05, 4.0849405e-05, 8.9047302e-05, 4.0018069e-05,\n",
            "       5.3713298e-05, 6.4782987e-05, 5.7737168e-05, 7.2898736e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst43', 'index': 45, 'shape': array([32,  1,  1, 32], dtype=int32), 'shape_signature': array([32,  1,  1, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0032036 , 0.00421095, 0.00288838, 0.00417784, 0.00287059,\n",
            "       0.00280011, 0.00248521, 0.00375873, 0.00330167, 0.00487274,\n",
            "       0.00354535, 0.00250399, 0.00356962, 0.00457716, 0.00273151,\n",
            "       0.00343301, 0.00294006, 0.00451271, 0.00295847, 0.00266988,\n",
            "       0.00375131, 0.00300603, 0.00410348, 0.0030987 , 0.00457527,\n",
            "       0.00217553, 0.00474243, 0.00213126, 0.00286063, 0.00345017,\n",
            "       0.00307493, 0.0038824 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst44', 'index': 46, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.02093623e-04, 1.96440800e-04, 1.03853090e-04, 1.73115943e-04,\n",
            "       1.74398665e-04, 1.09044006e-04, 1.07763030e-04, 1.65556849e-04,\n",
            "       1.48759529e-04, 8.14387095e-05, 1.04025101e-04, 9.98380565e-05,\n",
            "       5.83870205e-05, 1.16414849e-04, 1.05722516e-04, 2.17252003e-04,\n",
            "       1.29389126e-04, 1.61333097e-04, 1.15762312e-04, 1.38706018e-04,\n",
            "       1.29748121e-04, 1.26716535e-04, 1.21137004e-04, 9.15585406e-05,\n",
            "       1.18304866e-04, 1.02419290e-04, 1.36009898e-04, 1.16511939e-04,\n",
            "       1.14756847e-04, 1.96201203e-04, 1.40840522e-04, 1.15820701e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst45', 'index': 47, 'shape': array([ 1,  3,  3, 32], dtype=int32), 'shape_signature': array([ 1,  3,  3, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.0115966 , 0.01127223, 0.00595933, 0.00993379, 0.0100074 ,\n",
            "       0.0062572 , 0.00618369, 0.00950004, 0.00853617, 0.00467314,\n",
            "       0.0059692 , 0.00572894, 0.00335038, 0.00668015, 0.0060666 ,\n",
            "       0.01246643, 0.00742465, 0.00925767, 0.00664271, 0.00795927,\n",
            "       0.00744525, 0.00727129, 0.00695112, 0.00525384, 0.00678861,\n",
            "       0.00587706, 0.00780456, 0.00668573, 0.00658501, 0.01125848,\n",
            "       0.00808176, 0.00664606], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst46', 'index': 48, 'shape': array([32], dtype=int32), 'shape_signature': array([32], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([6.2997162e-05, 9.9306097e-05, 7.6090968e-05, 6.4428932e-05,\n",
            "       9.0213820e-05, 6.8998372e-05, 6.6161672e-05, 4.9107282e-05,\n",
            "       5.3424868e-05, 7.7770943e-05, 1.0656891e-04, 1.0922693e-04,\n",
            "       7.3542913e-05, 5.4291100e-05, 8.8790381e-05, 7.2432711e-05,\n",
            "       7.2676747e-05, 4.2422900e-05, 7.5269993e-05, 5.7071298e-05,\n",
            "       9.5466152e-05, 8.4109815e-05, 6.1609804e-05, 1.3133579e-04,\n",
            "       8.6026805e-05, 4.9482507e-05, 6.8538197e-05, 5.5329725e-05,\n",
            "       6.3724343e-05, 4.8429549e-05, 8.6532236e-05, 9.7941855e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst47', 'index': 49, 'shape': array([32,  1,  1, 16], dtype=int32), 'shape_signature': array([32,  1,  1, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00335486, 0.00528846, 0.00405216, 0.00343111, 0.00480426,\n",
            "       0.00367445, 0.00352338, 0.00261516, 0.00284509, 0.00414162,\n",
            "       0.00567523, 0.00581678, 0.00391646, 0.00289122, 0.00472845,\n",
            "       0.00385734, 0.00387033, 0.00225919, 0.00400844, 0.00303928,\n",
            "       0.00508396, 0.00447919, 0.00328097, 0.00699417, 0.00458128,\n",
            "       0.00263515, 0.00364994, 0.00294653, 0.00339358, 0.00257907,\n",
            "       0.0046082 , 0.00521581], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst48', 'index': 50, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([2.45029310e-04, 1.74803907e-04, 1.18041782e-04, 7.98226247e-05,\n",
            "       8.48194395e-05, 1.47260973e-04, 1.67100865e-04, 2.37933491e-04,\n",
            "       1.61259988e-04, 9.80851764e-05, 2.44057010e-04, 9.05817433e-05,\n",
            "       9.07978610e-05, 9.30265014e-05, 1.10386994e-04, 1.08146072e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst49', 'index': 51, 'shape': array([ 1,  3,  3, 16], dtype=int32), 'shape_signature': array([ 1,  3,  3, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01168389, 0.00833529, 0.00562866, 0.00380623, 0.0040445 ,\n",
            "       0.00702194, 0.00796798, 0.01134553, 0.00768946, 0.00467706,\n",
            "       0.01163753, 0.00431927, 0.00432957, 0.00443584, 0.00526365,\n",
            "       0.0051568 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst50', 'index': 52, 'shape': array([16], dtype=int32), 'shape_signature': array([16], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([8.07914039e-05, 1.50084205e-04, 2.54023413e-04, 1.20742334e-04,\n",
            "       9.10037706e-05, 1.14319722e-04, 8.97624341e-05, 1.00664722e-04,\n",
            "       1.37772455e-04, 1.81732117e-04, 8.29108758e-05, 1.33051886e-04,\n",
            "       1.31935958e-04, 1.45511571e-04, 1.12895388e-04, 2.08014026e-04],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst51', 'index': 53, 'shape': array([16,  1,  1,  8], dtype=int32), 'shape_signature': array([16,  1,  1,  8], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00451198, 0.00838179, 0.0141865 , 0.00674312, 0.00508231,\n",
            "       0.00638444, 0.00501298, 0.00562185, 0.00769421, 0.01014923,\n",
            "       0.00463034, 0.00743058, 0.00736826, 0.00812642, 0.00630489,\n",
            "       0.01161701], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst52', 'index': 54, 'shape': array([8], dtype=int32), 'shape_signature': array([8], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([1.8043852e-04, 1.9830542e-04, 1.7323847e-04, 7.3410112e-05,\n",
            "       1.1016655e-04, 1.6462340e-04, 9.8756274e-05, 8.6688415e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst53', 'index': 55, 'shape': array([1, 3, 3, 8], dtype=int32), 'shape_signature': array([1, 3, 3, 8], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.01049524, 0.01153447, 0.01007644, 0.00426991, 0.00640785,\n",
            "       0.00957535, 0.00574417, 0.00504225], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 3}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst54', 'index': 56, 'shape': array([8], dtype=int32), 'shape_signature': array([8], dtype=int32), 'dtype': <class 'numpy.int32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([3.2567466e-05, 1.5142502e-05, 1.4095625e-05, 5.2020139e-05,\n",
            "       7.5366457e-05, 4.3393553e-05, 8.6376524e-05, 2.9059991e-05],\n",
            "      dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'tfl.pseudo_qconst55', 'index': 57, 'shape': array([8, 3, 3, 1], dtype=int32), 'shape_signature': array([8, 3, 3, 1], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([0.00830471, 0.00386134, 0.00359439, 0.01326515, 0.01921846,\n",
            "       0.01106536, 0.02202603, 0.0074103 ], dtype=float32), 'zero_points': array([0, 0, 0, 0, 0, 0, 0, 0], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1', 'index': 58, 'shape': array([10000,    14,    14,     8], dtype=int32), 'shape_signature': array([-1, 14, 14,  8], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.017192423343658447, -128), 'quantization_parameters': {'scales': array([0.01719242], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub', 'index': 59, 'shape': array([10000,    14,    14,     8], dtype=int32), 'shape_signature': array([-1, 14, 14,  8], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01790599152445793, -128), 'quantization_parameters': {'scales': array([0.01790599], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub', 'index': 60, 'shape': array([10000,    14,    14,    16], dtype=int32), 'shape_signature': array([-1, 14, 14, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02097155526280403, -128), 'quantization_parameters': {'scales': array([0.02097156], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub', 'index': 61, 'shape': array([10000,     7,     7,    16], dtype=int32), 'shape_signature': array([-1,  7,  7, 16], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.018777895718812943, -128), 'quantization_parameters': {'scales': array([0.0187779], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub', 'index': 62, 'shape': array([10000,     7,     7,    32], dtype=int32), 'shape_signature': array([-1,  7,  7, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01742696948349476, -128), 'quantization_parameters': {'scales': array([0.01742697], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub', 'index': 63, 'shape': array([10000,     7,     7,    32], dtype=int32), 'shape_signature': array([-1,  7,  7, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01877673901617527, -128), 'quantization_parameters': {'scales': array([0.01877674], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub', 'index': 64, 'shape': array([10000,     7,     7,    32], dtype=int32), 'shape_signature': array([-1,  7,  7, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.017786666750907898, -128), 'quantization_parameters': {'scales': array([0.01778667], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub', 'index': 65, 'shape': array([10000,     4,     4,    32], dtype=int32), 'shape_signature': array([-1,  4,  4, 32], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.026197660714387894, -128), 'quantization_parameters': {'scales': array([0.02619766], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub', 'index': 66, 'shape': array([10000,     4,     4,    64], dtype=int32), 'shape_signature': array([-1,  4,  4, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.021361839026212692, -128), 'quantization_parameters': {'scales': array([0.02136184], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub', 'index': 67, 'shape': array([10000,     4,     4,    64], dtype=int32), 'shape_signature': array([-1,  4,  4, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02894580364227295, -128), 'quantization_parameters': {'scales': array([0.0289458], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub', 'index': 68, 'shape': array([10000,     4,     4,    64], dtype=int32), 'shape_signature': array([-1,  4,  4, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.017407115548849106, -128), 'quantization_parameters': {'scales': array([0.01740712], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub', 'index': 69, 'shape': array([10000,     2,     2,    64], dtype=int32), 'shape_signature': array([-1,  2,  2, 64], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02768493816256523, -128), 'quantization_parameters': {'scales': array([0.02768494], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub', 'index': 70, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.02200617454946041, -128), 'quantization_parameters': {'scales': array([0.02200617], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub', 'index': 71, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01962970197200775, -128), 'quantization_parameters': {'scales': array([0.0196297], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub', 'index': 72, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.011828812770545483, -128), 'quantization_parameters': {'scales': array([0.01182881], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub', 'index': 73, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.012631356716156006, -128), 'quantization_parameters': {'scales': array([0.01263136], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub', 'index': 74, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.011574283242225647, -128), 'quantization_parameters': {'scales': array([0.01157428], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub', 'index': 75, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01339762657880783, -128), 'quantization_parameters': {'scales': array([0.01339763], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub', 'index': 76, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.011506822891533375, -128), 'quantization_parameters': {'scales': array([0.01150682], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub', 'index': 77, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.014721904881298542, -128), 'quantization_parameters': {'scales': array([0.0147219], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub', 'index': 78, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.013180045410990715, -128), 'quantization_parameters': {'scales': array([0.01318005], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub', 'index': 79, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.01728026755154133, -128), 'quantization_parameters': {'scales': array([0.01728027], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub', 'index': 80, 'shape': array([10000,     2,     2,   128], dtype=int32), 'shape_signature': array([ -1,   2,   2, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.012640813365578651, -128), 'quantization_parameters': {'scales': array([0.01264081], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub', 'index': 81, 'shape': array([10000,     1,     1,   128], dtype=int32), 'shape_signature': array([ -1,   1,   1, 128], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008468407206237316, -128), 'quantization_parameters': {'scales': array([0.00846841], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub', 'index': 82, 'shape': array([10000,     1,     1,   256], dtype=int32), 'shape_signature': array([ -1,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.009426194243133068, -128), 'quantization_parameters': {'scales': array([0.00942619], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub', 'index': 83, 'shape': array([10000,     1,     1,   256], dtype=int32), 'shape_signature': array([ -1,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.006344756577163935, -128), 'quantization_parameters': {'scales': array([0.00634476], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub', 'index': 84, 'shape': array([10000,     1,     1,   256], dtype=int32), 'shape_signature': array([ -1,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008856091648340225, -128), 'quantization_parameters': {'scales': array([0.00885609], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/average_pooling2d_1_1/AvgPool', 'index': 85, 'shape': array([10000,     1,     1,   256], dtype=int32), 'shape_signature': array([ -1,   1,   1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008856091648340225, -128), 'quantization_parameters': {'scales': array([0.00885609], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/flatten_1_1/Reshape', 'index': 86, 'shape': array([10000,   256], dtype=int32), 'shape_signature': array([ -1, 256], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.008856091648340225, -128), 'quantization_parameters': {'scales': array([0.00885609], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add', 'index': 87, 'shape': array([10000,    10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.04402478411793709, 26), 'quantization_parameters': {'scales': array([0.04402478], dtype=float32), 'zero_points': array([26], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': 'StatefulPartitionedCall_1:0', 'index': 88, 'shape': array([10000,    10], dtype=int32), 'shape_signature': array([-1, 10], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.00390625, -128), 'quantization_parameters': {'scales': array([0.00390625], dtype=float32), 'zero_points': array([-128], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
            "{'name': '', 'index': 95, 'shape': array([10000,    14,    14,     9], dtype=int32), 'shape_signature': array([10000,    14,    14,     9], dtype=int32), 'dtype': <class 'numpy.int8'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tvm --pre"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baT4-X7Fp34U",
        "outputId": "7b50370b-10fd-489a-8ac9-2f49349922a8"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tvm in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: appdirs in /usr/local/lib/python3.10/dist-packages (from tvm) (1.4.4)\n",
            "Requirement already satisfied: docopt in /usr/local/lib/python3.10/dist-packages (from tvm) (0.6.2)\n",
            "Requirement already satisfied: inform in /usr/local/lib/python3.10/dist-packages (from tvm) (1.31)\n",
            "Requirement already satisfied: quantiphy in /usr/local/lib/python3.10/dist-packages (from tvm) (2.20)\n",
            "Requirement already satisfied: arrow in /usr/local/lib/python3.10/dist-packages (from inform->tvm) (1.3.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from inform->tvm) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from arrow->inform->tvm) (2.8.2)\n",
            "Requirement already satisfied: types-python-dateutil>=2.8.10 in /usr/local/lib/python3.10/dist-packages (from arrow->inform->tvm) (2.9.0.20240906)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "hzMEl3A65RXP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d82cbfe2-8710-4c1a-f2d8-290d43b6aa21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: apache-tvm in /usr/local/lib/python3.10/dist-packages (0.14.dev273)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (24.2.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (2.2.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.4.2)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (0.3.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.23.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (5.9.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (1.10.1)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (6.3.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from apache-tvm) (4.12.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install apache-tvm --pre"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyserial==3.5 tflite==2.1 Pillow==9.0 typing_extensions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YEanC868Jigb",
        "outputId": "d944c153-1413-4b3f-c829-5565f17ad837"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyserial==3.5 in /usr/local/lib/python3.10/dist-packages (3.5)\n",
            "Requirement already satisfied: tflite==2.1 in /usr/local/lib/python3.10/dist-packages (2.1.0)\n",
            "Requirement already satisfied: Pillow==9.0 in /usr/local/lib/python3.10/dist-packages (9.0.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.10/dist-packages (4.12.2)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from tflite==2.1) (24.3.25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "XMwfdj355SX8"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import tarfile\n",
        "import pathlib\n",
        "import tempfile\n",
        "import numpy as np\n",
        "\n",
        "import tvm\n",
        "import tvm.micro\n",
        "import tvm.micro.testing\n",
        "from tvm import relay\n",
        "import tvm.contrib.utils\n",
        "from tvm.micro import export_model_library_format\n",
        "from tvm.contrib.download import download_testdata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "NVrGMr3D5XAg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "695e0387-117b-4bf1-d74e-d60ba8dbea82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "def @main(%serving_default_keras_tensor_85:0: Tensor[(1, 28, 28, 1), int8] /* span=serving_default_keras_tensor_85:0:0:0 */, %v_param_1: Tensor[(3, 3, 1, 8), int8] /* span=tfl.pseudo_qconst55:0:0 */, %v_param_2: Tensor[(8), int32] /* span=tfl.pseudo_qconst54:0:0 */, %v_param_3: Tensor[(3, 3, 8, 1), int8] /* span=tfl.pseudo_qconst53:0:0 */, %v_param_4: Tensor[(8), int32] /* span=tfl.pseudo_qconst52:0:0 */, %v_param_5: Tensor[(1, 1, 8, 16), int8] /* span=tfl.pseudo_qconst51:0:0 */, %v_param_6: Tensor[(16), int32] /* span=tfl.pseudo_qconst50:0:0 */, %v_param_7: Tensor[(3, 3, 16, 1), int8] /* span=tfl.pseudo_qconst49:0:0 */, %v_param_8: Tensor[(16), int32] /* span=tfl.pseudo_qconst48:0:0 */, %v_param_9: Tensor[(1, 1, 16, 32), int8] /* span=tfl.pseudo_qconst47:0:0 */, %v_param_10: Tensor[(32), int32] /* span=tfl.pseudo_qconst46:0:0 */, %v_param_11: Tensor[(3, 3, 32, 1), int8] /* span=tfl.pseudo_qconst45:0:0 */, %v_param_12: Tensor[(32), int32] /* span=tfl.pseudo_qconst44:0:0 */, %v_param_13: Tensor[(1, 1, 32, 32), int8] /* span=tfl.pseudo_qconst43:0:0 */, %v_param_14: Tensor[(32), int32] /* span=tfl.pseudo_qconst42:0:0 */, %v_param_15: Tensor[(3, 3, 32, 1), int8] /* span=tfl.pseudo_qconst41:0:0 */, %v_param_16: Tensor[(32), int32] /* span=tfl.pseudo_qconst40:0:0 */, %v_param_17: Tensor[(1, 1, 32, 64), int8] /* span=tfl.pseudo_qconst39:0:0 */, %v_param_18: Tensor[(64), int32] /* span=tfl.pseudo_qconst38:0:0 */, %v_param_19: Tensor[(3, 3, 64, 1), int8] /* span=tfl.pseudo_qconst37:0:0 */, %v_param_20: Tensor[(64), int32] /* span=tfl.pseudo_qconst36:0:0 */, %v_param_21: Tensor[(1, 1, 64, 64), int8] /* span=tfl.pseudo_qconst35:0:0 */, %v_param_22: Tensor[(64), int32] /* span=tfl.pseudo_qconst34:0:0 */, %v_param_23: Tensor[(3, 3, 64, 1), int8] /* span=tfl.pseudo_qconst33:0:0 */, %v_param_24: Tensor[(64), int32] /* span=tfl.pseudo_qconst32:0:0 */, %v_param_25: Tensor[(1, 1, 64, 128), int8] /* span=tfl.pseudo_qconst31:0:0 */, %v_param_26: Tensor[(128), int32] /* span=tfl.pseudo_qconst30:0:0 */, %v_param_27: Tensor[(3, 3, 128, 1), int8] /* span=tfl.pseudo_qconst29:0:0 */, %v_param_28: Tensor[(128), int32] /* span=tfl.pseudo_qconst28:0:0 */, %v_param_29: Tensor[(1, 1, 128, 128), int8] /* span=tfl.pseudo_qconst27:0:0 */, %v_param_30: Tensor[(128), int32] /* span=tfl.pseudo_qconst26:0:0 */, %v_param_31: Tensor[(3, 3, 128, 1), int8] /* span=tfl.pseudo_qconst25:0:0 */, %v_param_32: Tensor[(128), int32] /* span=tfl.pseudo_qconst24:0:0 */, %v_param_33: Tensor[(1, 1, 128, 128), int8] /* span=tfl.pseudo_qconst23:0:0 */, %v_param_34: Tensor[(128), int32] /* span=tfl.pseudo_qconst22:0:0 */, %v_param_35: Tensor[(3, 3, 128, 1), int8] /* span=tfl.pseudo_qconst21:0:0 */, %v_param_36: Tensor[(128), int32] /* span=tfl.pseudo_qconst20:0:0 */, %v_param_37: Tensor[(1, 1, 128, 128), int8] /* span=tfl.pseudo_qconst19:0:0 */, %v_param_38: Tensor[(128), int32] /* span=tfl.pseudo_qconst18:0:0 */, %v_param_39: Tensor[(3, 3, 128, 1), int8] /* span=tfl.pseudo_qconst17:0:0 */, %v_param_40: Tensor[(128), int32] /* span=tfl.pseudo_qconst16:0:0 */, %v_param_41: Tensor[(1, 1, 128, 128), int8] /* span=tfl.pseudo_qconst15:0:0 */, %v_param_42: Tensor[(128), int32] /* span=tfl.pseudo_qconst14:0:0 */, %v_param_43: Tensor[(3, 3, 128, 1), int8] /* span=tfl.pseudo_qconst13:0:0 */, %v_param_44: Tensor[(128), int32] /* span=tfl.pseudo_qconst12:0:0 */, %v_param_45: Tensor[(1, 1, 128, 128), int8] /* span=tfl.pseudo_qconst11:0:0 */, %v_param_46: Tensor[(128), int32] /* span=tfl.pseudo_qconst10:0:0 */, %v_param_47: Tensor[(3, 3, 128, 1), int8] /* span=tfl.pseudo_qconst9:0:0 */, %v_param_48: Tensor[(128), int32] /* span=tfl.pseudo_qconst8:0:0 */, %v_param_49: Tensor[(1, 1, 128, 256), int8] /* span=tfl.pseudo_qconst7:0:0 */, %v_param_50: Tensor[(256), int32] /* span=tfl.pseudo_qconst6:0:0 */, %v_param_51: Tensor[(3, 3, 256, 1), int8] /* span=tfl.pseudo_qconst5:0:0 */, %v_param_52: Tensor[(256), int32] /* span=tfl.pseudo_qconst4:0:0 */, %v_param_53: Tensor[(1, 1, 256, 256), int8] /* span=tfl.pseudo_qconst3:0:0 */, %v_param_54: Tensor[(256), int32] /* span=tfl.pseudo_qconst2:0:0 */, %v_param_55: Tensor[(10, 256), int8] /* span=tfl.pseudo_qconst1:0:0 */, %v_param_56: Tensor[(10), int32] /* span=tfl.pseudo_qconst:0:0 */, output_tensor_names=[\"StatefulPartitionedCall_1_0\"]) {\n",
            "  %0 = qnn.conv2d(%serving_default_keras_tensor_85:0, %v_param_1, -128 /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, 0 /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, 0.00392157f /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, meta[relay.Constant][0] /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], channels=8, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */;\n",
            "  %1 = nn.bias_add(%0, %v_param_2, axis=3) /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */;\n",
            "  %2 = qnn.requantize(%1, meta[relay.Constant][1] /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, 0 /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, 0.0171924f /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, -128 /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */;\n",
            "  %3 = clip(%2, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_27_1/Relu;functional_1_1/batch_normalization_27_1/batchnorm/add_1;functional_1_1/batch_normalization_27_1/batchnorm/mul_1;functional_1_1/conv2d_14_1/Reshape;functional_1_1/conv2d_14_1/add;functional_1_1/batch_normalization_27_1/batchnorm/mul;functional_1_1/conv2d_14_1/convolution;functional_1_1/batch_normalization_27_1/batchnorm/sub1:0:0 */;\n",
            "  %4 = qnn.conv2d(%3, %v_param_3, -128 /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, 0.0171924f /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, meta[relay.Constant][2] /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=8, channels=8, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */;\n",
            "  %5 = nn.bias_add(%4, %v_param_4, axis=3) /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */;\n",
            "  %6 = qnn.requantize(%5, meta[relay.Constant][3] /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, 0.017906f /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */;\n",
            "  %7 = clip(%6, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_28_1/Relu;functional_1_1/batch_normalization_28_1/batchnorm/add_1;functional_1_1/batch_normalization_28_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_13_1/add;functional_1_1/depthwise_conv2d_13_1/depthwise;functional_1_1/depthwise_conv2d_13_1/Reshape;functional_1_1/batch_normalization_28_1/batchnorm/mul;functional_1_1/batch_normalization_28_1/batchnorm/sub:0:0 */;\n",
            "  %8 = qnn.conv2d(%7, %v_param_5, -128 /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, 0.017906f /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, meta[relay.Constant][4] /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=16, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */;\n",
            "  %9 = nn.bias_add(%8, %v_param_6, axis=3) /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */;\n",
            "  %10 = qnn.requantize(%9, meta[relay.Constant][5] /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, 0.0209716f /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */;\n",
            "  %11 = clip(%10, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_29_1/Relu;functional_1_1/batch_normalization_29_1/batchnorm/add_1;functional_1_1/batch_normalization_29_1/batchnorm/mul_1;functional_1_1/conv2d_15_1/Reshape;functional_1_1/conv2d_15_1/add;functional_1_1/batch_normalization_29_1/batchnorm/mul;functional_1_1/conv2d_15_1/convolution;functional_1_1/batch_normalization_29_1/batchnorm/sub:0:0 */;\n",
            "  %12 = qnn.conv2d(%11, %v_param_7, -128 /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, 0.0209716f /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, meta[relay.Constant][6] /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=16, channels=16, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */;\n",
            "  %13 = nn.bias_add(%12, %v_param_8, axis=3) /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */;\n",
            "  %14 = qnn.requantize(%13, meta[relay.Constant][7] /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, 0.0187779f /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */;\n",
            "  %15 = clip(%14, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_30_1/Relu;functional_1_1/batch_normalization_30_1/batchnorm/add_1;functional_1_1/batch_normalization_30_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_14_1/add;functional_1_1/depthwise_conv2d_14_1/depthwise;functional_1_1/depthwise_conv2d_14_1/Reshape;functional_1_1/batch_normalization_30_1/batchnorm/mul;functional_1_1/batch_normalization_30_1/batchnorm/sub:0:0 */;\n",
            "  %16 = qnn.conv2d(%15, %v_param_9, -128 /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, 0.0187779f /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, meta[relay.Constant][8] /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */;\n",
            "  %17 = nn.bias_add(%16, %v_param_10, axis=3) /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */;\n",
            "  %18 = qnn.requantize(%17, meta[relay.Constant][9] /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, 0.017427f /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */;\n",
            "  %19 = clip(%18, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_31_1/Relu;functional_1_1/batch_normalization_31_1/batchnorm/add_1;functional_1_1/batch_normalization_31_1/batchnorm/mul_1;functional_1_1/conv2d_16_1/Reshape;functional_1_1/conv2d_16_1/add;functional_1_1/batch_normalization_31_1/batchnorm/mul;functional_1_1/conv2d_16_1/convolution;functional_1_1/batch_normalization_31_1/batchnorm/sub:0:0 */;\n",
            "  %20 = qnn.conv2d(%19, %v_param_11, -128 /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, 0.017427f /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, meta[relay.Constant][10] /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */;\n",
            "  %21 = nn.bias_add(%20, %v_param_12, axis=3) /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */;\n",
            "  %22 = qnn.requantize(%21, meta[relay.Constant][11] /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, 0.0187767f /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */;\n",
            "  %23 = clip(%22, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_32_1/Relu;functional_1_1/batch_normalization_32_1/batchnorm/add_1;functional_1_1/batch_normalization_32_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_15_1/add;functional_1_1/depthwise_conv2d_15_1/depthwise;functional_1_1/depthwise_conv2d_15_1/Reshape;functional_1_1/batch_normalization_32_1/batchnorm/mul;functional_1_1/batch_normalization_32_1/batchnorm/sub:0:0 */;\n",
            "  %24 = qnn.conv2d(%23, %v_param_13, -128 /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, 0.0187767f /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, meta[relay.Constant][12] /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=32, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */;\n",
            "  %25 = nn.bias_add(%24, %v_param_14, axis=3) /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */;\n",
            "  %26 = qnn.requantize(%25, meta[relay.Constant][13] /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, 0.0177867f /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */;\n",
            "  %27 = clip(%26, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_33_1/Relu;functional_1_1/batch_normalization_33_1/batchnorm/add_1;functional_1_1/batch_normalization_33_1/batchnorm/mul_1;functional_1_1/conv2d_17_1/Reshape;functional_1_1/conv2d_17_1/add;functional_1_1/batch_normalization_33_1/batchnorm/mul;functional_1_1/conv2d_17_1/convolution;functional_1_1/batch_normalization_33_1/batchnorm/sub:0:0 */;\n",
            "  %28 = qnn.conv2d(%27, %v_param_15, -128 /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, 0.0177867f /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, meta[relay.Constant][14] /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, strides=[2, 2], padding=[1, 1, 1, 1], groups=32, channels=32, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */;\n",
            "  %29 = nn.bias_add(%28, %v_param_16, axis=3) /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */;\n",
            "  %30 = qnn.requantize(%29, meta[relay.Constant][15] /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, 0.0261977f /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */;\n",
            "  %31 = clip(%30, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_34_1/Relu;functional_1_1/batch_normalization_34_1/batchnorm/add_1;functional_1_1/batch_normalization_34_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_16_1/add;functional_1_1/depthwise_conv2d_16_1/depthwise;functional_1_1/depthwise_conv2d_16_1/Reshape;functional_1_1/batch_normalization_34_1/batchnorm/mul;functional_1_1/batch_normalization_34_1/batchnorm/sub:0:0 */;\n",
            "  %32 = qnn.conv2d(%31, %v_param_17, -128 /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, 0.0261977f /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, meta[relay.Constant][16] /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */;\n",
            "  %33 = nn.bias_add(%32, %v_param_18, axis=3) /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */;\n",
            "  %34 = qnn.requantize(%33, meta[relay.Constant][17] /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, 0.0213618f /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */;\n",
            "  %35 = clip(%34, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_35_1/Relu;functional_1_1/batch_normalization_35_1/batchnorm/add_1;functional_1_1/batch_normalization_35_1/batchnorm/mul_1;functional_1_1/conv2d_18_1/Reshape;functional_1_1/conv2d_18_1/add;functional_1_1/batch_normalization_35_1/batchnorm/mul;functional_1_1/conv2d_18_1/convolution;functional_1_1/batch_normalization_35_1/batchnorm/sub:0:0 */;\n",
            "  %36 = qnn.conv2d(%35, %v_param_19, -128 /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, 0.0213618f /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, meta[relay.Constant][18] /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */;\n",
            "  %37 = nn.bias_add(%36, %v_param_20, axis=3) /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */;\n",
            "  %38 = qnn.requantize(%37, meta[relay.Constant][19] /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, 0.0289458f /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */;\n",
            "  %39 = clip(%38, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_36_1/Relu;functional_1_1/batch_normalization_36_1/batchnorm/add_1;functional_1_1/batch_normalization_36_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_17_1/add;functional_1_1/depthwise_conv2d_17_1/depthwise;functional_1_1/depthwise_conv2d_17_1/Reshape;functional_1_1/batch_normalization_36_1/batchnorm/mul;functional_1_1/batch_normalization_36_1/batchnorm/sub:0:0 */;\n",
            "  %40 = qnn.conv2d(%39, %v_param_21, -128 /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, 0.0289458f /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, meta[relay.Constant][20] /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=64, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */;\n",
            "  %41 = nn.bias_add(%40, %v_param_22, axis=3) /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */;\n",
            "  %42 = qnn.requantize(%41, meta[relay.Constant][21] /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, 0.0174071f /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */;\n",
            "  %43 = clip(%42, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_37_1/Relu;functional_1_1/batch_normalization_37_1/batchnorm/add_1;functional_1_1/batch_normalization_37_1/batchnorm/mul_1;functional_1_1/conv2d_19_1/Reshape;functional_1_1/conv2d_19_1/add;functional_1_1/batch_normalization_37_1/batchnorm/mul;functional_1_1/conv2d_19_1/convolution;functional_1_1/batch_normalization_37_1/batchnorm/sub:0:0 */;\n",
            "  %44 = qnn.conv2d(%43, %v_param_23, -128 /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, 0.0174071f /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, meta[relay.Constant][22] /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=64, channels=64, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */;\n",
            "  %45 = nn.bias_add(%44, %v_param_24, axis=3) /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */;\n",
            "  %46 = qnn.requantize(%45, meta[relay.Constant][23] /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, 0.0276849f /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */;\n",
            "  %47 = clip(%46, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_38_1/Relu;functional_1_1/batch_normalization_38_1/batchnorm/add_1;functional_1_1/batch_normalization_38_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_18_1/add;functional_1_1/depthwise_conv2d_18_1/depthwise;functional_1_1/depthwise_conv2d_18_1/Reshape;functional_1_1/batch_normalization_38_1/batchnorm/mul;functional_1_1/batch_normalization_38_1/batchnorm/sub:0:0 */;\n",
            "  %48 = qnn.conv2d(%47, %v_param_25, -128 /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, 0.0276849f /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, meta[relay.Constant][24] /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */;\n",
            "  %49 = nn.bias_add(%48, %v_param_26, axis=3) /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */;\n",
            "  %50 = qnn.requantize(%49, meta[relay.Constant][25] /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, 0.0220062f /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */;\n",
            "  %51 = clip(%50, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_39_1/Relu;functional_1_1/batch_normalization_39_1/batchnorm/add_1;functional_1_1/batch_normalization_39_1/batchnorm/mul_1;functional_1_1/conv2d_20_1/Reshape;functional_1_1/conv2d_20_1/add;functional_1_1/batch_normalization_39_1/batchnorm/mul;functional_1_1/conv2d_20_1/convolution;functional_1_1/batch_normalization_39_1/batchnorm/sub:0:0 */;\n",
            "  %52 = qnn.conv2d(%51, %v_param_27, -128 /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, 0.0220062f /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, meta[relay.Constant][26] /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */;\n",
            "  %53 = nn.bias_add(%52, %v_param_28, axis=3) /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */;\n",
            "  %54 = qnn.requantize(%53, meta[relay.Constant][27] /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, 0.0196297f /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */;\n",
            "  %55 = clip(%54, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_40_1/Relu;functional_1_1/batch_normalization_40_1/batchnorm/add_1;functional_1_1/batch_normalization_40_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_19_1/add;functional_1_1/depthwise_conv2d_19_1/depthwise;functional_1_1/depthwise_conv2d_19_1/Reshape;functional_1_1/batch_normalization_40_1/batchnorm/mul;functional_1_1/batch_normalization_40_1/batchnorm/sub:0:0 */;\n",
            "  %56 = qnn.conv2d(%55, %v_param_29, -128 /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, 0.0196297f /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, meta[relay.Constant][28] /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */;\n",
            "  %57 = nn.bias_add(%56, %v_param_30, axis=3) /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */;\n",
            "  %58 = qnn.requantize(%57, meta[relay.Constant][29] /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, 0.0118288f /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */;\n",
            "  %59 = clip(%58, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_41_1/Relu;functional_1_1/batch_normalization_41_1/batchnorm/add_1;functional_1_1/batch_normalization_41_1/batchnorm/mul_1;functional_1_1/conv2d_21_1/Reshape;functional_1_1/conv2d_21_1/add;functional_1_1/batch_normalization_41_1/batchnorm/mul;functional_1_1/conv2d_21_1/convolution;functional_1_1/batch_normalization_41_1/batchnorm/sub:0:0 */;\n",
            "  %60 = qnn.conv2d(%59, %v_param_31, -128 /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, 0.0118288f /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, meta[relay.Constant][30] /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */;\n",
            "  %61 = nn.bias_add(%60, %v_param_32, axis=3) /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */;\n",
            "  %62 = qnn.requantize(%61, meta[relay.Constant][31] /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, 0.0126314f /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */;\n",
            "  %63 = clip(%62, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_42_1/Relu;functional_1_1/batch_normalization_42_1/batchnorm/add_1;functional_1_1/batch_normalization_42_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_20_1/add;functional_1_1/depthwise_conv2d_20_1/depthwise;functional_1_1/depthwise_conv2d_20_1/Reshape;functional_1_1/batch_normalization_42_1/batchnorm/mul;functional_1_1/batch_normalization_42_1/batchnorm/sub:0:0 */;\n",
            "  %64 = qnn.conv2d(%63, %v_param_33, -128 /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, 0.0126314f /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, meta[relay.Constant][32] /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */;\n",
            "  %65 = nn.bias_add(%64, %v_param_34, axis=3) /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */;\n",
            "  %66 = qnn.requantize(%65, meta[relay.Constant][33] /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, 0.0115743f /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */;\n",
            "  %67 = clip(%66, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_43_1/Relu;functional_1_1/batch_normalization_43_1/batchnorm/add_1;functional_1_1/batch_normalization_43_1/batchnorm/mul_1;functional_1_1/conv2d_22_1/Reshape;functional_1_1/conv2d_22_1/add;functional_1_1/batch_normalization_43_1/batchnorm/mul;functional_1_1/conv2d_22_1/convolution;functional_1_1/batch_normalization_43_1/batchnorm/sub:0:0 */;\n",
            "  %68 = qnn.conv2d(%67, %v_param_35, -128 /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, 0.0115743f /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, meta[relay.Constant][34] /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */;\n",
            "  %69 = nn.bias_add(%68, %v_param_36, axis=3) /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */;\n",
            "  %70 = qnn.requantize(%69, meta[relay.Constant][35] /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, 0.0133976f /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */;\n",
            "  %71 = clip(%70, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_44_1/Relu;functional_1_1/batch_normalization_44_1/batchnorm/add_1;functional_1_1/batch_normalization_44_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_21_1/add;functional_1_1/depthwise_conv2d_21_1/depthwise;functional_1_1/depthwise_conv2d_21_1/Reshape;functional_1_1/batch_normalization_44_1/batchnorm/mul;functional_1_1/batch_normalization_44_1/batchnorm/sub:0:0 */;\n",
            "  %72 = qnn.conv2d(%71, %v_param_37, -128 /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, 0.0133976f /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, meta[relay.Constant][36] /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */;\n",
            "  %73 = nn.bias_add(%72, %v_param_38, axis=3) /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */;\n",
            "  %74 = qnn.requantize(%73, meta[relay.Constant][37] /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, 0.0115068f /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */;\n",
            "  %75 = clip(%74, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_45_1/Relu;functional_1_1/batch_normalization_45_1/batchnorm/add_1;functional_1_1/batch_normalization_45_1/batchnorm/mul_1;functional_1_1/conv2d_23_1/Reshape;functional_1_1/conv2d_23_1/add;functional_1_1/batch_normalization_45_1/batchnorm/mul;functional_1_1/conv2d_23_1/convolution;functional_1_1/batch_normalization_45_1/batchnorm/sub:0:0 */;\n",
            "  %76 = qnn.conv2d(%75, %v_param_39, -128 /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, 0.0115068f /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, meta[relay.Constant][38] /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */;\n",
            "  %77 = nn.bias_add(%76, %v_param_40, axis=3) /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */;\n",
            "  %78 = qnn.requantize(%77, meta[relay.Constant][39] /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, 0.0147219f /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */;\n",
            "  %79 = clip(%78, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_46_1/Relu;functional_1_1/batch_normalization_46_1/batchnorm/add_1;functional_1_1/batch_normalization_46_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_22_1/add;functional_1_1/depthwise_conv2d_22_1/depthwise;functional_1_1/depthwise_conv2d_22_1/Reshape;functional_1_1/batch_normalization_46_1/batchnorm/mul;functional_1_1/batch_normalization_46_1/batchnorm/sub:0:0 */;\n",
            "  %80 = qnn.conv2d(%79, %v_param_41, -128 /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, 0.0147219f /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, meta[relay.Constant][40] /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */;\n",
            "  %81 = nn.bias_add(%80, %v_param_42, axis=3) /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */;\n",
            "  %82 = qnn.requantize(%81, meta[relay.Constant][41] /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, 0.01318f /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */;\n",
            "  %83 = clip(%82, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_47_1/Relu;functional_1_1/batch_normalization_47_1/batchnorm/add_1;functional_1_1/batch_normalization_47_1/batchnorm/mul_1;functional_1_1/conv2d_24_1/Reshape;functional_1_1/conv2d_24_1/add;functional_1_1/batch_normalization_47_1/batchnorm/mul;functional_1_1/conv2d_24_1/convolution;functional_1_1/batch_normalization_47_1/batchnorm/sub:0:0 */;\n",
            "  %84 = qnn.conv2d(%83, %v_param_43, -128 /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, 0.01318f /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, meta[relay.Constant][42] /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */;\n",
            "  %85 = nn.bias_add(%84, %v_param_44, axis=3) /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */;\n",
            "  %86 = qnn.requantize(%85, meta[relay.Constant][43] /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, 0.0172803f /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */;\n",
            "  %87 = clip(%86, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_48_1/Relu;functional_1_1/batch_normalization_48_1/batchnorm/add_1;functional_1_1/batch_normalization_48_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_23_1/add;functional_1_1/depthwise_conv2d_23_1/depthwise;functional_1_1/depthwise_conv2d_23_1/Reshape;functional_1_1/batch_normalization_48_1/batchnorm/mul;functional_1_1/batch_normalization_48_1/batchnorm/sub:0:0 */;\n",
            "  %88 = qnn.conv2d(%87, %v_param_45, -128 /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, 0.0172803f /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, meta[relay.Constant][44] /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=128, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */;\n",
            "  %89 = nn.bias_add(%88, %v_param_46, axis=3) /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */;\n",
            "  %90 = qnn.requantize(%89, meta[relay.Constant][45] /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, 0.0126408f /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */;\n",
            "  %91 = clip(%90, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_49_1/Relu;functional_1_1/batch_normalization_49_1/batchnorm/add_1;functional_1_1/batch_normalization_49_1/batchnorm/mul_1;functional_1_1/conv2d_25_1/Reshape;functional_1_1/conv2d_25_1/add;functional_1_1/batch_normalization_49_1/batchnorm/mul;functional_1_1/conv2d_25_1/convolution;functional_1_1/batch_normalization_49_1/batchnorm/sub:0:0 */;\n",
            "  %92 = qnn.conv2d(%91, %v_param_47, -128 /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, 0.0126408f /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, meta[relay.Constant][46] /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, strides=[2, 2], padding=[0, 0, 1, 1], groups=128, channels=128, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */;\n",
            "  %93 = nn.bias_add(%92, %v_param_48, axis=3) /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */;\n",
            "  %94 = qnn.requantize(%93, meta[relay.Constant][47] /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, 0.00846841f /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */;\n",
            "  %95 = clip(%94, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_50_1/Relu;functional_1_1/batch_normalization_50_1/batchnorm/add_1;functional_1_1/batch_normalization_50_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_24_1/add;functional_1_1/depthwise_conv2d_24_1/depthwise;functional_1_1/depthwise_conv2d_24_1/Reshape;functional_1_1/batch_normalization_50_1/batchnorm/mul;functional_1_1/batch_normalization_50_1/batchnorm/sub:0:0 */;\n",
            "  %96 = qnn.conv2d(%95, %v_param_49, -128 /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, 0.00846841f /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, meta[relay.Constant][48] /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */;\n",
            "  %97 = nn.bias_add(%96, %v_param_50, axis=3) /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */;\n",
            "  %98 = qnn.requantize(%97, meta[relay.Constant][49] /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, 0.00942619f /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */;\n",
            "  %99 = clip(%98, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_51_1/Relu;functional_1_1/batch_normalization_51_1/batchnorm/add_1;functional_1_1/batch_normalization_51_1/batchnorm/mul_1;functional_1_1/conv2d_26_1/Reshape;functional_1_1/conv2d_26_1/add;functional_1_1/batch_normalization_51_1/batchnorm/mul;functional_1_1/conv2d_26_1/convolution;functional_1_1/batch_normalization_51_1/batchnorm/sub:0:0 */;\n",
            "  %100 = qnn.conv2d(%99, %v_param_51, -128 /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, 0.00942619f /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, meta[relay.Constant][50] /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, padding=[1, 1, 1, 1], groups=256, channels=256, kernel_size=[3, 3], data_layout=\"NHWC\", kernel_layout=\"HWOI\", out_dtype=\"int32\") /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */;\n",
            "  %101 = nn.bias_add(%100, %v_param_52, axis=3) /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */;\n",
            "  %102 = qnn.requantize(%101, meta[relay.Constant][51] /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, 0.00634476f /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */;\n",
            "  %103 = clip(%102, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_52_1/Relu;functional_1_1/batch_normalization_52_1/batchnorm/add_1;functional_1_1/batch_normalization_52_1/batchnorm/mul_1;functional_1_1/depthwise_conv2d_25_1/add;functional_1_1/depthwise_conv2d_25_1/depthwise;functional_1_1/depthwise_conv2d_25_1/Reshape;functional_1_1/batch_normalization_52_1/batchnorm/mul;functional_1_1/batch_normalization_52_1/batchnorm/sub:0:0 */;\n",
            "  %104 = qnn.conv2d(%103, %v_param_53, -128 /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, 0.00634476f /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, meta[relay.Constant][52] /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, padding=[0, 0, 0, 0], channels=256, kernel_size=[1, 1], data_layout=\"NHWC\", kernel_layout=\"HWIO\", out_dtype=\"int32\") /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */;\n",
            "  %105 = nn.bias_add(%104, %v_param_54, axis=3) /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */;\n",
            "  %106 = qnn.requantize(%105, meta[relay.Constant][53] /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, 0 /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, 0.00885609f /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, -128 /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */, axis=3, out_dtype=\"int8\") /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */;\n",
            "  %107 = clip(%106, a_min=-128f, a_max=127f) /* span=functional_1_1/activation_53_1/Relu;functional_1_1/batch_normalization_53_1/batchnorm/add_1;functional_1_1/batch_normalization_53_1/batchnorm/mul_1;functional_1_1/conv2d_27_1/Reshape;functional_1_1/conv2d_27_1/add;functional_1_1/batch_normalization_53_1/batchnorm/mul;functional_1_1/conv2d_27_1/convolution;functional_1_1/batch_normalization_53_1/batchnorm/sub:0:0 */;\n",
            "  %108 = cast(%107, dtype=\"int32\") /* span=functional_1_1/average_pooling2d_1_1/AvgPool:0:0 */;\n",
            "  %109 = nn.avg_pool2d(%108, pool_size=[1, 1], padding=[0, 0, 0, 0], layout=\"NHWC\") /* span=functional_1_1/average_pooling2d_1_1/AvgPool:0:0 */;\n",
            "  %110 = cast(%109, dtype=\"int8\") /* span=functional_1_1/average_pooling2d_1_1/AvgPool:0:0 */;\n",
            "  %111 = reshape(%110, newshape=[-1, 256]) /* span=functional_1_1/flatten_1_1/Reshape:0:0 */;\n",
            "  %112 = reshape(%111, newshape=[-1, 256]) /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */;\n",
            "  %113 = qnn.dense(%112, %v_param_55, -128 /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, 0 /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, 0.00885609f /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, 0.00558068f /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, units=10, out_dtype=\"int32\") /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */;\n",
            "  %114 = nn.bias_add(%113, %v_param_56) /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */;\n",
            "  %115 = qnn.requantize(%114, 4.9423e-05f /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, 0 /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, 0.0440248f /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, 26 /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */, out_dtype=\"int8\") /* span=functional_1_1/dense_1_1/MatMul;functional_1_1/dense_1_1/Add:0:0 */;\n",
            "  %116 = qnn.dequantize(%115, 0.0440248f /* span=StatefulPartitionedCall_1:0:0:0 */, 26 /* span=StatefulPartitionedCall_1:0:0:0 */, out_dtype=\"float32\") /* span=StatefulPartitionedCall_1:0:0:0 */;\n",
            "  %117 = nn.softmax(%116) /* span=StatefulPartitionedCall_1:0:0:0 */;\n",
            "  qnn.quantize(%117, 0.00390625f /* span=StatefulPartitionedCall_1:0:0:0 */, -128 /* span=StatefulPartitionedCall_1:0:0:0 */, out_dtype=\"int8\") /* span=StatefulPartitionedCall_1:0:0:0 */\n",
            "}\n",
            "\n",
            "\n",
            "Name: _param_1, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 1, 8)\n",
            "Name: _param_2, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (8,)\n",
            "Name: _param_3, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 8, 1)\n",
            "Name: _param_4, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (8,)\n",
            "Name: _param_5, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 8, 16)\n",
            "Name: _param_6, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (16,)\n",
            "Name: _param_7, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 16, 1)\n",
            "Name: _param_8, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (16,)\n",
            "Name: _param_9, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 16, 32)\n",
            "Name: _param_10, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (32,)\n",
            "Name: _param_11, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 32, 1)\n",
            "Name: _param_12, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (32,)\n",
            "Name: _param_13, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 32, 32)\n",
            "Name: _param_14, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (32,)\n",
            "Name: _param_15, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 32, 1)\n",
            "Name: _param_16, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (32,)\n",
            "Name: _param_17, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 32, 64)\n",
            "Name: _param_18, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (64,)\n",
            "Name: _param_19, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 64, 1)\n",
            "Name: _param_20, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (64,)\n",
            "Name: _param_21, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 64, 64)\n",
            "Name: _param_22, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (64,)\n",
            "Name: _param_23, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 64, 1)\n",
            "Name: _param_24, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (64,)\n",
            "Name: _param_25, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 64, 128)\n",
            "Name: _param_26, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_27, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 128, 1)\n",
            "Name: _param_28, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_29, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 128, 128)\n",
            "Name: _param_30, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_31, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 128, 1)\n",
            "Name: _param_32, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_33, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 128, 128)\n",
            "Name: _param_34, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_35, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 128, 1)\n",
            "Name: _param_36, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_37, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 128, 128)\n",
            "Name: _param_38, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_39, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 128, 1)\n",
            "Name: _param_40, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_41, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 128, 128)\n",
            "Name: _param_42, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_43, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 128, 1)\n",
            "Name: _param_44, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_45, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 128, 128)\n",
            "Name: _param_46, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_47, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 128, 1)\n",
            "Name: _param_48, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (128,)\n",
            "Name: _param_49, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 128, 256)\n",
            "Name: _param_50, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (256,)\n",
            "Name: _param_51, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (3, 3, 256, 1)\n",
            "Name: _param_52, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (256,)\n",
            "Name: _param_53, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (1, 1, 256, 256)\n",
            "Name: _param_54, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (256,)\n",
            "Name: _param_55, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (10, 256)\n",
            "Name: _param_56, Type: <class 'tvm.runtime.ndarray.NDArray'>, Shape: (10,)\n"
          ]
        }
      ],
      "source": [
        "MODEL_URL = \"/content/drive/MyDrive/trained_models/meinMNIST_V1.tflite\"\n",
        "MODEL_NAME = \"meinMNIST_V1.tflite\"\n",
        "\n",
        "tflite_model_buf = open(MODEL_URL, \"rb\").read()\n",
        "try:\n",
        "    import tflite\n",
        "\n",
        "    tflite_model = tflite.Model.GetRootAsModel(tflite_model_buf, 0)\n",
        "except AttributeError:\n",
        "    import tflite.Model\n",
        "\n",
        "    tflite_model = tflite.Model.Model.GetRootAsModel(tflite_model_buf, 0)\n",
        "\n",
        "\n",
        "\n",
        "input_tensor = 'serving_default_input_layer_9:0'  # Use the name from input_details\n",
        "input_shape = (1, 28, 28,1)  # This should be a tuple\n",
        "input_dtype = 'float32'          # This should be a string\n",
        "\n",
        "\n",
        "# Parse TFLite model and convert it to a Relay module\n",
        "from tvm import relay, transform\n",
        "\n",
        "mod, params = relay.frontend.from_tflite(\n",
        "    tflite_model, shape_dict={input_tensor: input_shape}, dtype_dict={input_tensor: input_dtype}\n",
        ")\n",
        "\n",
        "# Print the Relay module to inspect the weights\n",
        "print(mod)\n",
        "\n",
        "# Check the type and shape of the weight tensors\n",
        "for name, param in params.items():\n",
        "    print(f\"Name: {name}, Type: {type(param)}, Shape: {param.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import json\n",
        "from PIL import Image\n",
        "import tarfile\n",
        "\n",
        "import tvm\n",
        "from tvm import relay\n",
        "from tvm.relay.backend import Executor, Runtime\n",
        "from tvm.contrib.download import download_testdata\n",
        "from tvm.micro import export_model_library_format\n",
        "from tvm.relay.op.contrib import cmsisnn\n",
        "from tvm.micro.testing.utils import create_header_file"
      ],
      "metadata": {
        "id": "QUQUYg4vfgH1"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "RHT2p9pQ5hTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13a6880-16db-4702-cee7-cac907b25b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameter size: 32\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/drive/MyDrive/Rar_files/model_meinMNIST2.tar')"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# We can use TVM native schedules or rely on the CMSIS-NN kernels using TVM Bring-Your-Own-Code (BYOC) capability.\n",
        "USE_CMSIS_NN = True\n",
        "\n",
        "# USMP (Unified Static Memory Planning) performs memory planning of all tensors holistically to achieve best memory utilization\n",
        "DISABLE_USMP = False\n",
        "\n",
        "# Use the C runtime (crt)\n",
        "RUNTIME = Runtime(\"crt\")\n",
        "\n",
        "# We define the target by passing the board name to `tvm.target.target.micro`.\n",
        "# If your board is not included in the supported models, you can define the target such as:\n",
        "#TARGET = tvm.target.Target(\"c -keys=arm_cpu,cpu -mcpu=cortex-m4\")\n",
        "TARGET = tvm.target.target.micro(\"stm32l4r5zi\")\n",
        "\n",
        "# Use the AOT executor rather than graph or vm executors. Use unpacked API and C calling style.\n",
        "EXECUTOR = tvm.relay.backend.Executor(\n",
        "    \"aot\", {\"unpacked-api\": True, \"interface-api\": \"c\", \"workspace-byte-alignment\": 8}\n",
        ")\n",
        "\n",
        "# Now, we set the compilation configurations and compile the model for the target:\n",
        "config = {\"tir.disable_vectorize\": True}\n",
        "#if USE_CMSIS_NN:\n",
        "#    config[\"relay.ext.cmsisnn.options\"] = {\"mcpu\": TARGET.mcpu}\n",
        "#if DISABLE_USMP:\n",
        "#    config[\"tir.usmp.enable\"] = False\n",
        "\n",
        "with tvm.transform.PassContext(opt_level=3, config=config):\n",
        "    if USE_CMSIS_NN:\n",
        "        # When we are using CMSIS-NN, TVM searches for patterns in the\n",
        "        # relay graph that it can offload to the CMSIS-NN kernels.\n",
        "        mod = cmsisnn.partition_for_cmsisnn(mod, params, mcpu=TARGET.mcpu)\n",
        "        lowered = tvm.relay.build(\n",
        "        mod, target=TARGET, params=params, runtime=RUNTIME, executor=EXECUTOR\n",
        "    )\n",
        "parameter_size = len(tvm.runtime.save_param_dict(lowered.get_params()))\n",
        "print(f\"Model parameter size: {parameter_size}\")\n",
        "\n",
        "# We need to pick a directory where our file will be saved.\n",
        "# If running on Google Colab, we'll save everything in ``/root/tutorial`` (aka ``~/tutorial``)\n",
        "# but you'll probably want to store it elsewhere if running locally.\n",
        "\n",
        "BUILD_DIR = pathlib.Path(\"/content/drive/MyDrive/Rar_files\")\n",
        "\n",
        "BUILD_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# Now, we export the model into a tar file:\n",
        "TAR_PATH = pathlib.Path(BUILD_DIR) / \"model_meinMNIST2.tar\"\n",
        "export_model_library_format(lowered, TAR_PATH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F8fDLb9wHCip"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPC70e8WtX3Fvvg4OVE6ugu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}